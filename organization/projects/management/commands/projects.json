[{"model": "organization-projects.project", "pk": 1, "fields": {"keywords_string": "", "site": 1, "title": "Cagima", "title_fr": "Cagima", "title_en": "Cagima", "slug": "cagima", "_meta_title": "", "description": "Conception acoustique globale d\u2019instruments de musique \u00e0 anche, justes et homog\u00e8nes", "description_fr": "Conception acoustique globale d\u2019instruments de musique \u00e0 anche, justes et homog\u00e8nes", "description_en": "global Acoustic Conception of Reed Musical Instruments, In Tune and Homogeneous", "gen_description": false, "created": "2016-09-02T14:16:07.906Z", "updated": "2018-07-25T14:34:51.394Z", "status": 2, "publish_date": "2016-09-02T14:16:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Cagima s'est int&eacute;ress&eacute; aux d&eacute;fauts de justesse et d'homog&eacute;n&eacute;it&eacute; d'&eacute;mission et de timbre des instruments de musique &agrave; anche, tant du point de vue de celui qui les joue que de celui qui les fabrique, et vise &agrave; int&eacute;grer au mieux les contraintes relatives &agrave; chacun d'eux.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le projet ambitionnait de remplacer l'approche incr&eacute;mentale historique adopt&eacute;e par les facteurs par une approche rationnelle et globale visant &agrave; concevoir ab initio de nouveaux instruments, appel&eacute;s &laquo; logiques &raquo;, minimisant les d&eacute;fauts identifi&eacute;s, ce qui constitue un r&eacute;el saut m&eacute;thodologique et technologique dans la facture instrumentale.</p>\r\n<p>Il s'est agi pour cela d'&eacute;valuer d'abord les contraintes sur la production du son impos&eacute;es par un instrument au musicien, via la mesure et l'interpr&eacute;tation du geste (pression dans la bouche, appui sur l'anche avec la l&egrave;vre, configuration du conduit vocal, etc.), et de les corr&eacute;ler &agrave; des d&eacute;fauts acoustiques des instruments afin de proposer des m&eacute;thodologies novatrices de conception globale de la perce et des trous lat&eacute;raux des instruments &agrave; anche. Pour cela, l'&eacute;tude de crit&egrave;res globaux &eacute;tait au centre du projet, et leur prise en compte a aboutit, apr&egrave;s un processus d'optimisation, &agrave; la fabrication de prototypes jouables d'instruments.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR\u201011\u2010BS09\u2010022\u201002.</p>\r\n<div class=\"Texte\"></div>", "content_fr": "<p>Le projet Cagima s'est int&eacute;ress&eacute; aux d&eacute;fauts de justesse et d'homog&eacute;n&eacute;it&eacute; d'&eacute;mission et de timbre des instruments de musique &agrave; anche, tant du point de vue de celui qui les joue que de celui qui les fabrique, et vise &agrave; int&eacute;grer au mieux les contraintes relatives &agrave; chacun d'eux.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le projet ambitionnait de remplacer l'approche incr&eacute;mentale historique adopt&eacute;e par les facteurs par une approche rationnelle et globale visant &agrave; concevoir ab initio de nouveaux instruments, appel&eacute;s &laquo; logiques &raquo;, minimisant les d&eacute;fauts identifi&eacute;s, ce qui constitue un r&eacute;el saut m&eacute;thodologique et technologique dans la facture instrumentale.</p>\r\n<p>Il s'est agi pour cela d'&eacute;valuer d'abord les contraintes sur la production du son impos&eacute;es par un instrument au musicien, via la mesure et l'interpr&eacute;tation du geste (pression dans la bouche, appui sur l'anche avec la l&egrave;vre, configuration du conduit vocal, etc.), et de les corr&eacute;ler &agrave; des d&eacute;fauts acoustiques des instruments afin de proposer des m&eacute;thodologies novatrices de conception globale de la perce et des trous lat&eacute;raux des instruments &agrave; anche. Pour cela, l'&eacute;tude de crit&egrave;res globaux &eacute;tait au centre du projet, et leur prise en compte a aboutit, apr&egrave;s un processus d'optimisation, &agrave; la fabrication de prototypes jouables d'instruments.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR\u201011\u2010BS09\u2010022\u201002.</p>\r\n<div class=\"Texte\"></div>", "content_en": "<p>The Cagima project focused on flaws found in reed instruments in tuning, homogeneity of emitted sounds, and timbre from both the perspective of the musician and also that of the instrument-maker who endeavors to satisfy the specific demands of each musician.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The project's ambition was to replace the historical incremental approach used by instrument-makers with a rational and global approach that aims to design new \"logical\" instruments that minimize the identified flaws. This is a large step forward for the methodology and technology of instrument making.</p>\r\n<p>To begin, the constraints of sound production that are imposed by an instrument on a musician must be evaluated via the measurement of a specific gesture (e.g. pressure in the mouth, pressing on the reed with a lip, configuration of the vocal tract) and to correlate them to the acoustic flaws of the instruments in order to suggest novel methodologies for the general design for the bore and the lateral holes of reed instruments. For this, the study of global criterion was at the heart of this project; their understanding led to the fabrication of playable prototypes of musical instruments.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR\u201011\u2010BS09\u2010022\u201002.</p>", "date_from": "2011-12-01", "date_to": "2015-11-30", "user": null, "type": "external", "external_id": "ANR\u201011\u2010BS09\u2010022\u201002", "program": 1, "program_type": 2, "call": 16, "lead_team": null, "lead_organization": 6, "website": "http://cagima.ircam.fr/", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 44], "organizations": [7, 1, 18], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 3, "fields": {"keywords_string": "", "site": 1, "title": "Lutherie Augment\u00e9e", "title_fr": "Lutherie Augment\u00e9e", "title_en": "Augmented instrument-making", "slug": "lutherie-augmentee", "_meta_title": "", "description": "Production de prototypes d\u2019instruments ou parties d\u2019instruments utilisables en concert", "description_fr": "Production de prototypes d\u2019instruments ou parties d\u2019instruments utilisables en concert", "description_en": "Prototypes of musical instruments, or components of musical instruments, that can be used in concert have been produced in this project", "gen_description": false, "created": "2016-09-06T12:45:12.431Z", "updated": "2018-06-29T10:22:40.373Z", "status": 2, "publish_date": "2016-09-06T12:45:12Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet &laquo; Lutherie Augment&eacute;e &raquo; est au c&oelig;ur des recherches sur les instruments de musique. Il a produit des prototypes d&rsquo;instruments ou parties d&rsquo;instruments utilisables en concert. On peut citer par exemple l&rsquo;&eacute;largissement de la gamme de sourdines des cuivres, l&rsquo;&eacute;tude d&rsquo;un dispositif d&rsquo;accord automatique pour la timbale et la r&eacute;alisation d&rsquo;un bec de clarinette &agrave; volume variable, ou encore un archet et un bec instrument&eacute;s par plusieurs capteurs.</p>\r\n<p>De plus, l&rsquo;Ircam con&ccedil;oit et poss&egrave;de un instrumentarium de SmartInstruments (guitares, quatuor &agrave; cordes, clarinette basse, sourdines de cuivres) munis de capteurs et d&rsquo;actionneurs, dont les propri&eacute;t&eacute;s acoustiques sont modifiables par l&rsquo;instrumentiste ou le compositeur, et qui diffusent des sons d&rsquo;origines diverses sans enceinte ext&eacute;rieure. Cela a amen&eacute; &agrave; la r&eacute;alisation de COALA, syst&egrave;me embarqu&eacute; de contr&ocirc;le actif &agrave; tr&egrave;s faible latence pour SmartInstruments.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/systemes-et-signaux-sonores-audioacoustique-instruments-s3am/\">Syst&egrave;mes et Signaux Sonores : Audio/Acoustique, instruMents</a>.</p>", "content_fr": "<p>Le projet &laquo; Lutherie Augment&eacute;e &raquo; est au c&oelig;ur des recherches sur les instruments de musique. Il a produit des prototypes d&rsquo;instruments ou parties d&rsquo;instruments utilisables en concert. On peut citer par exemple l&rsquo;&eacute;largissement de la gamme de sourdines des cuivres, l&rsquo;&eacute;tude d&rsquo;un dispositif d&rsquo;accord automatique pour la timbale et la r&eacute;alisation d&rsquo;un bec de clarinette &agrave; volume variable, ou encore un archet et un bec instrument&eacute;s par plusieurs capteurs.</p>\r\n<p>De plus, l&rsquo;Ircam con&ccedil;oit et poss&egrave;de un instrumentarium de SmartInstruments (guitares, quatuor &agrave; cordes, clarinette basse, sourdines de cuivres) munis de capteurs et d&rsquo;actionneurs, dont les propri&eacute;t&eacute;s acoustiques sont modifiables par l&rsquo;instrumentiste ou le compositeur, et qui diffusent des sons d&rsquo;origines diverses sans enceinte ext&eacute;rieure. Cela a amen&eacute; &agrave; la r&eacute;alisation de COALA, syst&egrave;me embarqu&eacute; de contr&ocirc;le actif &agrave; tr&egrave;s faible latence pour SmartInstruments.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/systemes-et-signaux-sonores-audioacoustique-instruments-s3am/\">Syst&egrave;mes et Signaux Sonores : Audio/Acoustique, instruMents</a>.</p>", "content_en": "<p>This project is at the heart of the research on musical instruments. Prototypes of musical instruments, or components of musical instruments, that can be used in concert have been produced in this project.&nbsp; Work carried out includes a broadening of the range of mutes for brass instruments, studying a system for the automatic tuning of a kettledrum, the creation of a clarinet mouthpiece with a variable volume, and the creation of a bow and mouthpiece instrumented via several sensors. In addition, IRCAM has designed and owns an instrumentarium of SmartInstruments (guitars, string quartet, bass clarinet, brass mutes) equipped with sensors and actuators with acoustic properties that a musician or composer can modify, and can diffuse sounds from a variety of sources without an external loudspeaker. This led to the realization of COALA, an embedded low-latency active control system for SmartInstruments.&nbsp;</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-recherche/systemes-et-signaux-sonores-audioacoustique-instruments-s3am/\">Sound Systems and Signals: Audio/Acoustics, InstruMents</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 4, "fields": {"keywords_string": "", "site": 1, "title": "Imarev", "title_fr": "Imarev", "title_en": "Imarev", "slug": "imarev", "_meta_title": "", "description": "Instruments de musique actifs avec r\u00e9glages virtuels", "description_fr": "Instruments de musique actifs avec r\u00e9glages virtuels", "description_en": "Active Musical Instruments with Virtual Adjustments", "gen_description": false, "created": "2016-09-06T12:55:22.873Z", "updated": "2018-07-25T14:40:48.227Z", "status": 2, "publish_date": "2016-09-06T12:55:22Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Au cours des cinquante derni&egrave;res ann&eacute;es, les sciences et technologies de la synth&egrave;se sonore ont permis de cr&eacute;er et contr&ocirc;ler de nouveaux sons &agrave; partir de synth&eacute;tiseurs. Pourtant, des centaines de millions d'instruments acoustiques sont toujours utilis&eacute;s dans le monde. En effet, l'interaction avec les claviers num&eacute;riques et la diffusion par des haut-parleurs est relativement pauvre compar&eacute;e aux subtilit&eacute;s des instruments de musique acoustiques.</p>\r\n<p>Une famille d'instruments de musiques innovants s'est d&eacute;velopp&eacute;e ces derni&egrave;res ann&eacute;es, appel&eacute;e \"instruments hybrides\". Leur principe est bas&eacute; sur l'utilisation d'instruments acoustiques contr&ocirc;l&eacute;s par feedback avec du traitement et de la synth&egrave;se sonore, en vue d'&eacute;tendre les possibilit&eacute;s sonores des instruments. Le son final est ainsi hybride. Il provient de la superposition de la vibration acoustique (ou m&eacute;canique) et de son traitement num&eacute;rique.</p>\r\n<p>Les instruments hybrides ont un avantage important sur les synth&eacute;tiseurs : l'interface avec le musicien reste l'instrument acoustique, tout en incluant les potentialit&eacute;s de la synth&egrave;se sonore. Pourtant, les instruments actifs ne sont pas aussi diffus&eacute;s que les synth&eacute;tiseurs. En effet, il n'y a pas encore de m&eacute;thodologie et d'outils unifi&eacute;s pour la conception et la fabrication d'instruments hybrides.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le but de ce projet est de d&eacute;velopper des mod&egrave;les, algorithmes et dispositifs permettant la cr&eacute;ation d'instruments actifs optimis&eacute;s, de mani&egrave;re unifi&eacute;e. Les mod&egrave;les int&egrave;grent des &laquo; r&eacute;glages virtuels &raquo; qui sont des param&egrave;tres d&eacute;duits de la connaissance et des r&eacute;glages des fabricants d'instruments. Ceci permet un contr&ocirc;le intuitif par les musiciens ainsi qu'une simplification de la complexit&eacute; de la conception des instruments actifs. La qualit&eacute; de la mod&eacute;lisation des &laquo; r&eacute;glages virtuels &raquo; a &eacute;t&eacute; &eacute;valu&eacute;e &agrave; partir de la synth&egrave;se sonore par mod&egrave;le physique et ensuite incorpor&eacute;e dans les instruments hybrides.</p>\r\n<p>En plus de l'application &agrave; la cr&eacute;ation musicale, ce projet a permis de cr&eacute;er des instruments avec une qualit&eacute; &laquo; r&eacute;glable &raquo; utilisant un traitement num&eacute;rique apr&egrave;s la fabrication.</p>\r\n<p>Il a comport&eacute; un volet de recherche fondamentale, avec des applications &agrave; la cr&eacute;ation musicale, la fabrication des instruments de musique et au domaine du contr&ocirc;le actif.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-11-PDOC-010-01.</p>", "content_fr": "<p>Au cours des cinquante derni&egrave;res ann&eacute;es, les sciences et technologies de la synth&egrave;se sonore ont permis de cr&eacute;er et contr&ocirc;ler de nouveaux sons &agrave; partir de synth&eacute;tiseurs. Pourtant, des centaines de millions d'instruments acoustiques sont toujours utilis&eacute;s dans le monde. En effet, l'interaction avec les claviers num&eacute;riques et la diffusion par des haut-parleurs est relativement pauvre compar&eacute;e aux subtilit&eacute;s des instruments de musique acoustiques.</p>\r\n<p>Une famille d'instruments de musiques innovants s'est d&eacute;velopp&eacute;e ces derni&egrave;res ann&eacute;es, appel&eacute;e \"instruments hybrides\". Leur principe est bas&eacute; sur l'utilisation d'instruments acoustiques contr&ocirc;l&eacute;s par feedback avec du traitement et de la synth&egrave;se sonore, en vue d'&eacute;tendre les possibilit&eacute;s sonores des instruments. Le son final est ainsi hybride. Il provient de la superposition de la vibration acoustique (ou m&eacute;canique) et de son traitement num&eacute;rique.</p>\r\n<p>Les instruments hybrides ont un avantage important sur les synth&eacute;tiseurs : l'interface avec le musicien reste l'instrument acoustique, tout en incluant les potentialit&eacute;s de la synth&egrave;se sonore. Pourtant, les instruments actifs ne sont pas aussi diffus&eacute;s que les synth&eacute;tiseurs. En effet, il n'y a pas encore de m&eacute;thodologie et d'outils unifi&eacute;s pour la conception et la fabrication d'instruments hybrides.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le but de ce projet est de d&eacute;velopper des mod&egrave;les, algorithmes et dispositifs permettant la cr&eacute;ation d'instruments actifs optimis&eacute;s, de mani&egrave;re unifi&eacute;e. Les mod&egrave;les int&egrave;grent des &laquo; r&eacute;glages virtuels &raquo; qui sont des param&egrave;tres d&eacute;duits de la connaissance et des r&eacute;glages des fabricants d'instruments. Ceci permet un contr&ocirc;le intuitif par les musiciens ainsi qu'une simplification de la complexit&eacute; de la conception des instruments actifs. La qualit&eacute; de la mod&eacute;lisation des &laquo; r&eacute;glages virtuels &raquo; a &eacute;t&eacute; &eacute;valu&eacute;e &agrave; partir de la synth&egrave;se sonore par mod&egrave;le physique et ensuite incorpor&eacute;e dans les instruments hybrides.</p>\r\n<p>En plus de l'application &agrave; la cr&eacute;ation musicale, ce projet a permis de cr&eacute;er des instruments avec une qualit&eacute; &laquo; r&eacute;glable &raquo; utilisant un traitement num&eacute;rique apr&egrave;s la fabrication.</p>\r\n<p>Il a comport&eacute; un volet de recherche fondamentale, avec des applications &agrave; la cr&eacute;ation musicale, la fabrication des instruments de musique et au domaine du contr&ocirc;le actif.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-11-PDOC-010-01.</p>", "content_en": "<p>During the past 50 years, the sciences and technologies of sound synthesis have made it possible to create and control new sounds from synthesizers. However, hundreds of millions of acoustic instruments are still used worldwide. The interaction with digital keyboards and hearing sound via loudspeakers is poor compared to the subtleties produced by acoustic musical instruments.</p>\r\n<p>A family of innovative musical instruments, called active instruments, has recently been developed. Their principle is based on the use of acoustic instruments controlled by feedback with processing of the sound synthesis, with the goal of extending the sound possibilities of instruments. The final sound is therefore hybrid; it comes from the overlapping of the acoustic or mechanic vibration and its digital processing.</p>\r\n<p>Active instruments have an important advantage over synthesizers: the interface with the musician remains the acoustic instrument while including the possibilities of sound synthesis. However, active instruments are not as widely sold as synthesizers; today there is no unified methodology or tools for the design and creation of active instruments.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The focus of this project is to develop the models, algorithms, and tools necessary for the creation of optimized and unified active instruments. The models will include virtual tuning, the parameters for which are deduced from the knowledge and tuning of instrument makers. This will facilitate an intuitive control by musicians as well as simplify the complexity of the design of active instruments.</p>\r\n<p>In addition to the applications for musical creation, this project made it possible to create \"tunable\" instruments, making use of a digital process post construction. This project includes an aspect of fundamental research with applications for musical creation, construction of musical instruments, and the domain of active control.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-11-PDOC-010-01.</p>", "date_from": "2011-10-01", "date_to": "2014-09-30", "user": null, "type": "external", "external_id": "ANR-11-PDOC-010-01", "program": 1, "program_type": 3, "call": 19, "lead_team": null, "lead_organization": 1, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [8, 9, 3], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 5, "fields": {"keywords_string": "", "site": 1, "title": "Pafi", "title_fr": "Pafi", "title_en": "Pafi", "slug": "pafi", "_meta_title": "", "description": "Plateforme modulaire d'aide \u00e0 la facture Instrumentale", "description_fr": "Plateforme modulaire d'aide \u00e0 la facture Instrumentale", "description_en": "Modular Platform for Assisted Instrument Construction", "gen_description": false, "created": "2016-09-06T13:03:40.704Z", "updated": "2018-07-25T14:48:24.040Z", "status": 2, "publish_date": "2016-09-06T13:03:40Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet a propos&eacute; une d&eacute;marche partenariale ambitieuse et totalement originale entre des laboratoires de recherche, un p&ocirc;le national d'innovation des m&eacute;tiers de la musique et un collectif d'artisans-luthiers agissant au nom d'associations professionnelles de la facture instrumentale, repr&eacute;sentatif du tissu des micro-entreprises fran&ccedil;aises.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Il s'agissait de r&eacute;pondre &agrave; la probl&eacute;matique de la reproduction et de l'optimisation de la conception d'instruments de musique haut de gamme, caract&eacute;ristiques de la lutherie fran&ccedil;aise sur le march&eacute; mondial.</p>\r\n<p>PAFI s'est donc attach&eacute; &agrave; la mise en &oelig;uvre d'outils de caract&eacute;risation et de pr&eacute;diction acoustique d&eacute;di&eacute;s &agrave; l'analyse et au prototypage virtuel des instruments.</p>\r\n<p>Ainsi, ont &eacute;t&eacute; r&eacute;alis&eacute;s la mise au point d'un dispositif exp&eacute;rimental de caract&eacute;risation de la justesse de l'instrument par un dispositif de mesure d'imp&eacute;dance d'entr&eacute;e, le d&eacute;veloppement d'un outil pr&eacute;dictif de justesse, et, dans le cadre de la th&egrave;se de Pauline Eveno, la mise en place d'une m&eacute;thodologie du contr&ocirc;le et de l'innovation avec les facteurs, en s'appuyant sur les outils du module d&eacute;velopp&eacute;s par les autres partenaires et en prospectant vers des outils plus en amont (bancs d'essai tels que des bouches artificielles et les simulations par mod&egrave;le physique des instruments en situation de jeu).</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2008-CORD-016-04.</p>", "content_fr": "<p>Ce projet a propos&eacute; une d&eacute;marche partenariale ambitieuse et totalement originale entre des laboratoires de recherche, un p&ocirc;le national d'innovation des m&eacute;tiers de la musique et un collectif d'artisans-luthiers agissant au nom d'associations professionnelles de la facture instrumentale, repr&eacute;sentatif du tissu des micro-entreprises fran&ccedil;aises.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Il s'agissait de r&eacute;pondre &agrave; la probl&eacute;matique de la reproduction et de l'optimisation de la conception d'instruments de musique haut de gamme, caract&eacute;ristiques de la lutherie fran&ccedil;aise sur le march&eacute; mondial.</p>\r\n<p>PAFI s'est donc attach&eacute; &agrave; la mise en &oelig;uvre d'outils de caract&eacute;risation et de pr&eacute;diction acoustique d&eacute;di&eacute;s &agrave; l'analyse et au prototypage virtuel des instruments.</p>\r\n<p>Ainsi, ont &eacute;t&eacute; r&eacute;alis&eacute;s la mise au point d'un dispositif exp&eacute;rimental de caract&eacute;risation de la justesse de l'instrument par un dispositif de mesure d'imp&eacute;dance d'entr&eacute;e, le d&eacute;veloppement d'un outil pr&eacute;dictif de justesse, et, dans le cadre de la th&egrave;se de Pauline Eveno, la mise en place d'une m&eacute;thodologie du contr&ocirc;le et de l'innovation avec les facteurs, en s'appuyant sur les outils du module d&eacute;velopp&eacute;s par les autres partenaires et en prospectant vers des outils plus en amont (bancs d'essai tels que des bouches artificielles et les simulations par mod&egrave;le physique des instruments en situation de jeu).</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2008-CORD-016-04.</p>", "content_en": "<p>The PAFI project instigated an ambitious and completely new dynamic among research laboratories, a national pole of innovation for the music industry, and a group of instrument makers acting on behalf of professional associations of instrument makers, representative of the French small business culture.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The goal of this project was to overcome the difficulties associated with the reproduction and optimization of high-quality musical instrument design, distinctive of French instrument making.</p>\r\n<p>PAFI aimed to implement tools for characterization as well as mechanical and acoustic prediction for the analysis and creation of prototypes of virtual instruments.</p>\r\n<p>During this project, the IRCAM team implemented an experimental characterization system for the accuracy of instruments via a system that measures the input impedance, the development of a tool that predicts accuracy, and as part of Pauline Eveno&rsquo;s doctoral thesis, the installation of a methodology for control and innovation with instrument-makers using tools based on a model developed by the other project partners (tests such as artificial mouths and simulations via physical models of instruments being played).</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-2008-CORD-016-04.</p>", "date_from": "2008-12-01", "date_to": "2013-05-31", "user": null, "type": "external", "external_id": "ANR-2008-CORD-016-04", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 10, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [12, 1, 13, 11], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 6, "fields": {"keywords_string": "", "site": 1, "title": "Consonnes", "title_fr": "Consonnes", "title_en": "Consonnes", "slug": "consonnes", "_meta_title": "", "description": "Contr\u00f4le des sons instrumentaux naturels et synth\u00e9tiques", "description_fr": "Contr\u00f4le des sons instrumentaux naturels et synth\u00e9tiques", "description_en": "Control of natural and synthetic instrumental sounds", "gen_description": false, "created": "2016-09-06T13:10:09.902Z", "updated": "2018-07-25T14:35:25.040Z", "status": 2, "publish_date": "2016-09-06T13:10:09Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;objectif du projet &eacute;tait d&rsquo;avancer dans la compr&eacute;hension du contr&ocirc;le des instruments de musique r&eacute;els et de leurs mod&egrave;les physiques de synth&egrave;se, en s&rsquo;attachant notamment au lien existant entre les param&egrave;tres de facture et de jeu d&rsquo;une part, les caract&eacute;ristiques physiques et perceptives des sons produits d&rsquo;autre part. Le projet s&rsquo;est int&eacute;ress&eacute; notamment &agrave; l&rsquo;&eacute;tude des transitoires, ph&eacute;nom&egrave;nes les plus d&eacute;licats &agrave; &eacute;tudier et &agrave; mod&eacute;liser, dans le contexte des instruments &agrave; vent.</p>\r\n<p>Les &eacute;quipes de l&rsquo;Ircam participant au projet ont orient&eacute; leurs travaux vers les objectifs suivants :</p>\r\n<ul>\r\n<li>mod&eacute;lisation simplifi&eacute;e des r&eacute;sonateurs d&rsquo;instruments &agrave; vent en vue de leur implantation en temps r&eacute;el et de la mise en &oelig;uvre de fonctions de contr&ocirc;le comme r&eacute;solution de probl&egrave;mes inverses (calcul des variations des param&egrave;tres de jeu pour produire un son enregistr&eacute; donn&eacute;) ;</li>\r\n<li>conception et r&eacute;alisation d&rsquo;un robot musicien, &eacute;volution de la bouche artificielle existante, permettant non seulement d&rsquo;effectuer des mesures reproductibles d&rsquo;instruments &agrave; vent r&eacute;els selon diff&eacute;rents types d&rsquo;embouchures et de modes d&rsquo;excitation, mais susceptibles &eacute;galement d&rsquo;utilisations musicales.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-05_BLAN-0097_02.</p>", "content_fr": "<p>L&rsquo;objectif du projet &eacute;tait d&rsquo;avancer dans la compr&eacute;hension du contr&ocirc;le des instruments de musique r&eacute;els et de leurs mod&egrave;les physiques de synth&egrave;se, en s&rsquo;attachant notamment au lien existant entre les param&egrave;tres de facture et de jeu d&rsquo;une part, les caract&eacute;ristiques physiques et perceptives des sons produits d&rsquo;autre part. Le projet s&rsquo;est int&eacute;ress&eacute; notamment &agrave; l&rsquo;&eacute;tude des transitoires, ph&eacute;nom&egrave;nes les plus d&eacute;licats &agrave; &eacute;tudier et &agrave; mod&eacute;liser, dans le contexte des instruments &agrave; vent.</p>\r\n<p>Les &eacute;quipes de l&rsquo;Ircam participant au projet ont orient&eacute; leurs travaux vers les objectifs suivants :</p>\r\n<ul>\r\n<li>mod&eacute;lisation simplifi&eacute;e des r&eacute;sonateurs d&rsquo;instruments &agrave; vent en vue de leur implantation en temps r&eacute;el et de la mise en &oelig;uvre de fonctions de contr&ocirc;le comme r&eacute;solution de probl&egrave;mes inverses (calcul des variations des param&egrave;tres de jeu pour produire un son enregistr&eacute; donn&eacute;) ;</li>\r\n<li>conception et r&eacute;alisation d&rsquo;un robot musicien, &eacute;volution de la bouche artificielle existante, permettant non seulement d&rsquo;effectuer des mesures reproductibles d&rsquo;instruments &agrave; vent r&eacute;els selon diff&eacute;rents types d&rsquo;embouchures et de modes d&rsquo;excitation, mais susceptibles &eacute;galement d&rsquo;utilisations musicales.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-05_BLAN-0097_02.</p>", "content_en": "<p>This project&rsquo;s goal was to move forward in the comprehension of the control of both real musical instruments and their physical synthesis models, while maintaining the relationship between the rules of instrument making and playing as well as the physical and perceptive characteristics of the sounds made. The project focused on the study of transitions in the context of wind instruments, a phenomenon extremely difficult to study and to model.</p>\r\n<p>The participating IRCAM research teams oriented their work in terms of the following objectives:</p>\r\n<ul>\r\n<li>Simplified modeling of wind instrument resonators so that they can be used in real-time and controlled through the resolution of inverse problems (the calculation of variations of the playing parameters in order to produce a given recorded sound), design and production of a musician-robot.</li>\r\n<li>Development of the existing artificial mouth in order to perform measurements that can be reproduced on real wind instruments with different types of mouthpieces and with different types of excitations, but which can also be used to musical ends as an artificial performer in concert situation.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>rojet reference : ANR-05_BLAN-0097_02.</p>", "date_from": "2005-12-01", "date_to": "2009-06-30", "user": null, "type": "external", "external_id": "ANR-05_BLAN-0097_02", "program": 1, "program_type": 2, "call": null, "lead_team": null, "lead_organization": 6, "website": "http://www.consonnes.cnrs-mrs.fr/", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [1, 4, 8], "organizations": [1, 11], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 7, "fields": {"keywords_string": "", "site": 1, "title": "Format SDIF", "title_fr": "Format SDIF", "title_en": "Format SDIF", "slug": "format-sdif", "_meta_title": "", "description": "Sound Interchange Standard Format", "description_fr": "Sound Interchange Standard Format", "description_en": "Sound Interchange Standard Format", "gen_description": false, "created": "2016-09-06T13:14:50.484Z", "updated": "2018-06-29T11:21:39.220Z", "status": 1, "publish_date": "2016-09-06T13:14:50Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce standard de format de fichier, ind&eacute;pendant des plateformes informatiques, extensible et en acc&egrave;s libre, sp&eacute;cifie tr&egrave;s pr&eacute;cis&eacute;ment les types de donn&eacute;es de description des signaux audio et leur repr&eacute;sentation. Il permet donc &agrave; des logiciels diff&eacute;rents de communiquer imm&eacute;diatement d&egrave;s lors que leurs entr&eacute;es/sorties sont conformes au standard.</p>\r\n<p>Il facilite &eacute;galement la maintenance des fichiers de donn&eacute;es gr&acirc;ce aux informations annexes encapsul&eacute;es dans le fichier, et en permettant &agrave; des donn&eacute;es h&eacute;t&eacute;rog&egrave;nes de coexister dans un seul fichier. Une biblioth&egrave;que de fonctions C de lecture/&eacute;criture, ainsi que des applications ont &eacute;t&eacute; d&eacute;velopp&eacute;es et mises en licence open source.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>, <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Interaction son musique mouvement</a>, <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>Ce standard de format de fichier, ind&eacute;pendant des plateformes informatiques, extensible et en acc&egrave;s libre, sp&eacute;cifie tr&egrave;s pr&eacute;cis&eacute;ment les types de donn&eacute;es de description des signaux audio et leur repr&eacute;sentation. Il permet donc &agrave; des logiciels diff&eacute;rents de communiquer imm&eacute;diatement d&egrave;s lors que leurs entr&eacute;es/sorties sont conformes au standard.</p>\r\n<p>Il facilite &eacute;galement la maintenance des fichiers de donn&eacute;es gr&acirc;ce aux informations annexes encapsul&eacute;es dans le fichier, et en permettant &agrave; des donn&eacute;es h&eacute;t&eacute;rog&egrave;nes de coexister dans un seul fichier. Une biblioth&egrave;que de fonctions C de lecture/&eacute;criture, ainsi que des applications ont &eacute;t&eacute; d&eacute;velopp&eacute;es et mises en licence open source.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>, <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Interaction son musique mouvement</a>, <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>This file format standard, independent from computer platforms, extendable and freely accessible, details very precisely the types of audio signal description data and their representation.Once their inputs and outputs conform to the same standard, it enables different pieces of software to communicate immediately.</p>\r\n<p>It also makes the maintenance of data files much easier thanks to annexed information carried in the file and enables pieces of heterogeneous data to co-exist in one file. A library of reading/writing C functions and applications have been developed and licensed in open source.</p>\r\n<p>IRCAM's Teams: <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Sound Analysis &amp; Synthesis team</a>, <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Sound Music Movement Interaction team</a>, <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 7], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 8, "fields": {"keywords_string": "", "site": 1, "title": "Traitement par Vocodeur de phase", "title_fr": "Traitement par Vocodeur de phase", "title_en": "Processing by Phase Vocoder", "slug": "traitement-par-vocodeur-de-phase", "_meta_title": "", "description": "Techniques performantes pour l\u2019analyse et la transformation des sons", "description_fr": "Techniques performantes pour l\u2019analyse et la transformation des sons", "description_en": "Techniques for the analysis and transformation of sounds", "gen_description": false, "created": "2016-09-06T13:16:32.674Z", "updated": "2018-06-29T09:12:55.249Z", "status": 2, "publish_date": "2016-09-06T13:16:32Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le vocodeur de phase, qui est l&rsquo;une des techniques les plus performantes pour l&rsquo;analyse et la transformation des sons, est la base du logiciel SupervP. Il permet par exemple de transposer, d&rsquo;&eacute;tirer ou de raccourcir des sons, de les filtrer pratiquement sans limitation, etc. Pour la parole &eacute;galement, la qualit&eacute; sonore des signaux transform&eacute;s atteint un excellent niveau. De tr&egrave;s nombreuses am&eacute;liorations et extensions y ont &eacute;t&eacute; apport&eacute;es. Citons par exemple :</p>\r\n<ul>\r\n<li>Le spectre r&eacute;allou&eacute; (reassigned spectrum) ;</li>\r\n<li>L&rsquo;estimation d&rsquo;enveloppe spectrale par &laquo; true envelope &raquo; ;</li>\r\n<li>La transposition avec pr&eacute;servation d&rsquo;enveloppe spectrale ;</li>\r\n<li>La transposition avec mod&egrave;le &laquo; shape invariant &raquo; ;</li>\r\n<li>La synth&egrave;se crois&eacute;e g&eacute;n&eacute;ralis&eacute;e qui permet de synth&eacute;tiser des sons hybrides ;</li>\r\n<li>Plusieurs m&eacute;thodes d&rsquo;estimation de la fr&eacute;quence fondamentale (hauteur) du signal ;</li>\r\n<li>La classification de la nature des pics spectraux, sinuso&iuml;daux (ou vois&eacute;s) ou non-sinuso&iuml;daux (bruits ou non-vois&eacute;s) ;</li>\r\n<li>La segmentation du plan temps-fr&eacute;quence en r&eacute;gions transitoires et non transitoires et le renforcement ou att&eacute;nuation des parties transitoires ;</li>\r\n<li>Le traitement des zones temps-fr&eacute;quence sinuso&iuml;dales, non-sinuso&iuml;dales et transitoires dans les traitements ;</li>\r\n<li>Le mod&egrave;le LF de source glottique permettant de transformer la voix, etc.</li>\r\n</ul>\r\n<p>Ces diff&eacute;rents modules d&rsquo;analyse, de synth&egrave;se et de traitement sont utilis&eacute;s dans plusieurs logiciels commerciaux.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_fr": "<p>Le vocodeur de phase, qui est l&rsquo;une des techniques les plus performantes pour l&rsquo;analyse et la transformation des sons, est la base du logiciel SupervP. Il permet par exemple de transposer, d&rsquo;&eacute;tirer ou de raccourcir des sons, de les filtrer pratiquement sans limitation, etc. Pour la parole &eacute;galement, la qualit&eacute; sonore des signaux transform&eacute;s atteint un excellent niveau. De tr&egrave;s nombreuses am&eacute;liorations et extensions y ont &eacute;t&eacute; apport&eacute;es. Citons par exemple :</p>\r\n<ul>\r\n<li>Le spectre r&eacute;allou&eacute; (reassigned spectrum) ;</li>\r\n<li>L&rsquo;estimation d&rsquo;enveloppe spectrale par &laquo; true envelope &raquo; ;</li>\r\n<li>La transposition avec pr&eacute;servation d&rsquo;enveloppe spectrale ;</li>\r\n<li>La transposition avec mod&egrave;le &laquo; shape invariant &raquo; ;</li>\r\n<li>La synth&egrave;se crois&eacute;e g&eacute;n&eacute;ralis&eacute;e qui permet de synth&eacute;tiser des sons hybrides ;</li>\r\n<li>Plusieurs m&eacute;thodes d&rsquo;estimation de la fr&eacute;quence fondamentale (hauteur) du signal ;</li>\r\n<li>La classification de la nature des pics spectraux, sinuso&iuml;daux (ou vois&eacute;s) ou non-sinuso&iuml;daux (bruits ou non-vois&eacute;s) ;</li>\r\n<li>La segmentation du plan temps-fr&eacute;quence en r&eacute;gions transitoires et non transitoires et le renforcement ou att&eacute;nuation des parties transitoires ;</li>\r\n<li>Le traitement des zones temps-fr&eacute;quence sinuso&iuml;dales, non-sinuso&iuml;dales et transitoires dans les traitements ;</li>\r\n<li>Le mod&egrave;le LF de source glottique permettant de transformer la voix, etc.</li>\r\n</ul>\r\n<p>Ces diff&eacute;rents modules d&rsquo;analyse, de synth&egrave;se et de traitement sont utilis&eacute;s dans plusieurs logiciels commerciaux.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_en": "<p>The phase vocoder, one of the most effective techniques for the analysis and transformation of sounds, represents the foundation of the SupervP software program. With the phase vocoder, it is possible to transpose, stretch, or shorten sounds; it is possible to apply a practically limitless number of filters to sounds. By the same token, the level of sound quality of the transformed signals is extremely high when applied to speech. Numerous improvements and extensions have been introduced, for example:</p>\r\n<ul>\r\n<li>Reassigned spectrum</li>\r\n<li>Estimation of the spectral envelope via &lsquo;true envelope&rsquo; transposition with the preservation of the spectral envelope transposition with the &lsquo;shape invariant&rsquo; model</li>\r\n<li>Generalized cross synthesis enabling the synthesis of hybrid sounds</li>\r\n<li>Several methods for estimating the fundamental frequency (pitch) of a signal</li>\r\n<li>Classification by nature of the spectral, sinusoidal (voiced) or non-sinusoidal (non-voiced sounds or noises) peaks segmentation of the time/frequency zones into transitory and non-transitory regions and the increase or decrease of transitory sections</li>\r\n<li>Processing the sinusoidal, non-sinusoidal, and transitory time/frequency zones</li>\r\n<li>The LF model of a glottal source, making it possible to transform a voice, etc.</li>\r\n</ul>\r\n<p>These different modules of analysis, synthesis, and processing are used in several software programs on the market today.</p>\r\n<p>IRCAM's team: <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Sound Analysis &amp; Synthesis team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 9, "fields": {"keywords_string": "", "site": 1, "title": "Synth\u00e8se concat\u00e9native par corpus", "title_fr": "Synth\u00e8se concat\u00e9native par corpus", "title_en": "Corpus-Based Concatenative Synthesis", "slug": "synthese-concatenative-par-corpus", "_meta_title": "", "description": "Base de donn\u00e9es de sons enregistr\u00e9s, segment\u00e9s et index\u00e9s par des descripteurs sonores", "description_fr": "Base de donn\u00e9es de sons enregistr\u00e9s, segment\u00e9s et index\u00e9s par des descripteurs sonores", "description_en": "Database of recorded sounds and a unit selection algorithm", "gen_description": false, "created": "2016-09-06T15:15:13.917Z", "updated": "2018-06-29T09:13:08.817Z", "status": 2, "publish_date": "2016-09-06T15:15:13Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La synth&egrave;se concat&eacute;native par corpus utilise une base de donn&eacute;es de sons enregistr&eacute;s, segment&eacute;s et index&eacute;s par des descripteurs sonores. Cette base, nomm&eacute;e corpus, est exploit&eacute;e par un algorithme de s&eacute;lection d&rsquo;unit&eacute;s qui choisit les segments du corpus qui conviennent le mieux pour la s&eacute;quence musicale que l&rsquo;on souhaite synth&eacute;tiser par concat&eacute;nation. La s&eacute;lection est fond&eacute;e sur les descripteurs sonores qui caract&eacute;risent les enregistrements, obtenus par analyse du signal et correspondant par exemple &agrave; la hauteur, &agrave; l&rsquo;&eacute;nergie ou au spectre.</p>\r\n<p>Les m&eacute;thodes de synth&egrave;se musicale habituelles sont fond&eacute;es sur un mod&egrave;le du signal sonore, mais il est tr&egrave;s difficile d&rsquo;&eacute;tablir un mod&egrave;le qui pr&eacute;serverait la totalit&eacute; des d&eacute;tails et de la finesse du son. En revanche, la synth&egrave;se concat&eacute;native, qui utilise des enregistrements r&eacute;els, pr&eacute;serve ces d&eacute;tails. La mise en &oelig;uvre de la nouvelle approche de synth&egrave;se sonore concat&eacute;native par corpus en temps r&eacute;el permet une exploration interactive d&rsquo;une base sonore et une composition granulaire cibl&eacute;e par des caract&eacute;ristiques sonores pr&eacute;cises, et permet aux compositeurs et musiciens d&rsquo;atteindre de nouvelles sonorit&eacute;s. Si la position cible de la synth&egrave;se est obtenue par analyse d&rsquo;un signal audio en entr&eacute;e, on parle alors d&rsquo;audio mosaicing. Ce principe est par exemple r&eacute;alis&eacute; dans le syst&egrave;me CataRT, qui permet l&rsquo;affichage d&rsquo;une projection 2D de l&rsquo;espace des descripteurs, par une navigation simple avec la souris, par des contr&ocirc;leurs externes ou par l&rsquo;analyse d&rsquo;un signal audio. CataRT, comme biblioth&egrave;que de modules pour Max ou comme application ind&eacute;pendante, est utilis&eacute; dans des contextes musicaux de composition, de performance et d&rsquo;installation sonore vari&eacute;s. La biblioth&egrave;que MuBu de modules optimis&eacute;s pour Max, permet &eacute;galement une grande vari&eacute;t&eacute; d&rsquo;applications de synth&egrave;se par corpus et d&rsquo;audio mosaicing par similarit&eacute; spectrale, associ&eacute;es &agrave; des entr&eacute;es audio ou gestuels.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Interaction son musique mouvement</a>.</p>", "content_fr": "<p>La synth&egrave;se concat&eacute;native par corpus utilise une base de donn&eacute;es de sons enregistr&eacute;s, segment&eacute;s et index&eacute;s par des descripteurs sonores. Cette base, nomm&eacute;e corpus, est exploit&eacute;e par un algorithme de s&eacute;lection d&rsquo;unit&eacute;s qui choisit les segments du corpus qui conviennent le mieux pour la s&eacute;quence musicale que l&rsquo;on souhaite synth&eacute;tiser par concat&eacute;nation. La s&eacute;lection est fond&eacute;e sur les descripteurs sonores qui caract&eacute;risent les enregistrements, obtenus par analyse du signal et correspondant par exemple &agrave; la hauteur, &agrave; l&rsquo;&eacute;nergie ou au spectre.</p>\r\n<p>Les m&eacute;thodes de synth&egrave;se musicale habituelles sont fond&eacute;es sur un mod&egrave;le du signal sonore, mais il est tr&egrave;s difficile d&rsquo;&eacute;tablir un mod&egrave;le qui pr&eacute;serverait la totalit&eacute; des d&eacute;tails et de la finesse du son. En revanche, la synth&egrave;se concat&eacute;native, qui utilise des enregistrements r&eacute;els, pr&eacute;serve ces d&eacute;tails. La mise en &oelig;uvre de la nouvelle approche de synth&egrave;se sonore concat&eacute;native par corpus en temps r&eacute;el permet une exploration interactive d&rsquo;une base sonore et une composition granulaire cibl&eacute;e par des caract&eacute;ristiques sonores pr&eacute;cises, et permet aux compositeurs et musiciens d&rsquo;atteindre de nouvelles sonorit&eacute;s. Si la position cible de la synth&egrave;se est obtenue par analyse d&rsquo;un signal audio en entr&eacute;e, on parle alors d&rsquo;audio mosaicing. Ce principe est par exemple r&eacute;alis&eacute; dans le syst&egrave;me CataRT, qui permet l&rsquo;affichage d&rsquo;une projection 2D de l&rsquo;espace des descripteurs, par une navigation simple avec la souris, par des contr&ocirc;leurs externes ou par l&rsquo;analyse d&rsquo;un signal audio. CataRT, comme biblioth&egrave;que de modules pour Max ou comme application ind&eacute;pendante, est utilis&eacute; dans des contextes musicaux de composition, de performance et d&rsquo;installation sonore vari&eacute;s. La biblioth&egrave;que MuBu de modules optimis&eacute;s pour Max, permet &eacute;galement une grande vari&eacute;t&eacute; d&rsquo;applications de synth&egrave;se par corpus et d&rsquo;audio mosaicing par similarit&eacute; spectrale, associ&eacute;es &agrave; des entr&eacute;es audio ou gestuels.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Interaction son musique mouvement</a>.</p>", "content_en": "<p>Corpus-based concatenative synthesis uses a database of recorded sounds and a unit selection algorithm that chooses the segments from the database that best suit the musical sequence that we would like to synthesize by concatenation. The selection is based on the characteristics of the recording obtained through signal analysis and match, for example, the pitch, energy, or spectrum.</p>\r\n<p>The habitual methods for musical synthesis are based on a model of a sound signal, but it is very difficult to establish a model that conserves the entirety of the details and delicacy of the sound. However, concatenative synthesis&mdash;that uses real recordings&mdash;preserves these details. Putting the new approach for concatenative synthesis by corpus in real-time in place enables an interactive exploration of a sound database and a granular composition that targets specific sound characteristics. It also makes it possible for composers and musicians to reach new sounds. This principle is carried out in the CataRT system. This <br />system makes it possible to display a 2D projection of the descriptor space that can be browsed using a mouse or external controllers. Grains are then selected in the original recording and performed by geometric proximity, metronome, in loops, or continuously. It is also possible to define a perimeter around one&rsquo;s present position that selects a sub-group of grains that are then played randomly. CataRT is used for musical composition, performance, and in various sound installations. As this field of research is fairly young, several interesting research questions have been raised (or will be raised in the future) concerning the analysis and exploitation of the information found in the data of a corpus, the visualization, and real-time interaction.</p>\r\n<p>IRCAM's team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Sound Music Movement Interaction team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 10, "fields": {"keywords_string": "", "site": 1, "title": "Physis", "title_fr": "Physis", "title_en": "Physis", "slug": "physis", "_meta_title": "", "description": "Mod\u00e9lisation, transformation et synth\u00e8se de sons pour les mondes virtuels interactifs", "description_fr": "Mod\u00e9lisation, transformation et synth\u00e8se de sons pour les mondes virtuels interactifs", "description_en": "Modeling, Transformation, and Synthesis of Sounds for Interactive Virtual Worlds", "gen_description": false, "created": "2016-09-06T15:16:50.795Z", "updated": "2018-07-25T14:48:53.568Z", "status": 2, "publish_date": "2016-09-06T15:16:50Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Physis est un projet de recherche industriel centr&eacute; sur la mod&eacute;lisation, la transformation et la synth&egrave;se des sons di&eacute;g&eacute;tiques pour les mondes virtuels interactifs (jeux vid&eacute;o, simulateurs, serious games) et la r&eacute;alit&eacute; augment&eacute;e. Par sons di&eacute;g&eacute;tiques, nous entendons tous les sons g&eacute;n&eacute;r&eacute;s par des objets identifiables dans la sc&egrave;ne virtuelle (par exemple les bruits d&rsquo;armes, de liquides, de feu, d&rsquo;eau, de tissus, etc.) et leurs interactions possibles : impacts physiques, frottements, glissements, roulements...</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Physis consid&egrave;re la production de contenu sonore interactif dans son ensemble et de fa&ccedil;on syst&eacute;mique. Il couvre en effet la totalit&eacute; des &eacute;tapes n&eacute;cessaires &agrave; la r&eacute;ussite d&rsquo;un tel challenge : depuis la recherche fondamentale indispensable pour une bonne mod&eacute;lisation des ph&eacute;nom&egrave;nes sonores, jusqu&rsquo;&agrave; la production de code embarquable dans des consoles de jeu ou du mat&eacute;riel sp&eacute;cifique. Physis pr&eacute;voit &eacute;galement la cr&eacute;ation d&rsquo;outils utilisables par des sound designers, l&rsquo;analyse et la transformation de fichiers sonores, la cr&eacute;ation de contr&ocirc;les s&eacute;mantiques et physiques de haut niveau ainsi que leur mise en situation interactive. Les principaux r&eacute;sultats du projet ont conduit &agrave;&nbsp; :</p>\r\n<ul>\r\n<li>des avanc&eacute;es significatives dans la mod&eacute;lisation des propri&eacute;t&eacute;s acoustiques des sons du corpus cibl&eacute; ;</li>\r\n<li>des mod&egrave;les de synth&egrave;se et de nouvelles strat&eacute;gies destin&eacute;s &agrave; cr&eacute;er et transformer les sons de fa&ccedil;on interactive avec des commandes s&eacute;mantiques et/ou physiques ;</li>\r\n<li>des d&eacute;monstrateurs technologiques qui mettent en avant ces innovations.</li>\r\n</ul>\r\n<p>L&rsquo;&eacute;mergence r&eacute;cente de jeux vid&eacute;o complexes et des univers virtuels, comme &laquo; Second Life &raquo;, a fait appara&icirc;tre les limites des moteurs son actuels, qui utilisent des sons pr&eacute;enregistr&eacute;s alors que l&rsquo;image de synth&egrave;se est, elle, calcul&eacute;e en temps r&eacute;el. Par ailleurs, l&rsquo;utilisation de mod&egrave;les physiques permet un comportement graphique plus r&eacute;aliste, plus complexe et plus vari&eacute;, mais ces derniers n&rsquo;ont qu&rsquo;une faible incidence sur les comportements sonores bas&eacute;s sur des fichiers pr&eacute;enregistr&eacute;s. Or, la mont&eacute;e en puissance du mat&eacute;riel a rendu possible la simulation pr&eacute;cise des propri&eacute;t&eacute;s audio et acoustiques des bruits quotidiens bas&eacute;s sur des param&egrave;tres physiques.</p>\r\n<p>De plus, de nouvelles interfaces sont maintenant incluses dans les smartphones, tablettes, consoles de jeux vid&eacute;o et sont en train de permettre une r&eacute;volution dans la fa&ccedil;on dont nous acc&eacute;dons &agrave; l&rsquo;information num&eacute;rique. Ces dispositifs ont sous-exploit&eacute;s d&rsquo;un point de vue sonore car la lecture de sons pr&eacute;enregistr&eacute;s ne permet pas une interaction correcte avec ce type d&rsquo;interface. La synth&egrave;se audio en temps r&eacute;el est ainsi parfaitement adapt&eacute;e &agrave; ces nouvelles interfaces et aux usages qui en d&eacute;coulent.</p>\r\n<p>En conclusion, Physis a permis de cr&eacute;er une base scientifique et technologique solide pour r&eacute;pondre &agrave; l&rsquo;ensemble de ces nouveaux besoins.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2012-CORD-006-03.</p>", "content_fr": "<p>Physis est un projet de recherche industriel centr&eacute; sur la mod&eacute;lisation, la transformation et la synth&egrave;se des sons di&eacute;g&eacute;tiques pour les mondes virtuels interactifs (jeux vid&eacute;o, simulateurs, serious games) et la r&eacute;alit&eacute; augment&eacute;e. Par sons di&eacute;g&eacute;tiques, nous entendons tous les sons g&eacute;n&eacute;r&eacute;s par des objets identifiables dans la sc&egrave;ne virtuelle (par exemple les bruits d&rsquo;armes, de liquides, de feu, d&rsquo;eau, de tissus, etc.) et leurs interactions possibles : impacts physiques, frottements, glissements, roulements...</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Physis consid&egrave;re la production de contenu sonore interactif dans son ensemble et de fa&ccedil;on syst&eacute;mique. Il couvre en effet la totalit&eacute; des &eacute;tapes n&eacute;cessaires &agrave; la r&eacute;ussite d&rsquo;un tel challenge : depuis la recherche fondamentale indispensable pour une bonne mod&eacute;lisation des ph&eacute;nom&egrave;nes sonores, jusqu&rsquo;&agrave; la production de code embarquable dans des consoles de jeu ou du mat&eacute;riel sp&eacute;cifique. Physis pr&eacute;voit &eacute;galement la cr&eacute;ation d&rsquo;outils utilisables par des sound designers, l&rsquo;analyse et la transformation de fichiers sonores, la cr&eacute;ation de contr&ocirc;les s&eacute;mantiques et physiques de haut niveau ainsi que leur mise en situation interactive. Les principaux r&eacute;sultats du projet ont conduit &agrave;&nbsp; :</p>\r\n<ul>\r\n<li>des avanc&eacute;es significatives dans la mod&eacute;lisation des propri&eacute;t&eacute;s acoustiques des sons du corpus cibl&eacute; ;</li>\r\n<li>des mod&egrave;les de synth&egrave;se et de nouvelles strat&eacute;gies destin&eacute;s &agrave; cr&eacute;er et transformer les sons de fa&ccedil;on interactive avec des commandes s&eacute;mantiques et/ou physiques ;</li>\r\n<li>des d&eacute;monstrateurs technologiques qui mettent en avant ces innovations.</li>\r\n</ul>\r\n<p>L&rsquo;&eacute;mergence r&eacute;cente de jeux vid&eacute;o complexes et des univers virtuels, comme &laquo; Second Life &raquo;, a fait appara&icirc;tre les limites des moteurs son actuels, qui utilisent des sons pr&eacute;enregistr&eacute;s alors que l&rsquo;image de synth&egrave;se est, elle, calcul&eacute;e en temps r&eacute;el. Par ailleurs, l&rsquo;utilisation de mod&egrave;les physiques permet un comportement graphique plus r&eacute;aliste, plus complexe et plus vari&eacute;, mais ces derniers n&rsquo;ont qu&rsquo;une faible incidence sur les comportements sonores bas&eacute;s sur des fichiers pr&eacute;enregistr&eacute;s. Or, la mont&eacute;e en puissance du mat&eacute;riel a rendu possible la simulation pr&eacute;cise des propri&eacute;t&eacute;s audio et acoustiques des bruits quotidiens bas&eacute;s sur des param&egrave;tres physiques.</p>\r\n<p>De plus, de nouvelles interfaces sont maintenant incluses dans les smartphones, tablettes, consoles de jeux vid&eacute;o et sont en train de permettre une r&eacute;volution dans la fa&ccedil;on dont nous acc&eacute;dons &agrave; l&rsquo;information num&eacute;rique. Ces dispositifs ont sous-exploit&eacute;s d&rsquo;un point de vue sonore car la lecture de sons pr&eacute;enregistr&eacute;s ne permet pas une interaction correcte avec ce type d&rsquo;interface. La synth&egrave;se audio en temps r&eacute;el est ainsi parfaitement adapt&eacute;e &agrave; ces nouvelles interfaces et aux usages qui en d&eacute;coulent.</p>\r\n<p>En conclusion, Physis a permis de cr&eacute;er une base scientifique et technologique solide pour r&eacute;pondre &agrave; l&rsquo;ensemble de ces nouveaux besoins.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2012-CORD-006-03.</p>", "content_en": "<p>Physis is an industrial research project centered on modeling, transforming, and a synthesizing diegetical sounds for interactive virtual worlds (video games, simulators, serious games) and for augmented reality. By diegetical sounds, we mean sounds created by identifiable objects in a virtual scene such as sounds made by weapons, liquids, fire, water, or fabrics, and their possible interactions including physical impacts, rubbing, sliding, and rolling.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>Physis considered the production of interactive sound contents in its entirety and in a systematic manner. It covered all steps necessary to meet the challenge: from fundamental research essential for the proper modeling of sound phenomena, to the production of portable code for game consoles or specific material. Physis also anticipated the creation of tools for sound designers, for the analysis and transformation of sound files, the creation of high-level semantic and physical controls as well as their implementation in an interactive situation. The major findings of this project led to:</p>\r\n<ul>\r\n<li>Significant advances in modeling acoustic properties of sounds in a target corpus</li>\r\n<li>Synthesis models and new strategies intended for the creation and transformation of sounds interactively with semantic and/or physical controls</li>\r\n<li>Technological demonstrators that showcase these innovations.</li>\r\n</ul>\r\n<p>The recent surfacing of complex video games and virtual universes like \"Second Life\" made apparent the limits of existing sound engines that use pre-recorded sounds with an image that is computed in real-time. Moreover, while the use of physical models enables a more realistic, more complex, and more varied graphical behavior, they have only a slight impact on the sound behaviors based on pre-recorded files. Improvements in computer materials have enabled a precise simulation of the audio and acoustic properties of everyday noises based on physical parameters.</p>\r\n<p>In addition, new interfaces now included in smartphones, tablets, and video game consoles are changing the way we access digital information. These systems are underused from a sound point of view for the reason that reading prerecorded sounds prevents correct interaction with this type of interface. Audio synthesis in real-time is perfectly adapted to these new interfaces and to the uses they imply.</p>\r\n<p>In conclusion, PHySIS made it possible to create a solid scientific and technological foundation that replied to these new needs.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-2012-CORD-006-03.</p>", "date_from": "2012-04-01", "date_to": "2015-04-30", "user": null, "type": "external", "external_id": "ANR-2012-CORD-006-03", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 14, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 7], "organizations": [6, 15, 1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 11, "fields": {"keywords_string": "", "site": 1, "title": "Sample Orchestrator 2", "title_fr": "Sample Orchestrator 2", "title_en": "Sample Orchestrator 2", "slug": "sample-orchestrator-2", "_meta_title": "", "description": "Constitution de fonctions nouvelles destin\u00e9es aux \u00e9chantillonneurs logiciels de nouvelle g\u00e9n\u00e9ration", "description_fr": "Constitution de fonctions nouvelles destin\u00e9es aux \u00e9chantillonneurs logiciels de nouvelle g\u00e9n\u00e9ration", "description_en": "Create innovative functions intended for a new generation of software samplers", "gen_description": false, "created": "2016-09-06T15:32:03.664Z", "updated": "2018-06-29T10:22:04.835Z", "status": 2, "publish_date": "2016-09-06T15:32:03Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Cette suite du projet Sample Orchestrator a vis&eacute; la constitution de fonctions nouvelles destin&eacute;es aux &eacute;chantillonneurs logiciels de nouvelle g&eacute;n&eacute;ration, selon trois aspects compl&eacute;mentaires :</p>\r\n<ul>\r\n<li style=\"text-align: justify;\">Techniques hybrides de synth&egrave;se sonore en temps r&eacute;el, interm&eacute;diaires entre mod&egrave;les de signaux con&ccedil;us pour tous types de sons et sons &eacute;chantillonn&eacute;s et b&eacute;n&eacute;ficiant des variations rendues possibles par la param&eacute;trisation des premiers et de l&rsquo;efficacit&eacute; des seconds. Il s&rsquo;agit plus particuli&egrave;rement de d&eacute;gager des mod&egrave;les sp&eacute;cifiques &agrave; chaque famille d&rsquo;instruments ;</li>\r\n<li style=\"text-align: justify;\">Techniques hybrides de spatialisation sonore en temps r&eacute;el, interm&eacute;diaires entre les mod&egrave;les param&eacute;triques tels que celui du Spat de l&rsquo;Ircam, et la convolution des signaux par des r&eacute;ponses impulsionnelles mesur&eacute;es dans des salles. Ici encore, l&rsquo;enjeu est de constituer des mod&egrave;les repr&eacute;sentant les meilleurs compromis en termes, d&rsquo;une part, de variabilit&eacute; et qualit&eacute;, d&rsquo;autre part, d&rsquo;efficacit&eacute; de calcul ;</li>\r\n<li style=\"text-align: justify;\">M&eacute;thodes de voicing et d&rsquo;orchestration en temps r&eacute;el, fournissant une extension du jeu instrumental en fonction de m&eacute;thodes d&rsquo;orchestration mod&eacute;lis&eacute;es et/ou apprises dans diff&eacute;rents corpus musicaux.</li>\r\n</ul>\r\n<p>L&rsquo;ensemble des objectifs du projet se situait au-del&agrave; de l&rsquo;&eacute;tat de l&rsquo;art de la recherche et le projet, par l&rsquo;&eacute;troite synergie qu&rsquo;il a mis en &oelig;uvre entre les diff&eacute;rentes &eacute;quipes de l&rsquo;Ircam et partenaires ext&eacute;rieurs, a produit des avanc&eacute;es importantes dans les champs de la recherche et des technologies musicales (mod&eacute;lisation des instruments, nouvelles techniques de spatialisation et analyse/synth&egrave;se des champs sonores, synth&egrave;se g&eacute;n&eacute;rative &agrave; partir de corpus musicaux).</p>", "content_fr": "<p>Cette suite du projet Sample Orchestrator a vis&eacute; la constitution de fonctions nouvelles destin&eacute;es aux &eacute;chantillonneurs logiciels de nouvelle g&eacute;n&eacute;ration, selon trois aspects compl&eacute;mentaires :</p>\r\n<ul>\r\n<li style=\"text-align: justify;\">Techniques hybrides de synth&egrave;se sonore en temps r&eacute;el, interm&eacute;diaires entre mod&egrave;les de signaux con&ccedil;us pour tous types de sons et sons &eacute;chantillonn&eacute;s et b&eacute;n&eacute;ficiant des variations rendues possibles par la param&eacute;trisation des premiers et de l&rsquo;efficacit&eacute; des seconds. Il s&rsquo;agit plus particuli&egrave;rement de d&eacute;gager des mod&egrave;les sp&eacute;cifiques &agrave; chaque famille d&rsquo;instruments ;</li>\r\n<li style=\"text-align: justify;\">Techniques hybrides de spatialisation sonore en temps r&eacute;el, interm&eacute;diaires entre les mod&egrave;les param&eacute;triques tels que celui du Spat de l&rsquo;Ircam, et la convolution des signaux par des r&eacute;ponses impulsionnelles mesur&eacute;es dans des salles. Ici encore, l&rsquo;enjeu est de constituer des mod&egrave;les repr&eacute;sentant les meilleurs compromis en termes, d&rsquo;une part, de variabilit&eacute; et qualit&eacute;, d&rsquo;autre part, d&rsquo;efficacit&eacute; de calcul ;</li>\r\n<li style=\"text-align: justify;\">M&eacute;thodes de voicing et d&rsquo;orchestration en temps r&eacute;el, fournissant une extension du jeu instrumental en fonction de m&eacute;thodes d&rsquo;orchestration mod&eacute;lis&eacute;es et/ou apprises dans diff&eacute;rents corpus musicaux.</li>\r\n</ul>\r\n<p>L&rsquo;ensemble des objectifs du projet se situait au-del&agrave; de l&rsquo;&eacute;tat de l&rsquo;art de la recherche et le projet, par l&rsquo;&eacute;troite synergie qu&rsquo;il a mis en &oelig;uvre entre les diff&eacute;rentes &eacute;quipes de l&rsquo;Ircam et partenaires ext&eacute;rieurs, a produit des avanc&eacute;es importantes dans les champs de la recherche et des technologies musicales (mod&eacute;lisation des instruments, nouvelles techniques de spatialisation et analyse/synth&egrave;se des champs sonores, synth&egrave;se g&eacute;n&eacute;rative &agrave; partir de corpus musicaux).</p>", "content_en": "<p>This follow-up to the Sample Orchestrator project aimed to create innovative functions intended for a new generation of software samplers, in accordance with three complementary aspects:</p>\r\n<ul>\r\n<li>Hybrid techniques for real-time sound synthesis, intermediaries between models of signals designed for all types of sounds and samples, and taking advantage of variations made possible by the definition of parameters of the former and the effectiveness of the latter. The goal is to have specific models for each family of instruments.</li>\r\n<li>Hybrid techniques for real-time sound spatialization, intermediaries between the parametric models such as IRCAM&rsquo;s Spat and the convolution of signals via measured concert hall impulsion responses. Here again, the issue is to create models that represent the best compromise in terms of variability and quality on one hand, and the efficiency of calculations on the other.</li>\r\n<li>Real-time methods for voicing and orchestration, providing an extension of the musical performance in function of orchestration methods modeled and/or learned in different musical corpora.</li>\r\n</ul>\r\n<p>The project&rsquo;s objectives lay beyond the then-current state of research and the project, via the synergy it created among different teams at IRCAM and with external partners, made important advances the domains of research and musical technologies including signal models of instruments, new techniques for spatialization and analysis/synthesis of sound fields, generative synthesis from a musical corpus.</p>", "date_from": "2010-11-01", "date_to": "2013-10-31", "user": null, "type": "external", "external_id": "ANR-2010-CORD-018-01", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 1, "website": "http://sor2.ircam.fr/", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 2, 7, 5], "organizations": [17, 16], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 12, "fields": {"keywords_string": "", "site": 1, "title": "Topophonie", "title_fr": "Topophonie", "title_en": "Topophonie", "slug": "topophonie", "_meta_title": "", "description": "Espaces virtuels navigables", "description_fr": "Espaces virtuels navigables", "description_en": "Virtual navigable sound spaces", "gen_description": false, "created": "2016-09-06T16:02:04.803Z", "updated": "2018-07-25T14:51:02.310Z", "status": 2, "publish_date": "2016-09-06T16:02:04Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Nous nommons topophonies des espaces virtuels navigables compos&eacute;s d&rsquo;un ensemble d&rsquo;objets sonores et/ou audiographiques.</p>\r\n<p>Le terme audiographique d&eacute;signe des formes graphiques et sonores dans lesquelles les modalit&eacute;s visuelle et sonore sont synchronis&eacute;es. On sait bien rendre des sc&egrave;nes compos&eacute;es d&rsquo;&eacute;l&eacute;ments graphiques et sonores ponctuels (points, objets), en r&eacute;alit&eacute; virtuelle et dans les jeux vid&eacute;o. En revanche, il n&rsquo;y a pas d&rsquo;outil permettant la navigation et le rendu interactif de sc&egrave;nes comportant des &eacute;l&eacute;ments visuels et sonores en tr&egrave;s grands nombres et dispers&eacute;s tels qu&rsquo;une foule, un flux de circulation automobile, un hall de machines, un feuillage ou une pluie.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le projet de recherche Topophonie a propos&eacute; des directions de recherche et de d&eacute;veloppement innovantes pour la navigation sonore et visuelle dans des espaces compos&eacute;s d&rsquo;&eacute;l&eacute;ments sonores et visuels multiples et diss&eacute;min&eacute;s. En faisant travailler une &eacute;quipe scientifique pluridisciplinaire (audio num&eacute;rique, image de synth&egrave;se, design sonore) et des entreprises sp&eacute;cialis&eacute;es dans le domaine des rendus multim&eacute;dias interactifs, le projet Topophonie con&ccedil;oit et d&eacute;veloppe des mod&egrave;les, des interfaces et des rendus audiographiques navigables d&rsquo;ensembles d&rsquo;objets granulaires, anim&eacute;s et spatialis&eacute;s.</p>\r\n<p>L&rsquo;&eacute;quipe du projet est compos&eacute;e de chercheurs sp&eacute;cialis&eacute;s en rendu sonore granulaire et en rendu graphique avanc&eacute; interactif, de designers num&eacute;riques et d&rsquo;entreprises sp&eacute;cialis&eacute;es dans les domaines d&rsquo;applications concern&eacute;s.</p>\r\n<p>Les travaux r&eacute;alis&eacute;s fournissent des interfaces de d&eacute;finition et de contr&ocirc;le de sc&egrave;nes multim&eacute;dias et des outils de rendu temps r&eacute;el sur les canaux audio et visuels synchronis&eacute;s. Les premi&egrave;res r&eacute;alisations &eacute;taient l&rsquo;installation de r&eacute;alit&eacute; augment&eacute;e audio Topophonie Mobile du festival Futur en Seine, permettant une balade g&eacute;olocalis&eacute;e dans un parc public augment&eacute; par une ambiance acoustique autour du th&egrave;me de l&rsquo;eau avec l&rsquo;application Navidium de cartographie num&eacute;rique interactive audiographique. Topophonie Mobile a re&ccedil;u le Grand Prix de l&rsquo;Innovation de la ville de Paris 2013 (mention sp&eacute;ciale Design).</p>\r\n<p>Les autres points forts de la recherche sont la conception d&rsquo;une nouvelle m&eacute;thode de synth&egrave;se de textures sonores, et la diffusion des savoirs en deux workshops internationaux sur la mod&eacute;lisation audiographique, organis&eacute;s par le projet en 2011.&nbsp;</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2009-CORD-022-03.</p>", "content_fr": "<p>Nous nommons topophonies des espaces virtuels navigables compos&eacute;s d&rsquo;un ensemble d&rsquo;objets sonores et/ou audiographiques.</p>\r\n<p>Le terme audiographique d&eacute;signe des formes graphiques et sonores dans lesquelles les modalit&eacute;s visuelle et sonore sont synchronis&eacute;es. On sait bien rendre des sc&egrave;nes compos&eacute;es d&rsquo;&eacute;l&eacute;ments graphiques et sonores ponctuels (points, objets), en r&eacute;alit&eacute; virtuelle et dans les jeux vid&eacute;o. En revanche, il n&rsquo;y a pas d&rsquo;outil permettant la navigation et le rendu interactif de sc&egrave;nes comportant des &eacute;l&eacute;ments visuels et sonores en tr&egrave;s grands nombres et dispers&eacute;s tels qu&rsquo;une foule, un flux de circulation automobile, un hall de machines, un feuillage ou une pluie.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le projet de recherche Topophonie a propos&eacute; des directions de recherche et de d&eacute;veloppement innovantes pour la navigation sonore et visuelle dans des espaces compos&eacute;s d&rsquo;&eacute;l&eacute;ments sonores et visuels multiples et diss&eacute;min&eacute;s. En faisant travailler une &eacute;quipe scientifique pluridisciplinaire (audio num&eacute;rique, image de synth&egrave;se, design sonore) et des entreprises sp&eacute;cialis&eacute;es dans le domaine des rendus multim&eacute;dias interactifs, le projet Topophonie con&ccedil;oit et d&eacute;veloppe des mod&egrave;les, des interfaces et des rendus audiographiques navigables d&rsquo;ensembles d&rsquo;objets granulaires, anim&eacute;s et spatialis&eacute;s.</p>\r\n<p>L&rsquo;&eacute;quipe du projet est compos&eacute;e de chercheurs sp&eacute;cialis&eacute;s en rendu sonore granulaire et en rendu graphique avanc&eacute; interactif, de designers num&eacute;riques et d&rsquo;entreprises sp&eacute;cialis&eacute;es dans les domaines d&rsquo;applications concern&eacute;s.</p>\r\n<p>Les travaux r&eacute;alis&eacute;s fournissent des interfaces de d&eacute;finition et de contr&ocirc;le de sc&egrave;nes multim&eacute;dias et des outils de rendu temps r&eacute;el sur les canaux audio et visuels synchronis&eacute;s. Les premi&egrave;res r&eacute;alisations &eacute;taient l&rsquo;installation de r&eacute;alit&eacute; augment&eacute;e audio Topophonie Mobile du festival Futur en Seine, permettant une balade g&eacute;olocalis&eacute;e dans un parc public augment&eacute; par une ambiance acoustique autour du th&egrave;me de l&rsquo;eau avec l&rsquo;application Navidium de cartographie num&eacute;rique interactive audiographique. Topophonie Mobile a re&ccedil;u le Grand Prix de l&rsquo;Innovation de la ville de Paris 2013 (mention sp&eacute;ciale Design).</p>\r\n<p>Les autres points forts de la recherche sont la conception d&rsquo;une nouvelle m&eacute;thode de synth&egrave;se de textures sonores, et la diffusion des savoirs en deux workshops internationaux sur la mod&eacute;lisation audiographique, organis&eacute;s par le projet en 2011.&nbsp;</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2009-CORD-022-03.</p>", "content_en": "<p>Topophonies are virtual navigable sound spaces, composed of sounding or audio-graphic objects. Graphic and sounding shapes or objects are audio-graphic when visual and audio modalities are synchronized.</p>\r\n<p>In virtual reality and videogames, we know how to make scenes composed of point-shaped elements: graphic and sound (i.e. a spot representing an object). However, there is no tool enabling navigation to make scenes consisting of a very great number of interactive visual and sound elements, nor of dispersed elements such as a crowd, a flow of traffic, foliage, or rain.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The research project Topophonie proposed lines of research and innovative developments for sound and visual navigation in spaces composed of multiple and disseminated sound and visual elements. By working in a multidisciplinary scientific group (digital audio, visualization, sound design) with companies specialized in the domain of interactive multimedia activities, the project Topophonie conceived and developed models, interfaces and audio-graphic renderings of groups of granular animated and spatialized objects.</p>\r\n<p>The project team was composed of researchers specialized in granular sound renderings and in advanced interactive graphical renderings, as well as digital designers and enterprises specialized in the relevant fields of application.</p>\r\n<p>The completed works produced interfaces that define and control multimedia scenes and tools for real-time rendering on synchronized audio and visual channels. The first production was an augmented audio reality installation, Topophonie Mobile, during the Futur en Seine festival. This installation augmented a position-determined walk in a public park with an acoustic ambiance on the theme of water via the Navidium application for interactive audio-graphical digital maps. Topophonie Mobile, won the Grand Prix de l&rsquo;Innovation from the City of Paris in 2013 (mention special design).</p>\r\n<p>The other strong points of the research carried out in this project were the conception of a new method of synthesizing sound textures, and the dissemination of knowledge via two international workshops on audio-graphical modeling organized as a part of the project in 2011.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-2009-CORD-022-03.</p>", "date_from": "2009-09-01", "date_to": "2012-12-31", "user": null, "type": "external", "external_id": "ANR-2009-CORD-022-03", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 19, "website": "http://www.topophonie.com/", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7], "organizations": [1, 20, 22, 23, 21, 24], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 14, "fields": {"keywords_string": "", "site": 1, "title": "Voice4Games", "title_fr": "Voice4Games", "title_en": "Voice4Games", "slug": "voice4games", "_meta_title": "", "description": "Traitement de la voix pour la production de jeux vid\u00e9o", "description_fr": "Traitement de la voix pour la production de jeux vid\u00e9o", "description_en": "Voice Processing for Video game Production", "gen_description": false, "created": "2016-09-07T07:57:31.944Z", "updated": "2018-06-29T09:57:17.995Z", "status": 2, "publish_date": "2016-09-07T07:57:31Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet voice4Games visait &agrave; la conception et la r&eacute;alisation de solutions technologiques nouvelles dans le domaine du traitement de la voix pour la production (interaction temps r&eacute;el) et la post-production de jeux vid&eacute;o.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Dans un contexte d&rsquo;explosion du march&eacute; du jeu vid&eacute;o, le consortium voice4Games s&rsquo;est form&eacute; pour r&eacute;pondre aux demandes d&rsquo;analyse, de transformation, et d&rsquo;indexation de contenu audio de voix parl&eacute;e et chant&eacute;e. Les innovations du projet voice4Games ont vis&eacute; &agrave; enrichir et &eacute;largir l&rsquo;&eacute;ventail de services de traitement vocaux dans les secteurs de la production audio de la voix, dans une synergie de l&rsquo;indexation et de la transformation de la voix en production temps r&eacute;el et en post-production.</p>\r\n<p>Les principales innovations concernent :</p>\r\n<ul>\r\n<li>L&rsquo;homog&eacute;n&eacute;isation de la qualit&eacute; audio de la voix multilingue ;</li>\r\n<li>La recherche de voix par similarit&eacute; pour le casting vocal multilingue ;</li>\r\n<li>L&rsquo;int&eacute;gration des nouvelles technologies audio/vid&eacute;o (Kinect) pour l&rsquo;interaction vocale en temps r&eacute;el (commande vocale, voix chant&eacute;e).</li>\r\n</ul>\r\n<p>Le r&ocirc;le de l&rsquo;Ircam au sein du projet voice4Games a &eacute;t&eacute; d&rsquo;impulser et de coordonner les recherches sur l&rsquo;analyse/indexation/transformation de la voix avec les partenaires Exequo, voxler, et Cyanide pour l&rsquo;enrichissement des applications de traitement de la voix dans les secteurs de la production et de la post-production de jeux vid&eacute;o.</p>", "content_fr": "<p>Le projet voice4Games visait &agrave; la conception et la r&eacute;alisation de solutions technologiques nouvelles dans le domaine du traitement de la voix pour la production (interaction temps r&eacute;el) et la post-production de jeux vid&eacute;o.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Dans un contexte d&rsquo;explosion du march&eacute; du jeu vid&eacute;o, le consortium voice4Games s&rsquo;est form&eacute; pour r&eacute;pondre aux demandes d&rsquo;analyse, de transformation, et d&rsquo;indexation de contenu audio de voix parl&eacute;e et chant&eacute;e. Les innovations du projet voice4Games ont vis&eacute; &agrave; enrichir et &eacute;largir l&rsquo;&eacute;ventail de services de traitement vocaux dans les secteurs de la production audio de la voix, dans une synergie de l&rsquo;indexation et de la transformation de la voix en production temps r&eacute;el et en post-production.</p>\r\n<p>Les principales innovations concernent :</p>\r\n<ul>\r\n<li>L&rsquo;homog&eacute;n&eacute;isation de la qualit&eacute; audio de la voix multilingue ;</li>\r\n<li>La recherche de voix par similarit&eacute; pour le casting vocal multilingue ;</li>\r\n<li>L&rsquo;int&eacute;gration des nouvelles technologies audio/vid&eacute;o (Kinect) pour l&rsquo;interaction vocale en temps r&eacute;el (commande vocale, voix chant&eacute;e).</li>\r\n</ul>\r\n<p>Le r&ocirc;le de l&rsquo;Ircam au sein du projet voice4Games a &eacute;t&eacute; d&rsquo;impulser et de coordonner les recherches sur l&rsquo;analyse/indexation/transformation de la voix avec les partenaires Exequo, voxler, et Cyanide pour l&rsquo;enrichissement des applications de traitement de la voix dans les secteurs de la production et de la post-production de jeux vid&eacute;o.</p>", "content_en": "<p>The objective of the voice4Games project was to provide innovative solutions in the domain of voice processing for the production and post-production of audio contents for video games.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The voice4Games consortium was created to reply to the demands for the analysis, recognition, and transformation of speaking and singing voices for the video game industry. The innovative solutions that were developed during the project expanded the use of voice processing techniques (voice recognition and transformation) to the production and post-production of audio content for video games.</p>\r\n<p>The project&rsquo;s main innovations:</p>\r\n<ul>\r\n<li>Homogenizing the audio quality of multi-speakers and multi-language voices</li>\r\n<li>Voice similarity for multi-language voice casting</li>\r\n<li>Integration of innovative audio/video technologies (kinect) for real-time voice interactions (vocal control, singing voice)</li>\r\n</ul>\r\n<p>The role of IRCAM in the voice4Games project was to manage the research on the analysis, recognition, and transformation of voices with the partners Exequo, voxler, and Cyanide for the extension of voice processing applications for video game production and post-production.</p>", "date_from": "2011-11-01", "date_to": "2014-10-31", "user": null, "type": "external", "external_id": "I11012094", "program": 2, "program_type": null, "call": 22, "lead_team": null, "lead_organization": 27, "website": "http://www.voice4games.fr/index_angl.html", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 7], "organizations": [29, 1, 28], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 15, "fields": {"keywords_string": "", "site": 1, "title": "Angel Studio", "title_fr": "Angel Studio", "title_en": "Angel Studio", "slug": "angel-studio", "_meta_title": "", "description": "G\u00e9n\u00e9rateur d'avatars personnalis\u00e9s", "description_fr": "G\u00e9n\u00e9rateur d'avatars personnalis\u00e9s", "description_en": "Generator of Personalized Avatars", "gen_description": false, "created": "2016-09-07T08:03:41.886Z", "updated": "2018-06-29T10:17:49.898Z", "status": 2, "publish_date": "2016-09-07T08:03:41Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Angel Studio avait pour objectif de d&eacute;velopper un g&eacute;n&eacute;rateur d&rsquo;avatars permettant de produire &agrave; partir de photos et d&rsquo;&eacute;chantillons de voix &ndash; correspondant &agrave; un utilisateur donn&eacute; &ndash; un avatar de ce dernier, sous la forme d&rsquo;un visage 3D photo r&eacute;aliste, anim&eacute; en temps r&eacute;el et dot&eacute; d&rsquo;une voix de synth&egrave;se param&eacute;trable.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;objectif scientifique du projet &eacute;tait de parvenir &agrave; une reproduction de l&rsquo;animation faciale et de la voix d&rsquo;un utilisateur avec un niveau de simulation correspondant au seuil d&rsquo;acceptabilit&eacute; pour les utilisateurs.</p>\r\n<p>L&rsquo;objectif industriel du projet &eacute;tait d&rsquo;int&eacute;grer ce g&eacute;n&eacute;rateur aux solutions d&eacute;velopp&eacute;es par les deux PME du consortium : As an angel et SoBuzzy. Le d&eacute;veloppement du march&eacute; des agents conversationnels ainsi que de celui du Web3D se heurte &agrave; la dure r&eacute;alit&eacute; du seuil d&rsquo;acceptabilit&eacute; de l&rsquo;utilisateur final. De nombreux projets et &eacute;tudes, conduits notamment par As An Angel (projet Agent conversationnel expressif), le laboratoire informatique de Grenoble (ex CLIPS) et le r&eacute;seau d&rsquo;excellence HUMAINE, ont montr&eacute; que ce seuil, qui peut certes varier d&rsquo;une culture &agrave; une autre, reste globalement tr&egrave;s &eacute;lev&eacute;. En effet, les attentes des utilisateurs, model&eacute;es notamment par la litt&eacute;rature et le cin&eacute;ma de science-fiction, correspondent &agrave; une simulation cr&eacute;dible de l&rsquo;humain, tant au niveau des capacit&eacute;s de dialogue qu&rsquo;&agrave; celui de la repr&eacute;sentation et l&rsquo;animation d&rsquo;un visage et d&rsquo;un corps de synth&egrave;se.</p>\r\n<p>Le projet Angel Studio visait donc &agrave; permettre &agrave; des agents conversationnels ou &agrave; des avatars d&rsquo;atteindre le seuil d&rsquo;acceptabilit&eacute; pour deux modalit&eacute;s de communication :</p>\r\n<ul>\r\n<li>L&rsquo;animation faciale expressive de visages &laquo; photo-r&eacute;alistes &raquo;</li>\r\n<li>La simulation cr&eacute;dible d&rsquo;une voix humaine expressive.</li>\r\n</ul>\r\n<p>L&rsquo;Ircam prend en charge le d&eacute;veloppement et la fourniture d&rsquo;algorithmes de conversion d&rsquo;identit&eacute; de voix, et la fourniture d&rsquo;algorithmes de transformation d&rsquo;expressivit&eacute; de voix, des phrases synth&eacute;tis&eacute;es par un syst&egrave;me de synth&egrave;se &agrave; partir de texte (TTS) du march&eacute; ou par celui de l&rsquo;Ircam (Ircam TTS).</p>", "content_fr": "<p>Le projet Angel Studio avait pour objectif de d&eacute;velopper un g&eacute;n&eacute;rateur d&rsquo;avatars permettant de produire &agrave; partir de photos et d&rsquo;&eacute;chantillons de voix &ndash; correspondant &agrave; un utilisateur donn&eacute; &ndash; un avatar de ce dernier, sous la forme d&rsquo;un visage 3D photo r&eacute;aliste, anim&eacute; en temps r&eacute;el et dot&eacute; d&rsquo;une voix de synth&egrave;se param&eacute;trable.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;objectif scientifique du projet &eacute;tait de parvenir &agrave; une reproduction de l&rsquo;animation faciale et de la voix d&rsquo;un utilisateur avec un niveau de simulation correspondant au seuil d&rsquo;acceptabilit&eacute; pour les utilisateurs.</p>\r\n<p>L&rsquo;objectif industriel du projet &eacute;tait d&rsquo;int&eacute;grer ce g&eacute;n&eacute;rateur aux solutions d&eacute;velopp&eacute;es par les deux PME du consortium : As an angel et SoBuzzy. Le d&eacute;veloppement du march&eacute; des agents conversationnels ainsi que de celui du Web3D se heurte &agrave; la dure r&eacute;alit&eacute; du seuil d&rsquo;acceptabilit&eacute; de l&rsquo;utilisateur final. De nombreux projets et &eacute;tudes, conduits notamment par As An Angel (projet Agent conversationnel expressif), le laboratoire informatique de Grenoble (ex CLIPS) et le r&eacute;seau d&rsquo;excellence HUMAINE, ont montr&eacute; que ce seuil, qui peut certes varier d&rsquo;une culture &agrave; une autre, reste globalement tr&egrave;s &eacute;lev&eacute;. En effet, les attentes des utilisateurs, model&eacute;es notamment par la litt&eacute;rature et le cin&eacute;ma de science-fiction, correspondent &agrave; une simulation cr&eacute;dible de l&rsquo;humain, tant au niveau des capacit&eacute;s de dialogue qu&rsquo;&agrave; celui de la repr&eacute;sentation et l&rsquo;animation d&rsquo;un visage et d&rsquo;un corps de synth&egrave;se.</p>\r\n<p>Le projet Angel Studio visait donc &agrave; permettre &agrave; des agents conversationnels ou &agrave; des avatars d&rsquo;atteindre le seuil d&rsquo;acceptabilit&eacute; pour deux modalit&eacute;s de communication :</p>\r\n<ul>\r\n<li>L&rsquo;animation faciale expressive de visages &laquo; photo-r&eacute;alistes &raquo;</li>\r\n<li>La simulation cr&eacute;dible d&rsquo;une voix humaine expressive.</li>\r\n</ul>\r\n<p>L&rsquo;Ircam prend en charge le d&eacute;veloppement et la fourniture d&rsquo;algorithmes de conversion d&rsquo;identit&eacute; de voix, et la fourniture d&rsquo;algorithmes de transformation d&rsquo;expressivit&eacute; de voix, des phrases synth&eacute;tis&eacute;es par un syst&egrave;me de synth&egrave;se &agrave; partir de texte (TTS) du march&eacute; ou par celui de l&rsquo;Ircam (Ircam TTS).</p>", "content_en": "<p>The development of an avatar generator that uses photos and voice samples was the central concept in the AngelStudio Project. The photos and voice samples for a specific user are used to create a realistic 3D avatar face, with a synthesized voice with parametric possibilities.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The scientific objective of the project was to be able to reproduce the facial and vocal movements of a user with a level of simulation acceptable for users.</p>\r\n<p>The commercial objective of the project was to include this generator in solutions developed by two small businesses involved in the project: As An Angel and SoBuzzy. The development of the conversational agent market, as well as that of Web3D, has come up against the challenge of what end users accept. Numerous projects and studies, especially those carried out by As An Angel (e.g. Project Agent Conversationnel Expressif), the Laboratoire Informatique de Grenoble (ex CLIPS), and the HUMAINE network have demonstrated this level of acceptance that can vary from one culture to another but remains relatively high. User expectations&mdash;modeled by writing, cinema, and science fiction&mdash;correspond to a plausible human imitation, both in terms of the capacity to converse and to the representation and animation of an artificial face and body.</p>\r\n<p>The AngelStudio project therefore aimed at creating conversational agents or avatars that meet users&rsquo; standards for two means of communication:</p>\r\n<ul>\r\n<li>Expressive facial animation of \"photo-realistic\" faces</li>\r\n<li>Plausible simulation of an expressive human voice</li>\r\n</ul>\r\n<p>IRCAM developed and provided the conversion algorithms for the identity of the voice, the transformation algorithms for the expressivity of the voice, sentences synthesized from text (TTS) by a system that is on the market, or by a propriety IRCAM system (IRCAM TTS).</p>", "date_from": "2009-03-01", "date_to": "2013-06-30", "user": null, "type": "external", "external_id": "FEDER-DRIRE-Ile-De-France", "program": 3, "program_type": null, "call": 22, "lead_team": null, "lead_organization": 603, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [30, 1, 31, 32], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 16, "fields": {"keywords_string": "", "site": 1, "title": "Rhapsodie", "title_fr": "Rhapsodie", "title_en": "Rhapsodie", "slug": "rhapsodie", "_meta_title": "", "description": "Corpus prosodique de r\u00e9f\u00e9rence en fran\u00e7ais parl\u00e9", "description_fr": "Corpus prosodique de r\u00e9f\u00e9rence en fran\u00e7ais parl\u00e9", "description_en": "A Prosodic Reference Corpus of Spoken French", "gen_description": false, "created": "2016-09-07T08:20:37.903Z", "updated": "2018-07-25T14:49:45.445Z", "status": 2, "publish_date": "2016-09-07T08:20:37Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Rhapsodie &eacute;tait consacr&eacute; &agrave; l&rsquo;&eacute;laboration d&rsquo;un corpus prosodique de r&eacute;f&eacute;rence en fran&ccedil;ais parl&eacute;, &eacute;chantillonn&eacute; en diff&eacute;rents genres discursifs.</p>\r\n<p>Outre les annotations prosodiques, le corpus est dot&eacute; d&rsquo;annotations syntaxiques et informationnelles exploitables pour l&rsquo;analyse de ses relations avec la syntaxe et du statut de la prosodie dans le discours (mise en place de la structure communicative, gestion des tours de parole). La question du standard d&rsquo;annotation est donc l&agrave; une question majeure. Les objectifs compl&eacute;mentaires des partenaires associ&eacute;s &agrave; ce programme s&rsquo;orientaient autour de sept axes :</p>\r\n<ul>\r\n<li>Mise au point de formats pour l&rsquo;annotation et la lecture des donn&eacute;es intonosyntaxiques dans une perspective d&rsquo;interop&eacute;rabilit&eacute; et d&rsquo;&eacute;change ;</li>\r\n<li>Mise &agrave; disposition au sein de la communaut&eacute; scientifique de ressources de fran&ccedil;ais parl&eacute; align&eacute;es (30 heures de parole) dont 20 % auront &eacute;t&eacute; annot&eacute;es prosodiquement (adaptation des conventions de transcription de la TEI, format xML) ;</li>\r\n<li>Distribution en ligne d&rsquo;outils pour traiter et analyser ces ressources avec manuels d&rsquo;utilisation exhaustifs ;</li>\r\n<li>D&eacute;veloppement de m&eacute;thodes linguistiques raisonn&eacute;es et explicit&eacute;es pour l&rsquo;interpr&eacute;tation et la g&eacute;n&eacute;ration des structures ;</li>\r\n<li>Enrichissement des mod&egrave;les intonosyntaxiques du fran&ccedil;ais parl&eacute; ;</li>\r\n<li>Contribution &agrave; l&rsquo;am&eacute;lioration de la prosodie en synth&egrave;se de la parole ;</li>\r\n<li>Organisation &agrave; l&rsquo;issue du programme d&rsquo;un colloque international sur le th&egrave;me de l&rsquo;interface prosodie-discours qui nous a permis d&rsquo;exposer nos r&eacute;sultats, de les confronter aux travaux des &eacute;quipes reconnues internationalement dans le domaine et de faire le point sur les mod&egrave;les prosodiques.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-07-CORP-030-02.</p>", "content_fr": "<p>Le projet Rhapsodie &eacute;tait consacr&eacute; &agrave; l&rsquo;&eacute;laboration d&rsquo;un corpus prosodique de r&eacute;f&eacute;rence en fran&ccedil;ais parl&eacute;, &eacute;chantillonn&eacute; en diff&eacute;rents genres discursifs.</p>\r\n<p>Outre les annotations prosodiques, le corpus est dot&eacute; d&rsquo;annotations syntaxiques et informationnelles exploitables pour l&rsquo;analyse de ses relations avec la syntaxe et du statut de la prosodie dans le discours (mise en place de la structure communicative, gestion des tours de parole). La question du standard d&rsquo;annotation est donc l&agrave; une question majeure. Les objectifs compl&eacute;mentaires des partenaires associ&eacute;s &agrave; ce programme s&rsquo;orientaient autour de sept axes :</p>\r\n<ul>\r\n<li>Mise au point de formats pour l&rsquo;annotation et la lecture des donn&eacute;es intonosyntaxiques dans une perspective d&rsquo;interop&eacute;rabilit&eacute; et d&rsquo;&eacute;change ;</li>\r\n<li>Mise &agrave; disposition au sein de la communaut&eacute; scientifique de ressources de fran&ccedil;ais parl&eacute; align&eacute;es (30 heures de parole) dont 20 % auront &eacute;t&eacute; annot&eacute;es prosodiquement (adaptation des conventions de transcription de la TEI, format xML) ;</li>\r\n<li>Distribution en ligne d&rsquo;outils pour traiter et analyser ces ressources avec manuels d&rsquo;utilisation exhaustifs ;</li>\r\n<li>D&eacute;veloppement de m&eacute;thodes linguistiques raisonn&eacute;es et explicit&eacute;es pour l&rsquo;interpr&eacute;tation et la g&eacute;n&eacute;ration des structures ;</li>\r\n<li>Enrichissement des mod&egrave;les intonosyntaxiques du fran&ccedil;ais parl&eacute; ;</li>\r\n<li>Contribution &agrave; l&rsquo;am&eacute;lioration de la prosodie en synth&egrave;se de la parole ;</li>\r\n<li>Organisation &agrave; l&rsquo;issue du programme d&rsquo;un colloque international sur le th&egrave;me de l&rsquo;interface prosodie-discours qui nous a permis d&rsquo;exposer nos r&eacute;sultats, de les confronter aux travaux des &eacute;quipes reconnues internationalement dans le domaine et de faire le point sur les mod&egrave;les prosodiques.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-07-CORP-030-02.</p>", "content_en": "<p>The intention of the Rhapsodie project was to create a prosodic reference corpus of spoken French, sampled from a broad array of discursive styles of speech.</p>\r\n<p>In addition to prosodic annotations, the corpus contains syntactic and informative annotations that can be used to analyze the relationships between syntax and the status of prosody in the speech (e.g. placing of the communicative structure, conducting speaking in turns). The issue of standardization of annotation is therefore central to the project. The complementary objectives of the project&rsquo;s partners can be found in 7 domains:</p>\r\n<ul>\r\n<li>Perfecting formants for the annotation and reading of intonosytactic data to promote interoperability and exchanges.</li>\r\n<li>Placing resources of spoken French (30 hours of speech) at the disposal of the scientific community. Twenty percent of these resources have been annotated in terms of prosody (following the Text Encoding Initiative transcription guidelines, formant xML).</li>\r\n<li>Distributing the tools online to process and analyze these resources with comprehensive users&rsquo; manuals.</li>\r\n<li>Developing reasoned and explicit linguistic methods for the interpretation and generation of structures.</li>\r\n<li>Enriching the intonosyntactical models of spoken French.</li>\r\n<li>Contributing to the improvement of prosody in speech synthesis.</li>\r\n<li>Organizing an international colloquium at the end of the project on prosody-speech interfaces to present the project&rsquo;s results and compare them with work carried out by internationally known research teams.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-07-CORP-030-02.</p>", "date_from": "2008-01-01", "date_to": "2012-06-30", "user": null, "type": "external", "external_id": "ANR-07-CORP-030-02", "program": 1, "program_type": 4, "call": 24, "lead_team": null, "lead_organization": 33, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [1, 35, 34, 36, 33], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 17, "fields": {"keywords_string": "", "site": 1, "title": "Indexation automatique de morceaux de musique", "title_fr": "Indexation automatique de morceaux de musique", "title_en": "Automatic Music Indexing", "slug": "indexation-automatique-de-morceaux-de-musique", "_meta_title": "", "description": "Extraction automatique de caract\u00e9ristiques musicales d\u2019un morceau de musique", "description_fr": "Extraction automatique de caract\u00e9ristiques musicales d\u2019un morceau de musique", "description_en": "Automatic extraction of musical descriptors for a piece of music", "gen_description": false, "created": "2016-09-07T13:22:26.342Z", "updated": "2018-06-29T08:55:23.314Z", "status": 2, "publish_date": "2016-09-07T13:22:26Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Dans le cadre de&nbsp; diff&eacute;rents projets pr&eacute;sent&eacute;s ci-apr&egrave;s, sont &eacute;labor&eacute;es :</p>\r\n<ul>\r\n<li>Des m&eacute;thodes d&rsquo;extraction automatique de caract&eacute;ristiques musicales d&rsquo;un morceau de musique, de type tempo, position des battues, m&eacute;trique, tonalit&eacute; ou suite temporelle d&rsquo;accords. Ces caract&eacute;ristiques permettent, par exemple, le classement automatique d&rsquo;un morceau, la recherche par le contenu et la recherche par similarit&eacute; dans une base de donn&eacute;es ou catalogue de titres musicaux ;</li>\r\n<li>Des m&eacute;thodes de reconnaissance d&rsquo;extraits musicaux, destin&eacute;es &agrave; l&rsquo;identification automatique d&rsquo;extraits de morceaux de musique &agrave; partir de bases d&rsquo;ayants droit. Reposant sur une signature sonore compacte codant l&rsquo;essentiel de l&rsquo;information, ces algorithmes comparent chaque fragment du son &agrave; identifier &agrave; ceux de la base de donn&eacute;es de r&eacute;f&eacute;rence ;</li>\r\n<li>Des m&eacute;thodes d&rsquo;estimation de la structure temporelle d&rsquo;un morceau en termes de r&eacute;p&eacute;tition de partie au cours du temps qui permettent, lors de l&rsquo;&eacute;coute, la navigation &agrave; l&rsquo;int&eacute;rieur de la structure temporelle du morceau ;</li>\r\n<li>Des m&eacute;thodes de cr&eacute;ation automatique de r&eacute;sum&eacute;s audio permettant des pr&eacute;-&eacute;coutes rapides du contenu d&rsquo;un morceau par ses points clefs.</li>\r\n</ul>\r\n<p>&Eacute;quipe Ircam: <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_fr": "<p>Dans le cadre de&nbsp; diff&eacute;rents projets pr&eacute;sent&eacute;s ci-apr&egrave;s, sont &eacute;labor&eacute;es :</p>\r\n<ul>\r\n<li>Des m&eacute;thodes d&rsquo;extraction automatique de caract&eacute;ristiques musicales d&rsquo;un morceau de musique, de type tempo, position des battues, m&eacute;trique, tonalit&eacute; ou suite temporelle d&rsquo;accords. Ces caract&eacute;ristiques permettent, par exemple, le classement automatique d&rsquo;un morceau, la recherche par le contenu et la recherche par similarit&eacute; dans une base de donn&eacute;es ou catalogue de titres musicaux ;</li>\r\n<li>Des m&eacute;thodes de reconnaissance d&rsquo;extraits musicaux, destin&eacute;es &agrave; l&rsquo;identification automatique d&rsquo;extraits de morceaux de musique &agrave; partir de bases d&rsquo;ayants droit. Reposant sur une signature sonore compacte codant l&rsquo;essentiel de l&rsquo;information, ces algorithmes comparent chaque fragment du son &agrave; identifier &agrave; ceux de la base de donn&eacute;es de r&eacute;f&eacute;rence ;</li>\r\n<li>Des m&eacute;thodes d&rsquo;estimation de la structure temporelle d&rsquo;un morceau en termes de r&eacute;p&eacute;tition de partie au cours du temps qui permettent, lors de l&rsquo;&eacute;coute, la navigation &agrave; l&rsquo;int&eacute;rieur de la structure temporelle du morceau ;</li>\r\n<li>Des m&eacute;thodes de cr&eacute;ation automatique de r&eacute;sum&eacute;s audio permettant des pr&eacute;-&eacute;coutes rapides du contenu d&rsquo;un morceau par ses points clefs.</li>\r\n</ul>\r\n<p>&Eacute;quipe Ircam: <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_en": "<p>During projects presented hereinafter, the following subjects were addressed:</p>\r\n<ul>\r\n<li>Methods for the automatic extraction of musical descriptors for a piece of music such as the tempo, location of beats, metrical, tonality, or a temporal grouping for a chord. These descriptors facilitate the automatic classification of a piece and can be used for content-based searches in sound databases.</li>\r\n<li>Musical excerpt recognition methods, designed to automatically identify excerpts from pieces of music using reference databases. These methods are based on a compact sound signature (fingerprint) encoding the essential information. These algorithms compare each fragment of sound under investigation, with those in the database.</li>\r\n<li>Methods for the estimation of the temporal structure of a piece of music in terms of the repetition of a section being listened to and enabling browsing within the temporal structure of the given musical piece.</li>\r\n<li>Methods for the automatic creation of audio summaries making it possible to quickly pre-listen to the contents of a given musical piece via its key points</li>\r\n</ul>\r\n<p>IRCAM's team: <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Sound Analysis &amp; Synthesis team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 18, "fields": {"keywords_string": "", "site": 1, "title": "ABC_DJ", "title_fr": "ABC_DJ", "title_en": "ABC_DJ", "slug": "abc_dj", "_meta_title": "", "description": "Artist-to-business-to-business-to-Consumer Audio branding System", "description_fr": "Artist-to-business-to-business-to-Consumer Audio branding System", "description_en": "Artist-to-business-to-business-to-Consumer Audio branding System", "gen_description": false, "created": "2016-09-07T13:29:51.466Z", "updated": "2019-01-11T14:25:53.310Z", "status": 2, "publish_date": "2016-09-07T13:29:51Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet ABC_DJ vise le d&eacute;veloppement de technologies avanc&eacute;es destin&eacute;es aux agences europ&eacute;ennes de cr&eacute;ation travaillant dans le champ de l&rsquo;audio branding, c&rsquo;est-&agrave;-dire de la s&eacute;lection et de la diffusion de musiques enregistr&eacute;es en rapport avec des caract&eacute;ristiques de produits et de marques (boutiques, communication, etc.). L&rsquo;enjeu est d&rsquo;abord de permettre &agrave; ces agences de produire des contenus de haute qualit&eacute; de sorte qu&rsquo;elles soient comp&eacute;titives par rapport aux quelques grands acteurs du march&eacute;. Le second enjeu est d&rsquo;ouvrir la cha&icirc;ne de valeur d&rsquo;audio branding aux cr&eacute;ateurs europ&eacute;ens et aux labels ind&eacute;pendants en proposant de nouveaux modes de valorisation de leur production, notamment pour les musiques diffus&eacute;es en boutiques. L&rsquo;ensemble de musiques effectivement exploitables par les agences et les marques clientes devrait ainsi pouvoir &ecirc;tre consid&eacute;rablement &eacute;tendu.</p>\r\n<p>L&rsquo;approche scientifique et technique du projet combine des recherches en ing&eacute;nierie des connaissances, en traitement de signal et des &eacute;tudes d&rsquo;usages et de march&eacute; pour assister le processus cr&eacute;atif et la diffusion automatis&eacute;e de morceaux.</p>\r\n<p>L&rsquo;Ircam y est plus particuli&egrave;rement en charge de la conception de nouveaux algorithmes d&rsquo;analyse du contenu audio musical (auto-tagging en genre, &eacute;motions, instrumentations, estimation de la tonalit&eacute; et du tempo) ainsi que de nouveaux outils pour permettre le mixage automatique (mesure de la qualit&eacute; audio, segmentation en segments vocaux, analyse hi&eacute;rarchique compl&egrave;te de la structure, r&eacute;sum&eacute;s audio intelligents, s&eacute;paration de sources audio).</p>", "content_fr": "<p>Le projet ABC_DJ vise le d&eacute;veloppement de technologies avanc&eacute;es destin&eacute;es aux agences europ&eacute;ennes de cr&eacute;ation travaillant dans le champ de l&rsquo;audio branding, c&rsquo;est-&agrave;-dire de la s&eacute;lection et de la diffusion de musiques enregistr&eacute;es en rapport avec des caract&eacute;ristiques de produits et de marques (boutiques, communication, etc.). L&rsquo;enjeu est d&rsquo;abord de permettre &agrave; ces agences de produire des contenus de haute qualit&eacute; de sorte qu&rsquo;elles soient comp&eacute;titives par rapport aux quelques grands acteurs du march&eacute;. Le second enjeu est d&rsquo;ouvrir la cha&icirc;ne de valeur d&rsquo;audio branding aux cr&eacute;ateurs europ&eacute;ens et aux labels ind&eacute;pendants en proposant de nouveaux modes de valorisation de leur production, notamment pour les musiques diffus&eacute;es en boutiques. L&rsquo;ensemble de musiques effectivement exploitables par les agences et les marques clientes devrait ainsi pouvoir &ecirc;tre consid&eacute;rablement &eacute;tendu.</p>\r\n<p>L&rsquo;approche scientifique et technique du projet combine des recherches en ing&eacute;nierie des connaissances, en traitement de signal et des &eacute;tudes d&rsquo;usages et de march&eacute; pour assister le processus cr&eacute;atif et la diffusion automatis&eacute;e de morceaux.</p>\r\n<p>L&rsquo;Ircam y est plus particuli&egrave;rement en charge de la conception de nouveaux algorithmes d&rsquo;analyse du contenu audio musical (auto-tagging en genre, &eacute;motions, instrumentations, estimation de la tonalit&eacute; et du tempo) ainsi que de nouveaux outils pour permettre le mixage automatique (mesure de la qualit&eacute; audio, segmentation en segments vocaux, analyse hi&eacute;rarchique compl&egrave;te de la structure, r&eacute;sum&eacute;s audio intelligents, s&eacute;paration de sources audio).</p>", "content_en": "<p>The ABC_DJ project seeks to provide advanced technology to European creative agencies in the field of audio branding&mdash;the selection and diffusion of recorded music in relationship with the characteristics of products and brands (boutiques, communication, etc.). The primary goal is to enable these agencies to produce high-level contents so they can successfully compete with major actors in the market. The second goal is to open the audio branding value chain to European artists and independent recording labels by offering them new means of monetizing their works, notably through in-store music. The range of music that can be used by client agencies and brands will be considerably extended.</p>\r\n<p>The scientific and technical approach employed in this project brings together research in engineering knowledge, sound signal processing, user studies, and market research to assist the creative process and the automatic broadcasting of music.</p>\r\n<p>In this project, IRCAM is particularly involved in the creation of new algorithms for the analysis of audio musical contents (auto tagging by genre, emotion, instrumentation, estimation of the tonality and tempo) as well as new tools for automatic mixing (measuring the audio quality, segmentation, a complete hierarchic analysis of the structure, intelligent audio summaries, separation of audio sources).</p>", "date_from": "2016-01-01", "date_to": "2018-12-31", "user": null, "type": "external", "external_id": "688122", "program": 4, "program_type": 5, "call": 6, "lead_team": null, "lead_organization": 37, "website": "http://abcdj.eu/", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [39, 42, 38, 41, 1, 40], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 19, "fields": {"keywords_string": "", "site": 1, "title": "Bee Music", "title_fr": "Bee Music", "title_en": "Bee Music", "slug": "bee-music", "_meta_title": "", "description": "Base de donn\u00e9es interprofessionnelle des producteurs phonographiques", "description_fr": "Base de donn\u00e9es interprofessionnelle des producteurs phonographiques", "description_en": "Inter-professional Phonographic Producers\u2019 Database", "gen_description": false, "created": "2016-09-07T13:34:07.196Z", "updated": "2018-06-29T09:51:55.468Z", "status": 2, "publish_date": "2016-09-07T13:34:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>BIPP est la Base de donn&eacute;es interprofessionnelle des producteurs phonographiques. D&eacute;tenue par le SNEP (Syndicat national de l&rsquo;&eacute;dition phonographique) en partenariat avec l&rsquo;UPFI (Union des producteurs phonographiques fran&ccedil;ais ind&eacute;pendants), sa gestion a &eacute;t&eacute; confi&eacute;e &agrave; Kantar Media en 2008. Sa vocation est de r&eacute;f&eacute;rencer tous les catalogues digitaux et physiques actifs sur le march&eacute; fran&ccedil;ais. BIPP r&eacute;f&eacute;rence actuellement 2,5 millions de titres.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;objectif du projet, associant Kantar Media (sous l&rsquo;&eacute;gide du SNEP et de l&rsquo;UPFI) &agrave; un consortium d&rsquo;acteurs acad&eacute;miques et priv&eacute;s est de doter la base musicale BIPP de toutes les qualit&eacute;s qui la valideront d&eacute;finitivement aupr&egrave;s des professionnels de la fili&egrave;re musicale :</p>\r\n<ul>\r\n<li>Exhaustivit&eacute; et homog&eacute;n&eacute;it&eacute; ;</li>\r\n<li>Identification univoque du contenu ;</li>\r\n<li>Richesse et automatisation de l&rsquo;indexation ;</li>\r\n<li>Vari&eacute;t&eacute; des angles de recherche et de recommandation, avec un accent particulier sur la crit&eacute;risation musicologique, visuelle et s&eacute;mantique en plus des crit&egrave;res contextuels usuels ;</li>\r\n<li>Simplicit&eacute; et profondeur des interfaces pour permettre une exploitation des donn&eacute;es adapt&eacute;e &agrave; des usages m&eacute;tier cibl&eacute;s.</li>\r\n</ul>\r\n<p>Seul laboratoire public associ&eacute; au projet, l&rsquo;Ircam est en charge d&rsquo;y mener les recherches, dans le domaine de la recherche d&rsquo;information musicale (music information retrieval) visant &agrave; extraire automatiquement les caract&eacute;ristiques attendues des morceaux de musique &agrave; partir de l&rsquo;analyse de leurs enregistrements sonores : s&eacute;lection d&rsquo;extrait repr&eacute;sentatif, genre et humeur, identifiant unique, etc.</p>\r\n<p>Bee Music pr&eacute;sente un caract&egrave;re structurant car, pour la premi&egrave;re fois, les travaux de recherche r&eacute;alis&eacute;s par les acteurs du consortium depuis plus de dix ans pourront &ecirc;tre mis &agrave; l&rsquo;&eacute;chelle, au sein d&rsquo;une base r&eacute;ellement op&eacute;rationnelle de millions de titres.</p>\r\n<p>En plus de l&rsquo;aspect technique, l&rsquo;int&eacute;r&ecirc;t p&eacute;dagogique de fournir une base musicale riche est central. Au-del&agrave; de la cible des professionnels de la fili&egrave;re musicale, le grand public sera directement b&eacute;n&eacute;ficiaire des travaux de Bee Music gr&acirc;ce &agrave; la richesse d&rsquo;information mise en ligne par les professionnels qui cr&eacute;eront des services B2C &agrave; partir de BIPP.</p>", "content_fr": "<p>BIPP est la Base de donn&eacute;es interprofessionnelle des producteurs phonographiques. D&eacute;tenue par le SNEP (Syndicat national de l&rsquo;&eacute;dition phonographique) en partenariat avec l&rsquo;UPFI (Union des producteurs phonographiques fran&ccedil;ais ind&eacute;pendants), sa gestion a &eacute;t&eacute; confi&eacute;e &agrave; Kantar Media en 2008. Sa vocation est de r&eacute;f&eacute;rencer tous les catalogues digitaux et physiques actifs sur le march&eacute; fran&ccedil;ais. BIPP r&eacute;f&eacute;rence actuellement 2,5 millions de titres.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;objectif du projet, associant Kantar Media (sous l&rsquo;&eacute;gide du SNEP et de l&rsquo;UPFI) &agrave; un consortium d&rsquo;acteurs acad&eacute;miques et priv&eacute;s est de doter la base musicale BIPP de toutes les qualit&eacute;s qui la valideront d&eacute;finitivement aupr&egrave;s des professionnels de la fili&egrave;re musicale :</p>\r\n<ul>\r\n<li>Exhaustivit&eacute; et homog&eacute;n&eacute;it&eacute; ;</li>\r\n<li>Identification univoque du contenu ;</li>\r\n<li>Richesse et automatisation de l&rsquo;indexation ;</li>\r\n<li>Vari&eacute;t&eacute; des angles de recherche et de recommandation, avec un accent particulier sur la crit&eacute;risation musicologique, visuelle et s&eacute;mantique en plus des crit&egrave;res contextuels usuels ;</li>\r\n<li>Simplicit&eacute; et profondeur des interfaces pour permettre une exploitation des donn&eacute;es adapt&eacute;e &agrave; des usages m&eacute;tier cibl&eacute;s.</li>\r\n</ul>\r\n<p>Seul laboratoire public associ&eacute; au projet, l&rsquo;Ircam est en charge d&rsquo;y mener les recherches, dans le domaine de la recherche d&rsquo;information musicale (music information retrieval) visant &agrave; extraire automatiquement les caract&eacute;ristiques attendues des morceaux de musique &agrave; partir de l&rsquo;analyse de leurs enregistrements sonores : s&eacute;lection d&rsquo;extrait repr&eacute;sentatif, genre et humeur, identifiant unique, etc.</p>\r\n<p>Bee Music pr&eacute;sente un caract&egrave;re structurant car, pour la premi&egrave;re fois, les travaux de recherche r&eacute;alis&eacute;s par les acteurs du consortium depuis plus de dix ans pourront &ecirc;tre mis &agrave; l&rsquo;&eacute;chelle, au sein d&rsquo;une base r&eacute;ellement op&eacute;rationnelle de millions de titres.</p>\r\n<p>En plus de l&rsquo;aspect technique, l&rsquo;int&eacute;r&ecirc;t p&eacute;dagogique de fournir une base musicale riche est central. Au-del&agrave; de la cible des professionnels de la fili&egrave;re musicale, le grand public sera directement b&eacute;n&eacute;ficiaire des travaux de Bee Music gr&acirc;ce &agrave; la richesse d&rsquo;information mise en ligne par les professionnels qui cr&eacute;eront des services B2C &agrave; partir de BIPP.</p>", "content_en": "<p>BIPP stands for the Base de donn&eacute;es Interprofessionnelle des Producteurs Phonographiques (lit. Inter-professional Phonographic Producers&rsquo; Database). Owned by the SNEP (Syndicat National de l&rsquo;&Eacute;dition Phonographique which represents the major producers) in partnership with the UPFI (Union des Producteurs phonographiques Fran&ccedil;ais Ind&eacute;pendants, gathering independent producers), its management was entrusted to kantar Media in 2008. Its vocation is to reference all active digital and physical catalogues active in the French market. BIPP has currently referenced 2.5 million titles.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The objective of this project that associates kantar Media (under the aegis of the SNEP and the UPFI) with a consortium of academic and private partners is to provide the BIPP database with all the qualities necessary for it to be validated by the music industry:</p>\r\n<ul>\r\n<li>Exhaustiveness and homogeneity</li>\r\n<li>Univocal identification of the contents</li>\r\n<li>Wealth and automation of indexing</li>\r\n<li>A variety of search and recommendation methods, with an emphasis on musicological, visual, and semantic criteria in addition to the common contextual criteria</li>\r\n<li>Simple and in-depth interfaces that enable personalized exploitation of the data by targeted professional users</li>\r\n</ul>\r\n<p>The only public laboratory associated with the project, IRCAM, is carrying out research in the domain of musical information retrieval, focusing on the automatic extraction of expected characteristics in pieces of music from the analysis of their recordings: selection of a representative excerpt, genre and mood, unique identifiers, etc.</p>\r\n<p>Bee Music has a structuring nature; for the first time, research carried out over the past ten years by consortium members can be scaled up to fit within a truly operational database containing millions of tracks. In addition to the technical aspect, providing a rich musical database for educational purposes is a central idea of this project.</p>\r\n<p>Beyond the target of music industry professionals, the general public can also take advantage of the work carried out during Bee Music thanks to the wealth of information available online by the professionals that will create B2C services using BIPP.</p>", "date_from": "2013-01-01", "date_to": "2015-12-31", "user": null, "type": "external", "external_id": "O14703-370483", "program": 5, "program_type": null, "call": 15, "lead_team": null, "lead_organization": 43, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [46, 1, 44, 47, 45], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 20, "fields": {"keywords_string": "", "site": 1, "title": "Quaero", "title_fr": "Quaero", "title_en": "Quaero", "slug": "quaero", "_meta_title": "", "description": "Conception et r\u00e9alisation de solutions technologiques nouvelles permettant l\u2019exploitation d\u2019informations dans les contenus num\u00e9riques multim\u00e9dia et multilingues", "description_fr": "Conception et r\u00e9alisation de solutions technologiques nouvelles permettant l\u2019exploitation d\u2019informations dans les contenus num\u00e9riques multim\u00e9dia et multilingues", "description_en": "Design and production of new technological solutions enabling the extraction, analysis, classification, and use of information in digital multimedia and multi-lingual contents", "gen_description": false, "created": "2016-09-07T13:44:57.379Z", "updated": "2018-06-29T09:56:18.827Z", "status": 2, "publish_date": "2016-09-07T13:44:57Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Quaero, dot&eacute; d&rsquo;un budget de 200 millions d&rsquo;euros, est l&rsquo;un des plus importants projets de R&amp;D industriels fran&ccedil;ais. Quaero vise la conception et la r&eacute;alisation de solutions technologiques nouvelles permettant l&rsquo;extraction, l&rsquo;analyse, la classification et l&rsquo;exploitation d&rsquo;informations dans les contenus num&eacute;riques multim&eacute;dia et multilingues, en se concentrant sur le traitement automatique de la parole, du langage, de la musique, de l&rsquo;image, de la vid&eacute;o et des documents imprim&eacute;s num&eacute;ris&eacute;s.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Dans un contexte d&rsquo;explosion des informations num&eacute;riques accessibles &agrave; tous via PC, t&eacute;l&eacute;vision, ou terminaux de poche, le consortium quaero a &eacute;t&eacute; cr&eacute;&eacute; pour r&eacute;pondre aux nouveaux besoins d&rsquo;analyse de contenus multim&eacute;dia en provenance du grand public et des professionnels. Il permettra aux multiples technologies de pointe dans ce domaine issues des laboratoires publics et priv&eacute;s en France et en Allemagne d&rsquo;&ecirc;tre pleinement exploit&eacute;es au niveau industriel par des acteurs cl&eacute;s de ce secteur : PME de croissance et grands groupes industriels. Les d&eacute;veloppements de quaero conduiront &agrave; l&rsquo;enrichissement des services offerts par les portails, les moteurs de recherche, les applications pour la t&eacute;l&eacute;vision interactive, les environnements professionnels pour la production ou la postproduction de contenus multim&eacute;dia et la mise en ligne de biblioth&egrave;ques de contenus num&eacute;riques culturels (livres, films, &eacute;missions de t&eacute;l&eacute;vision...).</p>\r\n<p>Cinq grands domaines applicatifs sont vis&eacute;s :</p>\r\n<ul>\r\n<li>Recherches multim&eacute;dia sur Internet ;</li>\r\n<li>Enrichissement des services d&rsquo;acc&egrave;s aux contenus audiovisuels sur les portails ;</li>\r\n<li>S&eacute;lection et diffusion personnalis&eacute;es de vid&eacute;os ;</li>\r\n<li>Gestion de ressources audiovisuelles professionnelles ;</li>\r\n<li>Num&eacute;risation et enrichissement des contenus des biblioth&egrave;ques, du patrimoine audiovisuel et de l&rsquo;&eacute;dition scientifique.</li>\r\n</ul>\r\n<p>Le r&ocirc;le de l&rsquo;Ircam dans le cadre du projet est de coordonner les recherches sur l&rsquo;indexation musicale et de collaborer avec les industriels Exalead et France T&eacute;l&eacute;com au d&eacute;veloppement des applications de recherche multim&eacute;dia et d&rsquo;enrichissement des services d&rsquo;acc&egrave;s aux contenus audiovisuels.</p>", "content_fr": "<p>Quaero, dot&eacute; d&rsquo;un budget de 200 millions d&rsquo;euros, est l&rsquo;un des plus importants projets de R&amp;D industriels fran&ccedil;ais. Quaero vise la conception et la r&eacute;alisation de solutions technologiques nouvelles permettant l&rsquo;extraction, l&rsquo;analyse, la classification et l&rsquo;exploitation d&rsquo;informations dans les contenus num&eacute;riques multim&eacute;dia et multilingues, en se concentrant sur le traitement automatique de la parole, du langage, de la musique, de l&rsquo;image, de la vid&eacute;o et des documents imprim&eacute;s num&eacute;ris&eacute;s.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Dans un contexte d&rsquo;explosion des informations num&eacute;riques accessibles &agrave; tous via PC, t&eacute;l&eacute;vision, ou terminaux de poche, le consortium quaero a &eacute;t&eacute; cr&eacute;&eacute; pour r&eacute;pondre aux nouveaux besoins d&rsquo;analyse de contenus multim&eacute;dia en provenance du grand public et des professionnels. Il permettra aux multiples technologies de pointe dans ce domaine issues des laboratoires publics et priv&eacute;s en France et en Allemagne d&rsquo;&ecirc;tre pleinement exploit&eacute;es au niveau industriel par des acteurs cl&eacute;s de ce secteur : PME de croissance et grands groupes industriels. Les d&eacute;veloppements de quaero conduiront &agrave; l&rsquo;enrichissement des services offerts par les portails, les moteurs de recherche, les applications pour la t&eacute;l&eacute;vision interactive, les environnements professionnels pour la production ou la postproduction de contenus multim&eacute;dia et la mise en ligne de biblioth&egrave;ques de contenus num&eacute;riques culturels (livres, films, &eacute;missions de t&eacute;l&eacute;vision...).</p>\r\n<p>Cinq grands domaines applicatifs sont vis&eacute;s :</p>\r\n<ul>\r\n<li>Recherches multim&eacute;dia sur Internet ;</li>\r\n<li>Enrichissement des services d&rsquo;acc&egrave;s aux contenus audiovisuels sur les portails ;</li>\r\n<li>S&eacute;lection et diffusion personnalis&eacute;es de vid&eacute;os ;</li>\r\n<li>Gestion de ressources audiovisuelles professionnelles ;</li>\r\n<li>Num&eacute;risation et enrichissement des contenus des biblioth&egrave;ques, du patrimoine audiovisuel et de l&rsquo;&eacute;dition scientifique.</li>\r\n</ul>\r\n<p>Le r&ocirc;le de l&rsquo;Ircam dans le cadre du projet est de coordonner les recherches sur l&rsquo;indexation musicale et de collaborer avec les industriels Exalead et France T&eacute;l&eacute;com au d&eacute;veloppement des applications de recherche multim&eacute;dia et d&rsquo;enrichissement des services d&rsquo;acc&egrave;s aux contenus audiovisuels.</p>", "content_en": "<p>Quaero, a 200-million euro project, has been one of the largest industrial R&amp;D projects in France. Quaero focuses on the design and production of new technological solutions enabling the extraction, analysis, classification, and use of information in digital multimedia and multi-lingual contents, concentrating on the automatic processing of speech, language, music, images, videos, and printed digitalized documents.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The quareo consortium was created in a world where it is becoming easier and easier to have access to digital information via PCs, television, or handheld devices. The quareo consortium aims to reply to new demands to analyze multimedia contents from the general public and professionals. The consortium makes it possible for the most up-to-date technologies developed in public and private laboratories in France and Germany to be used to their fullest potential by key industrial interests in this domain be they small, growing businesses or large industrial groups. The developments made by the quareo consortium contribute to the expansion of the services offered by portals, search engines, applications for interactive television, professional environments for the production or post-production of multimedia contents, and will facilitate uploading digital media online for libraries (e.g. books, films, television programs, etc.).</p>\r\n<p>The quareo project concentrates on five major application domains:</p>\r\n<ul>\r\n<li>Multimedia online searches</li>\r\n<li>Improvement of services that provide access to audiovisual contents via portals</li>\r\n<li>Personalized selection and display of video contents management of professional audiovisual resources digitalization and improvement of library contents, audiovisual</li>\r\n<li>Archives, and scientific publications</li>\r\n</ul>\r\n<p>IRCAM will coordinate the research carried out by partner laboratories on musical indexing and act as a liaison with industrial partners such as Exalead and France Telecom in developing applications for multimedia indexing and in improving services to access audiovisual content.</p>", "date_from": "2008-01-01", "date_to": "2013-12-31", "user": null, "type": "external", "external_id": "2006-00-155-PMII-Quaero/Thomson", "program": 6, "program_type": null, "call": 20, "lead_team": null, "lead_organization": 48, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [53, 59, 58, 51, 49, 50, 4, 61, 1, 62, 63, 60, 64, 56, 57, 55, 65, 52], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 21, "fields": {"keywords_string": "", "site": 1, "title": "ROUTE", "title_fr": "ROUTE", "title_en": "ROUTE", "slug": "route", "_meta_title": "", "description": "Robot \u00e0 l'\u00e9coute", "description_fr": "Robot \u00e0 l'\u00e9coute", "description_en": "Robot \u00e0 l'\u00e9coute", "gen_description": false, "created": "2016-09-07T14:38:09.567Z", "updated": "2018-06-29T09:01:58.035Z", "status": 2, "publish_date": "2016-09-07T14:38:09Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le programme propos&eacute; par ROUTE se concentre sur une probl&eacute;matique commune &agrave; deux domaines de recherche a priori distincts :</p>\r\n<ul>\r\n<li>l&rsquo;analyse automatique d&rsquo;une sc&egrave;ne sonore, &agrave; partir d&rsquo;un processus d&rsquo;apprentissage de dictionnaire. En traitement du signal audio, on retrouve cet aspect dans plusieurs applications d&rsquo;int&eacute;r&ecirc;t majeur : computational auditory scene analysis (CASA), indexation automatique, s&eacute;paration de source, d&eacute;tection et localisation d&rsquo;objets sonores, parmi d&rsquo;autres ;</li>\r\n<li>l&rsquo;audition artificielle, domaine d&rsquo;&eacute;tude r&eacute;cent en robotique, pour lequel l&rsquo;analyse d&rsquo;une sc&egrave;ne sonore devient petit &agrave; petit un pr&eacute;requis n&eacute;cessaire &agrave; toute application moderne (par exemple, pour la surveillance des personnes &acirc;g&eacute;es, ou l&rsquo;&eacute;tude de l&rsquo;interaction homme/robot).</li>\r\n</ul>\r\n<p>L&rsquo;objectif central du projet porte sur la conception et la mise en place d&rsquo;une strat&eacute;gie de d&eacute;tection et localisation de locuteur principal dans la sc&egrave;ne sonore : une telle strat&eacute;gie doit permettre &agrave; un robot d&rsquo;identifier un signal vocal en pr&eacute;sence de bruit, et localiser la position du locuteur principal (en cas de plusieurs locuteurs en simultan&eacute;e). Le probl&egrave;me trait&eacute; est li&eacute; &eacute;troitement au domaine tr&egrave;s actuel du computational auditory scene analysis (CASA). En CASA, il s&rsquo;agit de concevoir des syst&egrave;mes automatiques avec une perception qui reproduit l&rsquo;audition humaine, en consid&eacute;rant ses aspects physiques et psychoacoustiques. Ce projet se situe dans une perspective diff&eacute;rente, bien que les outils de traitement audio consid&eacute;r&eacute;s soient comparables (machine learning, s&eacute;paration de source) : le c&ocirc;t&eacute; audition est trait&eacute; du point de vue du robot, et l&rsquo;int&eacute;r&ecirc;t se concentre dans l&rsquo;analyse de la sc&egrave;ne audio en soi.</p>", "content_fr": "<p>Le programme propos&eacute; par ROUTE se concentre sur une probl&eacute;matique commune &agrave; deux domaines de recherche a priori distincts :</p>\r\n<ul>\r\n<li>l&rsquo;analyse automatique d&rsquo;une sc&egrave;ne sonore, &agrave; partir d&rsquo;un processus d&rsquo;apprentissage de dictionnaire. En traitement du signal audio, on retrouve cet aspect dans plusieurs applications d&rsquo;int&eacute;r&ecirc;t majeur : computational auditory scene analysis (CASA), indexation automatique, s&eacute;paration de source, d&eacute;tection et localisation d&rsquo;objets sonores, parmi d&rsquo;autres ;</li>\r\n<li>l&rsquo;audition artificielle, domaine d&rsquo;&eacute;tude r&eacute;cent en robotique, pour lequel l&rsquo;analyse d&rsquo;une sc&egrave;ne sonore devient petit &agrave; petit un pr&eacute;requis n&eacute;cessaire &agrave; toute application moderne (par exemple, pour la surveillance des personnes &acirc;g&eacute;es, ou l&rsquo;&eacute;tude de l&rsquo;interaction homme/robot).</li>\r\n</ul>\r\n<p>L&rsquo;objectif central du projet porte sur la conception et la mise en place d&rsquo;une strat&eacute;gie de d&eacute;tection et localisation de locuteur principal dans la sc&egrave;ne sonore : une telle strat&eacute;gie doit permettre &agrave; un robot d&rsquo;identifier un signal vocal en pr&eacute;sence de bruit, et localiser la position du locuteur principal (en cas de plusieurs locuteurs en simultan&eacute;e). Le probl&egrave;me trait&eacute; est li&eacute; &eacute;troitement au domaine tr&egrave;s actuel du computational auditory scene analysis (CASA). En CASA, il s&rsquo;agit de concevoir des syst&egrave;mes automatiques avec une perception qui reproduit l&rsquo;audition humaine, en consid&eacute;rant ses aspects physiques et psychoacoustiques. Ce projet se situe dans une perspective diff&eacute;rente, bien que les outils de traitement audio consid&eacute;r&eacute;s soient comparables (machine learning, s&eacute;paration de source) : le c&ocirc;t&eacute; audition est trait&eacute; du point de vue du robot, et l&rsquo;int&eacute;r&ecirc;t se concentre dans l&rsquo;analyse de la sc&egrave;ne audio en soi.</p>", "content_en": "<p>This project focuses on a common issue for two apparently distinct research domains:</p>\r\n<ul>\r\n<li>The automatic analysis of a sound scene, from a learning process using a dictionary. In audio signal processing, we find this aspect in several major applications for example computational auditory scene analysis (CASA), automatic indexing, source separation, detection and localization of sound objects.</li>\r\n<li>Artificial hearing, a recent field of study in robotics, for which the analysis of a sound stage gradually becomes a prerequisite for any modern application (e.g. monitoring the elderly, or studying human-robot interaction).&nbsp;</li>\r\n</ul>\r\n<p>The central objective of the project is the design and development of a new method for the detection and localization of the main speaker in a sound scene. The method is intended to enable a robot to identify a vocal signal in the presence of noise and locate the main speaker&rsquo;s position, in the case where there are several speakers. The problem is closely related to the current field of computational auditory scene analysis (CASA). The objective of CASA is to design automatic systems with a perception that mimics human hearing, considering its physical and psycho-acoustical aspects. This project takes a different approach, while the audio processing tools are comparable (machine learning, source separation), hearing is treated from the robot&rsquo;s point of view and the interest lies in the analysis of the audio scene.</p>", "date_from": "2015-09-01", "date_to": "2016-09-30", "user": null, "type": "external", "external_id": "", "program": 7, "program_type": 6, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [1, 54], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 22, "fields": {"keywords_string": "", "site": 1, "title": "3DTVS", "title_fr": "3DTVS", "title_en": "3DTVS", "slug": "3dtvs", "_meta_title": "", "description": "\u00c9tude des techniques de description de contenus audiovisuels 3D", "description_fr": "\u00c9tude des techniques de description de contenus audiovisuels 3D", "description_en": "Study of techniques for description of 3D audiovisual contents", "gen_description": false, "created": "2016-09-07T14:43:32.933Z", "updated": "2018-06-29T08:53:57.452Z", "status": 2, "publish_date": "2016-09-07T14:43:32Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet 3DTvS est consacr&eacute; &agrave; l&rsquo;&eacute;tude des techniques de description de contenu, d&rsquo;indexation automatis&eacute;e, de recherche et de navigation dans les contenus audiovisuels tridimensionnels disponibles sur les plateformes mobiles et non mobiles, avec notamment pour objectif d&rsquo;am&eacute;liorer la performance des analyses du fait du format tridimensionnel des signaux audio et vid&eacute;o analys&eacute;s. Le projet vise &eacute;galement l&rsquo;enrichissement des indexations audio/vid&eacute;o par la multi-modalit&eacute; des approches. Le r&ocirc;le de l&rsquo;Ircam dans le projet porte sur les m&eacute;thodes d&rsquo;analyse de signaux audio spatialis&eacute;s (flux audio multicanal), afin d&rsquo;am&eacute;liorer l&rsquo;indexation et de fournir la localisation des sources dans l&rsquo;espace 3D.</p>", "content_fr": "<p>Le projet 3DTvS est consacr&eacute; &agrave; l&rsquo;&eacute;tude des techniques de description de contenu, d&rsquo;indexation automatis&eacute;e, de recherche et de navigation dans les contenus audiovisuels tridimensionnels disponibles sur les plateformes mobiles et non mobiles, avec notamment pour objectif d&rsquo;am&eacute;liorer la performance des analyses du fait du format tridimensionnel des signaux audio et vid&eacute;o analys&eacute;s. Le projet vise &eacute;galement l&rsquo;enrichissement des indexations audio/vid&eacute;o par la multi-modalit&eacute; des approches. Le r&ocirc;le de l&rsquo;Ircam dans le projet porte sur les m&eacute;thodes d&rsquo;analyse de signaux audio spatialis&eacute;s (flux audio multicanal), afin d&rsquo;am&eacute;liorer l&rsquo;indexation et de fournir la localisation des sources dans l&rsquo;espace 3D.</p>", "content_en": "<p>The 3DTvs project is dedicated to the study of description techniques for the contents, automatic indexing, searches, and browsing in three-dimensional audiovisual contents available on both mobile and stationary platforms. The objective of this project is to improve the performance of the analyses carried out on the three- dimensional formation of audio and video signals. The project also aims to expand audio/video indexing through the multimodality of the approaches. The role of IRCAM in this project focuses on the analysis methods for spatialized audio signals (multi-channel audio streams) in order to improve indexing and provide the localization of sound sources in three-dimensional space.</p>", "date_from": "2011-11-01", "date_to": "2015-01-31", "user": null, "type": "external", "external_id": "287674", "program": 8, "program_type": 7, "call": 17, "lead_team": null, "lead_organization": 66, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [71, 68, 67, 1, 70, 66, 69], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 23, "fields": {"keywords_string": "", "site": 1, "title": "MIReS", "title_fr": "MIReS", "title_en": "MIReS", "slug": "mires", "_meta_title": "", "description": "Roadmap for Music Information ReSearch", "description_fr": "Roadmap for Music Information ReSearch", "description_en": "Roadmap for Music Information ReSearch", "gen_description": false, "created": "2016-09-07T14:48:15.014Z", "updated": "2018-06-29T10:18:03.017Z", "status": 2, "publish_date": "2016-09-07T14:48:15Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet MIReS est une action de coordination et de support du 7<sup>e</sup> programme de la Commission europ&eacute;enne. Son objectif est d&rsquo;&eacute;laborer un &eacute;tat de l&rsquo;art et de proposer les directions du champ de recherche en Music Information Retrieval. Le projet &eacute;tudie notamment les challenges relatifs aux informations multimodales, multi-culturelles et pluridisciplinaires.</p>", "content_fr": "<p>Le projet MIReS est une action de coordination et de support du 7<sup>e</sup> programme de la Commission europ&eacute;enne. Son objectif est d&rsquo;&eacute;laborer un &eacute;tat de l&rsquo;art et de proposer les directions du champ de recherche en Music Information Retrieval. Le projet &eacute;tudie notamment les challenges relatifs aux informations multimodales, multi-culturelles et pluridisciplinaires.</p>", "content_en": "<p>MIReS project is a Coordination and support action funded by the 7th Framework Programme of the European Commission. MIReS project aims to create a research roadmap for Music Information Research. The project studies the challenges associated with multimodal, multicultural, and multidisciplinary information.</p>", "date_from": "2011-10-01", "date_to": "2013-03-31", "user": null, "type": "external", "external_id": "EC-287711", "program": 8, "program_type": 7, "call": 17, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [72, 76, 1, 77, 74, 75, 73], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 24, "fields": {"keywords_string": "", "site": 1, "title": "Recherche efficace de s\u00e9ries temporelles", "title_fr": "Recherche efficace de s\u00e9ries temporelles", "title_en": "Effective Searches of Temporal Series", "slug": "recherche-efficace-de-series-temporelles", "_meta_title": "", "description": "Syst\u00e8me g\u00e9n\u00e9rique permettant d\u2019effectuer des requ\u00eates efficaces sur des formes temporelles", "description_fr": "Syst\u00e8me g\u00e9n\u00e9rique permettant d\u2019effectuer des requ\u00eates efficaces sur des formes temporelles", "description_en": "Code that makes it possible to carry out effective searches on temporal forms", "gen_description": false, "created": "2016-09-07T14:54:57.866Z", "updated": "2018-06-29T09:14:34.115Z", "status": 2, "publish_date": "2016-09-07T14:54:57Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La recherche de sons peut s&rsquo;av&eacute;rer une t&acirc;che p&eacute;nible et laborieuse dans le cas de bases de donn&eacute;es massives. M&ecirc;me lorsque des m&eacute;ta-informations sont disponibles, les r&eacute;sultats restent souvent loin de la repr&eacute;sentation mentale imagin&eacute;e par l&rsquo;utilisateur. Aucun syst&egrave;me ne permet actuellement la projection intuitive d&rsquo;une id&eacute;e sonore en requ&ecirc;te efficace, les &eacute;chantillons sonores ne permettant pas la m&ecirc;me extraction d&rsquo;information de haut niveau que les chansons (e.g. m&eacute;lodie, paroles).</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Partant de cette observation, nous avons d&eacute;velopp&eacute; un syst&egrave;me g&eacute;n&eacute;rique permettant d&rsquo;effectuer des requ&ecirc;tes efficaces sur des formes temporelles et de prendre en compte la nature multidimensionelle de la perception sonore. Celle-ci permet d&rsquo;effectuer des requ&ecirc;tes bas&eacute;es sur la forme temporelle de descripteurs plut&ocirc;t que sur de simples valeurs moyenn&eacute;es. Ces descripteurs sont mod&eacute;lis&eacute;s pour obtenir leur moyenne, &eacute;cart-type ainsi que la forme de leur &eacute;volution temporelle gr&acirc;ce &agrave; une repr&eacute;sentation symbolique permettant &agrave; la fois un stockage compact et une recherche efficace. Cependant, il &eacute;tait primordial que la comparaison des s&eacute;ries temporelles permette d&rsquo;obtenir une similarit&eacute; bas&eacute;e sur des crit&egrave;res perceptifs pour des objets pouvant &ecirc;tre math&eacute;matiquement tr&egrave;s divergents. En utilisant une approche d&eacute;rivant du Dynamic Time Warping (DTW), nous avons d&eacute;velopp&eacute; une mesure de similarit&eacute; robuste suivant les distorsions non-lin&eacute;aires aussi bien d&rsquo;amplitude, de temps de bruit et de valeurs singuli&egrave;res. Gr&acirc;ce &agrave; un algorithme d&rsquo;indexation novateur, il est possible d&rsquo;obtenir presque instantan&eacute;ment le meilleur &eacute;l&eacute;ment d&rsquo;une base de plusieurs millions d&rsquo;&eacute;chantillons sonores.</p>\r\n<p>Notre &eacute;tude s&rsquo;est ensuite ouverte &agrave; l&rsquo;impl&eacute;mentation d&rsquo;interactions de plus haut niveau. Nous avons &eacute;tudi&eacute; la possibilit&eacute; d&rsquo;une recherche pertinente sur plusieurs courbes temporelles simultan&eacute;ment, d&eacute;passant le cadre de la simple pond&eacute;ration de crit&egrave;res souvent peu pertinente. Gr&acirc;ce &agrave; une heuristique novatrice, nous avons r&eacute;alis&eacute; le premier algorithme exact de recherche multi-objectif des s&eacute;ries temporelles.</p>\r\n<p>Ces techniques s&rsquo;appliquent &agrave; tous les champs de recherche scientifique de par l&rsquo;ubiquit&eacute; de l&rsquo;information temporelle. La recherche multi-objective de s&eacute;ries temporelles ouvre &agrave; de nombreuses applications dans divers domaines allant de l&rsquo;analyse m&eacute;dicale &agrave; la robotique. Celle-ci permet &eacute;galement la mise en place d&rsquo;un syst&egrave;me de requ&ecirc;te par imitation vocale bas&eacute; sur de multiples descripteurs spectraux.</p>\r\n<p>Toutes ces avanc&eacute;es ont &eacute;t&eacute; impl&eacute;ment&eacute;es dans une interface utilisant la technologie multi-touch de l&rsquo;iPad.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>La recherche de sons peut s&rsquo;av&eacute;rer une t&acirc;che p&eacute;nible et laborieuse dans le cas de bases de donn&eacute;es massives. M&ecirc;me lorsque des m&eacute;ta-informations sont disponibles, les r&eacute;sultats restent souvent loin de la repr&eacute;sentation mentale imagin&eacute;e par l&rsquo;utilisateur. Aucun syst&egrave;me ne permet actuellement la projection intuitive d&rsquo;une id&eacute;e sonore en requ&ecirc;te efficace, les &eacute;chantillons sonores ne permettant pas la m&ecirc;me extraction d&rsquo;information de haut niveau que les chansons (e.g. m&eacute;lodie, paroles).</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Partant de cette observation, nous avons d&eacute;velopp&eacute; un syst&egrave;me g&eacute;n&eacute;rique permettant d&rsquo;effectuer des requ&ecirc;tes efficaces sur des formes temporelles et de prendre en compte la nature multidimensionelle de la perception sonore. Celle-ci permet d&rsquo;effectuer des requ&ecirc;tes bas&eacute;es sur la forme temporelle de descripteurs plut&ocirc;t que sur de simples valeurs moyenn&eacute;es. Ces descripteurs sont mod&eacute;lis&eacute;s pour obtenir leur moyenne, &eacute;cart-type ainsi que la forme de leur &eacute;volution temporelle gr&acirc;ce &agrave; une repr&eacute;sentation symbolique permettant &agrave; la fois un stockage compact et une recherche efficace. Cependant, il &eacute;tait primordial que la comparaison des s&eacute;ries temporelles permette d&rsquo;obtenir une similarit&eacute; bas&eacute;e sur des crit&egrave;res perceptifs pour des objets pouvant &ecirc;tre math&eacute;matiquement tr&egrave;s divergents. En utilisant une approche d&eacute;rivant du Dynamic Time Warping (DTW), nous avons d&eacute;velopp&eacute; une mesure de similarit&eacute; robuste suivant les distorsions non-lin&eacute;aires aussi bien d&rsquo;amplitude, de temps de bruit et de valeurs singuli&egrave;res. Gr&acirc;ce &agrave; un algorithme d&rsquo;indexation novateur, il est possible d&rsquo;obtenir presque instantan&eacute;ment le meilleur &eacute;l&eacute;ment d&rsquo;une base de plusieurs millions d&rsquo;&eacute;chantillons sonores.</p>\r\n<p>Notre &eacute;tude s&rsquo;est ensuite ouverte &agrave; l&rsquo;impl&eacute;mentation d&rsquo;interactions de plus haut niveau. Nous avons &eacute;tudi&eacute; la possibilit&eacute; d&rsquo;une recherche pertinente sur plusieurs courbes temporelles simultan&eacute;ment, d&eacute;passant le cadre de la simple pond&eacute;ration de crit&egrave;res souvent peu pertinente. Gr&acirc;ce &agrave; une heuristique novatrice, nous avons r&eacute;alis&eacute; le premier algorithme exact de recherche multi-objectif des s&eacute;ries temporelles.</p>\r\n<p>Ces techniques s&rsquo;appliquent &agrave; tous les champs de recherche scientifique de par l&rsquo;ubiquit&eacute; de l&rsquo;information temporelle. La recherche multi-objective de s&eacute;ries temporelles ouvre &agrave; de nombreuses applications dans divers domaines allant de l&rsquo;analyse m&eacute;dicale &agrave; la robotique. Celle-ci permet &eacute;galement la mise en place d&rsquo;un syst&egrave;me de requ&ecirc;te par imitation vocale bas&eacute; sur de multiples descripteurs spectraux.</p>\r\n<p>Toutes ces avanc&eacute;es ont &eacute;t&eacute; impl&eacute;ment&eacute;es dans une interface utilisant la technologie multi-touch de l&rsquo;iPad.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>Searching for sounds can be a painful and tedious task when dealing with large-scale databases. Even when metainformation is available, query results are often far from the mental image imagined by the user. Today, there is no system that transforms the intuitive projection of a sound idea into an effective search; sound samples do not let users extract high-level information such as melody or lyrics from songs.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>Beginning with this observation, we have developed a code that makes it possible to carry out effective searches on temporal forms and take into account the multidimensional nature of sound perception. This makes it possible to carry out searches based on the temporal form of the descriptors rather than on mean values. These descriptors are modeled to obtain their average, standard deviation as well as the form of their temporal evolution via a symbolic representation enabling both compact storage and an effective search. However, it was essential that the comparison of temporal series that make it possible to obtain a similarity based on perceptive criteria for objects that could possibly be very different mathematically. Using an approach derived from Dynamic Time Warping (DTW), we have developed a robust measure of similarity following non-linear distortions such as range, noise sound, and unique values. Thanks to a new algorithm for indexing, it is possible to obtain the best element from a database containing several million sound samples almost immediately.</p>\r\n<p>Our study then opened to the implementation of higher-lever interactions. We studied the possibility of a query that is pertinent to several temporal curves simultaneously, going beyond the framework of the simple consideration of often less relevant criteria. Thanks to new heuristics, we have carried out the first precise multi-objective search algorithm for temporal series.</p>\r\n<p>These techniques apply to all fields of scientific research due to the ubiquity of the temporal information. Multi-objective searches of temporal series are open to numerous applications in fields ranging from medical analysis to robotics.This also enables the installation of a system of request by vocal imitation based on multiples of spectral descriptors.</p>\r\n<p>These advances have been implemented in an interface using iPad multi-touch technology.</p>\r\n<p>IRCAM's team: <a href=\"/recherche/equipes-recherche/repmus/\">Musical Representations team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 25, "fields": {"keywords_string": "", "site": 1, "title": "Houle", "title_fr": "Houle", "title_en": "Houle", "slug": "houle", "_meta_title": "", "description": "Hierarchical Object based Unsupervised Learning", "description_fr": "Hierarchical Object based Unsupervised Learning", "description_en": "Hierarchical Object based Unsupervised Learning", "gen_description": false, "created": "2016-09-07T15:01:47.916Z", "updated": "2018-07-25T14:39:42.084Z", "status": 2, "publish_date": "2016-09-07T15:01:47Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Dans le cadre du projet HOULE, nous proposons des techniques originales d&rsquo;apprentissage non supervis&eacute; pour r&eacute;soudre le probl&egrave;me de la structuration des sc&egrave;nes auditives (Computational Auditory Scene Analysis : CASA), probl&egrave;me consistant &agrave; identifier et d&eacute;crire les objets sonores constituant une sc&egrave;ne. CASA est un domaine tr&egrave;s actif du traitement du son ayant de nombreuses applications. Les points bloquant les m&eacute;thodes actuelles sont :</p>\r\n<ul>\r\n<li>Ne pouvant faire d&rsquo;hypoth&egrave;se sur la nature des objets trait&eacute;s, on ne peut les mod&eacute;liser a priori ;</li>\r\n<li>Les objets m&eacute;lang&eacute;s dans la sc&egrave;ne ne peuvent &ecirc;tre observ&eacute;s en isolation ;</li>\r\n<li>Leur structure est gouvern&eacute;e par de nombreuses relations dont la priorit&eacute; est difficile &agrave; &eacute;tablir.</li>\r\n</ul>\r\n<p>Les caract&eacute;ristiques dont nous tirons parti pour notre approche sont, l&rsquo;organisation hi&eacute;rarchique des sc&egrave;nes audio (atomes rassembl&eacute;s en objets qui sont des instances de classes comme &laquo; La4 de piano &raquo;, elle-m&ecirc;me un exemple de &laquo; Note de piano &raquo;), et la redondance pr&eacute;sente &agrave; tous les niveaux de cette hi&eacute;rarchie. Cette redondance nous permet d&rsquo;identifier des motifs r&eacute;currents sur lesquels fonder une repr&eacute;sentation riche et robuste.</p>\r\n<p>&Agrave; cette nouvelle approche de la repr&eacute;sentation de sc&egrave;nes audio correspond un algorithme d&rsquo;apprentissage non supervis&eacute; sp&eacute;cialement con&ccedil;u pour traiter ces donn&eacute;es. Le syst&egrave;me est structur&eacute; en deux composants : le Regroupement Multi-Niveaux (RMN) op&egrave;re la structuration des donn&eacute;es, tandis que le &laquo; Superviseur &raquo; (module d&rsquo;adaptation r&eacute;flexive) incarne l&rsquo;aspect &laquo; apprentissage &raquo; en optimisant &agrave; la vol&eacute;e le fonctionnement de RMN en r&eacute;f&eacute;rence &agrave; une m&eacute;moire d&rsquo;ex&eacute;cutions pass&eacute;es.</p>\r\n<p>L&rsquo;originalit&eacute; de notre proposition tient dans son d&eacute;tachement des approches traditionnelles &agrave; CASA, en commen&ccedil;ant par le paradigme de repr&eacute;sentation des sc&egrave;nes et objets. L&rsquo;innovation est principalement pr&eacute;sente dans les m&eacute;thodes d&rsquo;apprentissage non supervis&eacute; que nous allons d&eacute;velopper, dont les applications d&eacute;passent largement le cadre de CASA.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : 2011-JS03-005-01.</p>", "content_fr": "<p>Dans le cadre du projet HOULE, nous proposons des techniques originales d&rsquo;apprentissage non supervis&eacute; pour r&eacute;soudre le probl&egrave;me de la structuration des sc&egrave;nes auditives (Computational Auditory Scene Analysis : CASA), probl&egrave;me consistant &agrave; identifier et d&eacute;crire les objets sonores constituant une sc&egrave;ne. CASA est un domaine tr&egrave;s actif du traitement du son ayant de nombreuses applications. Les points bloquant les m&eacute;thodes actuelles sont :</p>\r\n<ul>\r\n<li>Ne pouvant faire d&rsquo;hypoth&egrave;se sur la nature des objets trait&eacute;s, on ne peut les mod&eacute;liser a priori ;</li>\r\n<li>Les objets m&eacute;lang&eacute;s dans la sc&egrave;ne ne peuvent &ecirc;tre observ&eacute;s en isolation ;</li>\r\n<li>Leur structure est gouvern&eacute;e par de nombreuses relations dont la priorit&eacute; est difficile &agrave; &eacute;tablir.</li>\r\n</ul>\r\n<p>Les caract&eacute;ristiques dont nous tirons parti pour notre approche sont, l&rsquo;organisation hi&eacute;rarchique des sc&egrave;nes audio (atomes rassembl&eacute;s en objets qui sont des instances de classes comme &laquo; La4 de piano &raquo;, elle-m&ecirc;me un exemple de &laquo; Note de piano &raquo;), et la redondance pr&eacute;sente &agrave; tous les niveaux de cette hi&eacute;rarchie. Cette redondance nous permet d&rsquo;identifier des motifs r&eacute;currents sur lesquels fonder une repr&eacute;sentation riche et robuste.</p>\r\n<p>&Agrave; cette nouvelle approche de la repr&eacute;sentation de sc&egrave;nes audio correspond un algorithme d&rsquo;apprentissage non supervis&eacute; sp&eacute;cialement con&ccedil;u pour traiter ces donn&eacute;es. Le syst&egrave;me est structur&eacute; en deux composants : le Regroupement Multi-Niveaux (RMN) op&egrave;re la structuration des donn&eacute;es, tandis que le &laquo; Superviseur &raquo; (module d&rsquo;adaptation r&eacute;flexive) incarne l&rsquo;aspect &laquo; apprentissage &raquo; en optimisant &agrave; la vol&eacute;e le fonctionnement de RMN en r&eacute;f&eacute;rence &agrave; une m&eacute;moire d&rsquo;ex&eacute;cutions pass&eacute;es.</p>\r\n<p>L&rsquo;originalit&eacute; de notre proposition tient dans son d&eacute;tachement des approches traditionnelles &agrave; CASA, en commen&ccedil;ant par le paradigme de repr&eacute;sentation des sc&egrave;nes et objets. L&rsquo;innovation est principalement pr&eacute;sente dans les m&eacute;thodes d&rsquo;apprentissage non supervis&eacute; que nous allons d&eacute;velopper, dont les applications d&eacute;passent largement le cadre de CASA.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : 2011-JS03-005-01.</p>", "content_en": "<p>In the context of the HOULE project, IRCAM suggests innovative unsupervised learning techniques to solve the problem of the structuring of audio scenes (Computational Auditory Scene Analysis: CASA); a problem that consists of identifying and describing sound objects that make up a scene. CASA is a very active domain of sound processing with numerous applications. The points that block the current methods are:</p>\r\n<ul>\r\n<li>Without being able to draw up a hypothesis on the nature of the processed objects, we can not model them</li>\r\n<li>The objects combined in the scene can not be observed isolated from each other</li>\r\n<li>The structure of the objects is governed by numerous relationships that is difficult to prioritize</li>\r\n</ul>\r\n<p>The characteristics that we will use for our approach are the hierarchal organization of audio scenes (atoms brought together in objects that are examples of classes such as &ldquo;Piano A4&rdquo;, itself an example of &ldquo;Piano note&rdquo;) and the redundancy present at all levels of this hierarchy. This redundancy enables us to identify reoccurring motifs on which a rich and robust representation can be based.</p>\r\n<p>This new method of representing audio scenes has led to the creation of an unsupervised learning algorithm designed expressly to process this data. The system features two components: the MLG (multi-level grouping) that structures the data and the Supervisor (a reflexive adaptation module) embodies the learning aspect by optimizing the MLG function on-the-fly in reference to the stocked memories of past executions.</p>\r\n<p>The originality of our proposition lies in its distance from traditional CASA approaches, beginning with the paradigm of representing scenes and objects. Innovation is primarily present in the unsupervised learning methods that we will develop, including applications that go well beyond the CASA framework.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: 2011-JS03-005-01.</p>", "date_from": "2011-09-01", "date_to": "2015-01-31", "user": null, "type": "external", "external_id": "2011-JS03-005-01", "program": 1, "program_type": 8, "call": 18, "lead_team": null, "lead_organization": 1, "website": "http://houle.ircam.fr/", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 3, 5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 26, "fields": {"keywords_string": "", "site": 1, "title": "Reconnaissance des hauteurs dans les sons polyphoniques", "title_fr": "Reconnaissance des hauteurs dans les sons polyphoniques", "title_en": "Pitch Recognition in a Polyphonic Context", "slug": "reconnaissance-des-hauteurs-dans-les-sons-polyphoniques", "_meta_title": "", "description": "", "description_fr": "", "description_en": "", "gen_description": false, "created": "2016-09-07T15:04:06.095Z", "updated": "2017-02-10T16:27:37.991Z", "status": 1, "publish_date": "2016-09-07T15:04:06Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Cette &eacute;tude concerne les hauteurs des diff&eacute;rents sons dans les enregistrements polyphoniques.</p>\r\n<p>La m&eacute;thode est fond&eacute;e sur des analyses en fr&eacute;quence et la caract&eacute;risation statistique des composantes en sinuso&iuml;des harmoniques et bruits. Un certain nombre de fr&eacute;quences fondamentales est d&eacute;termin&eacute; pour expliquer de fa&ccedil;on optimale les composantes harmoniques trouv&eacute;es et d&eacute;finissent ainsi les sons de la polyphonie et leurs hauteurs. Les applications concernent l&rsquo;analyse musicale, le traitement des sons polyphoniques, la reconnaissance des instruments et la s&eacute;paration des sources.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_fr": "<p>Cette &eacute;tude concerne les hauteurs des diff&eacute;rents sons dans les enregistrements polyphoniques.</p>\r\n<p>La m&eacute;thode est fond&eacute;e sur des analyses en fr&eacute;quence et la caract&eacute;risation statistique des composantes en sinuso&iuml;des harmoniques et bruits. Un certain nombre de fr&eacute;quences fondamentales est d&eacute;termin&eacute; pour expliquer de fa&ccedil;on optimale les composantes harmoniques trouv&eacute;es et d&eacute;finissent ainsi les sons de la polyphonie et leurs hauteurs. Les applications concernent l&rsquo;analyse musicale, le traitement des sons polyphoniques, la reconnaissance des instruments et la s&eacute;paration des sources.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_en": "<p>This study concerns the pitch of different sounds in polyphonic recordings.</p>\r\n<p>The method used is based on frequency analyses and the statistical characterization of the sinusoidal characteristics of harmonics and sounds. A certain number of fundamental frequencies are chosen to best explain the harmonic components found and consequently define the polyphonic sounds and their different pitches. Applications are related to musical analysis, polyphonic sound processing, instrument recognition, and the separation of sound sources.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Sound Analysis &amp; Synthesis team</a>.</p>\r\n<p></p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 27, "fields": {"keywords_string": "", "site": 1, "title": "Mod\u00e9lisation des flux audio et g\u00e9om\u00e9trie de l'information", "title_fr": "Mod\u00e9lisation des flux audio et g\u00e9om\u00e9trie de l'information", "title_en": "Modeling Audio Flows and the Geometry of Information", "slug": "modelisation-des-flux-audio-et-geometrie-de-linformation", "_meta_title": "", "description": "", "description_fr": "", "description_en": "", "gen_description": false, "created": "2016-09-07T15:07:11.150Z", "updated": "2017-02-10T16:20:57.891Z", "status": 2, "publish_date": "2016-09-07T15:07:11Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Un signal audio-num&eacute;rique contient de multiples flux d&rsquo;informations de haut niveau comme des notes, des instruments, la forme musicale, etc. L&rsquo;analyse et l&rsquo;extraction de ces contenus est une probl&eacute;matique r&eacute;currente des sciences et technologies de l&rsquo;information musicale, qui essaie de rapprocher les deux aspects symbolique et signal&eacute;tique du son.</p>\r\n<p>L&rsquo;objectif de ce projet est d&rsquo;utiliser les outils r&eacute;cents de la recherche en g&eacute;om&eacute;trie de l&rsquo;information pour proposer des nouveaux paradigmes en traitement et repr&eacute;sentation du signal audio.</p>\r\n<p>La g&eacute;om&eacute;trie de l&rsquo;information est un domaine r&eacute;cent des math&eacute;matiques qui &eacute;tudie les notions de probabilit&eacute; et d&rsquo;information par le biais de la g&eacute;om&eacute;trie diff&eacute;rentielle. L&rsquo;id&eacute;e principale est de trouver des nouveaux moyens de repr&eacute;sentation des flux d&rsquo;information qui permettent de d&eacute;crire et d&rsquo;atteindre des contenus de haut niveau dans un flux audio temps r&eacute;el. Ayant acc&egrave;s &agrave; ces contenus, diverses applications artistiques et industrielles deviennent possibles : fouille de donn&eacute;es musicales, reconnaissance en temps r&eacute;el des donn&eacute;es musicales et improvisation automatique.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>Un signal audio-num&eacute;rique contient de multiples flux d&rsquo;informations de haut niveau comme des notes, des instruments, la forme musicale, etc. L&rsquo;analyse et l&rsquo;extraction de ces contenus est une probl&eacute;matique r&eacute;currente des sciences et technologies de l&rsquo;information musicale, qui essaie de rapprocher les deux aspects symbolique et signal&eacute;tique du son.</p>\r\n<p>L&rsquo;objectif de ce projet est d&rsquo;utiliser les outils r&eacute;cents de la recherche en g&eacute;om&eacute;trie de l&rsquo;information pour proposer des nouveaux paradigmes en traitement et repr&eacute;sentation du signal audio.</p>\r\n<p>La g&eacute;om&eacute;trie de l&rsquo;information est un domaine r&eacute;cent des math&eacute;matiques qui &eacute;tudie les notions de probabilit&eacute; et d&rsquo;information par le biais de la g&eacute;om&eacute;trie diff&eacute;rentielle. L&rsquo;id&eacute;e principale est de trouver des nouveaux moyens de repr&eacute;sentation des flux d&rsquo;information qui permettent de d&eacute;crire et d&rsquo;atteindre des contenus de haut niveau dans un flux audio temps r&eacute;el. Ayant acc&egrave;s &agrave; ces contenus, diverses applications artistiques et industrielles deviennent possibles : fouille de donn&eacute;es musicales, reconnaissance en temps r&eacute;el des donn&eacute;es musicales et improvisation automatique.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>A digital audio signal contains multiple flows of high-level information such as notes, instruments, and the musical form. The analysis and extraction of these contents is a recurrent problem in science and computer-music technologies that attempts to bring these two aspects of sound&mdash;symbolic and identifying&mdash;closer together.</p>\r\n<p>The objective of this project is to use tools recently created for the geometry of information to suggest new paradigms for audio signal processing and representation.</p>\r\n<p>The geometry of information is a recent mathematical domain that studies notions of probability and information via differential geometry. The principle idea is <br />to find new means of representing information flows, making it possible to describe and reach high-level contents within a real-time audio flow. Easily accessing this information makes diverse artistic and industrial applications possible such as searching musical data, real-time recognition of musical data, and automatic improvisation.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [], "organizations": [79, 1, 78, 80], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 28, "fields": {"keywords_string": "", "site": 1, "title": "SemanticHIFI", "title_fr": "SemanticHIFI", "title_en": "SemanticHIFI", "slug": "semantichifi", "_meta_title": "", "description": "Naviguer, \u00e9couter, interagir, jouer, partager sur les syst\u00e8mes HiFi du futur", "description_fr": "Naviguer, \u00e9couter, interagir, jouer, partager sur les syst\u00e8mes HiFi du futur", "description_en": "Browsing, listening, interacting, performing, sharing on future HIFI systems", "gen_description": false, "created": "2016-09-07T15:13:26.946Z", "updated": "2018-06-29T10:18:15.258Z", "status": 2, "publish_date": "2016-09-07T15:13:26Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Dans la continuit&eacute; du projet Cuidado et dans le contexte de la distribution de musique num&eacute;rique &agrave; grande &eacute;chelle, le but du projet &eacute;tait de d&eacute;velopper une nouvelle g&eacute;n&eacute;ration des th&egrave;mes de haute-fid&eacute;lit&eacute;, offrant de nouvelles fonctionnalit&eacute;s pour la navigation, l&rsquo;interaction, le rendu, la personnalisation et l&rsquo;&eacute;dition du mat&eacute;riel musical. Reposant sur la diffusion d&rsquo;informations musicales enrichies au-del&agrave; des seuls enregistrements sonores, ainsi que sur la mise en &oelig;uvre d&rsquo;outils d&rsquo;indexation et d&rsquo;interfaces de navigation personnalis&eacute;s, le projet vise un changement radical des pratiques d&rsquo;acc&egrave;s &agrave; la musique et d&rsquo;&eacute;coute instrument&eacute;e, au point de brouiller les limites traditionnelles entre l&rsquo;&eacute;coute et l&rsquo;ex&eacute;cution.</p>\r\n<p>Ces syst&egrave;mes de haute-fid&eacute;lit&eacute; seront des stations d&rsquo;&eacute;coute autant que des instruments ouverts et sont &agrave; m&ecirc;me de constituer des vecteurs technologiques d&rsquo;une nouvelle intelligibilit&eacute; de la musique.</p>\r\n<p>Principales fonctions vis&eacute;es :</p>\r\n<ul>\r\n<li>Classement personnalis&eacute; et navigation par le contenu entre morceaux de musique ; recherche par chantonnement ;</li>\r\n<li>G&eacute;n&eacute;ration automatique de listes de morceaux &agrave; partir de crit&egrave;res globaux ;</li>\r\n<li>Spatialisation domestique des sons de tr&egrave;s haute qualit&eacute; avec compensation automatique du contexte d&rsquo;&eacute;coute ;</li>\r\n<li>Navigation &agrave; l&rsquo;int&eacute;rieur de la polyphonie et mixage assist&eacute; ;</li>\r\n<li>Navigation &agrave; l&rsquo;int&eacute;rieur de morceaux de musique ;</li>\r\n<li>Outils d&rsquo;&eacute;dition et de composition personnalis&eacute;s, application DJ ;</li>\r\n<li>Outils de jeu instrumental et vocal, accompagnement automatique ;</li>\r\n<li>Partage du travail d&rsquo;indexation, de composition et de jeu sur r&eacute;seaux peer-to-peer.</li>\r\n</ul>", "content_fr": "<p>Dans la continuit&eacute; du projet Cuidado et dans le contexte de la distribution de musique num&eacute;rique &agrave; grande &eacute;chelle, le but du projet &eacute;tait de d&eacute;velopper une nouvelle g&eacute;n&eacute;ration des th&egrave;mes de haute-fid&eacute;lit&eacute;, offrant de nouvelles fonctionnalit&eacute;s pour la navigation, l&rsquo;interaction, le rendu, la personnalisation et l&rsquo;&eacute;dition du mat&eacute;riel musical. Reposant sur la diffusion d&rsquo;informations musicales enrichies au-del&agrave; des seuls enregistrements sonores, ainsi que sur la mise en &oelig;uvre d&rsquo;outils d&rsquo;indexation et d&rsquo;interfaces de navigation personnalis&eacute;s, le projet vise un changement radical des pratiques d&rsquo;acc&egrave;s &agrave; la musique et d&rsquo;&eacute;coute instrument&eacute;e, au point de brouiller les limites traditionnelles entre l&rsquo;&eacute;coute et l&rsquo;ex&eacute;cution.</p>\r\n<p>Ces syst&egrave;mes de haute-fid&eacute;lit&eacute; seront des stations d&rsquo;&eacute;coute autant que des instruments ouverts et sont &agrave; m&ecirc;me de constituer des vecteurs technologiques d&rsquo;une nouvelle intelligibilit&eacute; de la musique.</p>\r\n<p>Principales fonctions vis&eacute;es :</p>\r\n<ul>\r\n<li>Classement personnalis&eacute; et navigation par le contenu entre morceaux de musique ; recherche par chantonnement ;</li>\r\n<li>G&eacute;n&eacute;ration automatique de listes de morceaux &agrave; partir de crit&egrave;res globaux ;</li>\r\n<li>Spatialisation domestique des sons de tr&egrave;s haute qualit&eacute; avec compensation automatique du contexte d&rsquo;&eacute;coute ;</li>\r\n<li>Navigation &agrave; l&rsquo;int&eacute;rieur de la polyphonie et mixage assist&eacute; ;</li>\r\n<li>Navigation &agrave; l&rsquo;int&eacute;rieur de morceaux de musique ;</li>\r\n<li>Outils d&rsquo;&eacute;dition et de composition personnalis&eacute;s, application DJ ;</li>\r\n<li>Outils de jeu instrumental et vocal, accompagnement automatique ;</li>\r\n<li>Partage du travail d&rsquo;indexation, de composition et de jeu sur r&eacute;seaux peer-to-peer.</li>\r\n</ul>", "content_en": "<p>In the context of large-scale digital music distribution, the goal of the project was to develop a new generation of Hi-Fi systems, offering new functionality for browsing, interacting, rendering, personalizing and editing musical material. This next generation of hard-disk based Hi-Fi systems will drastically change the home users&rsquo; relationship to music and multimedia content. They will be able to interact with music, blurring the traditional limits between playing, performing and remixing.</p>\r\n<p>These Hi-Fi systems will be as much open instruments as listening stations.</p>\r\n<p>Main Functions Proposed:</p>\r\n<ul>\r\n<li>Personalized classification and content-based management of music pieces; query by humming; automated playlist</li>\r\n<li>Generation specified by global and content-based criteria</li>\r\n<li>High-quality home sound spatialization with automatic compensation of the acoustic listening context; 3D audio real-time navigation in the sound scene with assisted mixing, browsing within musical pieces,</li>\r\n<li>Personalized editing and composition tools, DJ application</li>\r\n<li>Instrumental and vocal tools and automatic accompaniment,</li>\r\n<li>Sharing of the indexing, composition, and performance work through P2P network</li>\r\n</ul>", "date_from": "2003-12-01", "date_to": "2006-11-30", "user": null, "type": "external", "external_id": "", "program": 8, "program_type": 9, "call": null, "lead_team": null, "lead_organization": 1, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 2, 7], "organizations": [81, 85, 83, 86, 84, 82], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 29, "fields": {"keywords_string": "", "site": 1, "title": "Analyse du champ sonore par r\u00e9seaux sph\u00e9riques de transducteurs", "title_fr": "Analyse du champ sonore par r\u00e9seaux sph\u00e9riques de transducteurs", "title_en": "Analysis of a Sound Scene through Spherical arrays of Transducers", "slug": "analyse-du-champ-sonore-par-reseaux-spheriques-de-transducteurs", "_meta_title": "", "description": "", "description_fr": "", "description_en": "", "gen_description": false, "created": "2016-09-07T15:38:07.494Z", "updated": "2018-06-29T10:36:01.045Z", "status": 2, "publish_date": "2016-09-07T15:38:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les propri&eacute;t&eacute;s spatiales d&rsquo;un champ sonore sont d&eacute;terminantes pour la perception des sons dans une salle. Ces propri&eacute;t&eacute;s spatiales sont traditionnellement &eacute;tudi&eacute;es en s&rsquo;appuyant s&eacute;par&eacute;ment, soit sur des r&eacute;seaux de microphones, soit sur des r&eacute;seaux de haut-parleurs. Les mesures combinant simultan&eacute;ment des r&eacute;seaux microphoniques et des r&eacute;seaux de haut-parleurs, d&eacute;nomm&eacute;s MIMO (multiple-input multiple-output) permettent d&rsquo;enrichir la description du champ sonore. En recourant &agrave; des syst&egrave;mes MIMO, les r&eacute;ponses impulsionnelles de salle peuvent &ecirc;tre repr&eacute;sent&eacute;es de mani&egrave;re matricielle et l&rsquo;analyse des propri&eacute;t&eacute;s spatiales du champ sonore peut faire appel aux outils de l&rsquo;alg&egrave;bre lin&eacute;aire. Par exemple, le rang de la matrice et son noyau permettent de r&eacute;v&eacute;ler des informations int&eacute;ressantes comme le nombre de r&eacute;flexions significatives, leur direction d&rsquo;incidence sur le microphone et leur direction d&rsquo;&eacute;mission depuis le haut-parleur. Ce projet fait l&rsquo;objet de travaux th&eacute;oriques sur la formalisation du probl&egrave;me et l&rsquo;optimisation des r&eacute;seaux de transducteurs sph&eacute;riques et associe par ailleurs un volet exp&eacute;rimental consacr&eacute; &agrave; l&rsquo;analyse acoustique des salles.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_fr": "<p>Les propri&eacute;t&eacute;s spatiales d&rsquo;un champ sonore sont d&eacute;terminantes pour la perception des sons dans une salle. Ces propri&eacute;t&eacute;s spatiales sont traditionnellement &eacute;tudi&eacute;es en s&rsquo;appuyant s&eacute;par&eacute;ment, soit sur des r&eacute;seaux de microphones, soit sur des r&eacute;seaux de haut-parleurs. Les mesures combinant simultan&eacute;ment des r&eacute;seaux microphoniques et des r&eacute;seaux de haut-parleurs, d&eacute;nomm&eacute;s MIMO (multiple-input multiple-output) permettent d&rsquo;enrichir la description du champ sonore. En recourant &agrave; des syst&egrave;mes MIMO, les r&eacute;ponses impulsionnelles de salle peuvent &ecirc;tre repr&eacute;sent&eacute;es de mani&egrave;re matricielle et l&rsquo;analyse des propri&eacute;t&eacute;s spatiales du champ sonore peut faire appel aux outils de l&rsquo;alg&egrave;bre lin&eacute;aire. Par exemple, le rang de la matrice et son noyau permettent de r&eacute;v&eacute;ler des informations int&eacute;ressantes comme le nombre de r&eacute;flexions significatives, leur direction d&rsquo;incidence sur le microphone et leur direction d&rsquo;&eacute;mission depuis le haut-parleur. Ce projet fait l&rsquo;objet de travaux th&eacute;oriques sur la formalisation du probl&egrave;me et l&rsquo;optimisation des r&eacute;seaux de transducteurs sph&eacute;riques et associe par ailleurs un volet exp&eacute;rimental consacr&eacute; &agrave; l&rsquo;analyse acoustique des salles.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_en": "<p>The spatial properties of a sound scene are determinant for the perception of sounds in a room. These spatial properties are usually studied through separate investigations of either the array of microphones, or the array of loudspeakers. Measures that take into account both the microphone and the loudspeaker arrays, called MIMO (multiple-input multiple-output), make it possible to augment the description of the sound scene. By using MIMO systems, the impulse responses of the room can be represented using a matrix and the analysis of the sound scene&rsquo;s spatial properties can call upon linear algebra tools. For example, the rank of the matrix and its kernel reveal interesting information such as the number of significant reflections, the direction of their incidences on the microphone, and the direction of their emission from the loudspeakers. This project is the object of theoretical work of the formalization of the problem and the optimization of arrays of spherical transducers and also includes an experimental aspect dedicated to the acoustic analysis of rooms.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Acoustic and Cognitive Spaces team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [1, 87, 84], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 30, "fields": {"keywords_string": "", "site": 1, "title": "Syst\u00e8me WFS et ambisonique \u00e0 l'Espace de projection", "title_fr": "Syst\u00e8me WFS et ambisonique \u00e0 l'Espace de projection", "title_en": "WFS and Ambisonic Systems in the Espace de Projection", "slug": "systeme-wfs-et-ambisonique-a-lespace-de-projection", "_meta_title": "", "description": "", "description_fr": "", "description_en": "", "gen_description": false, "created": "2016-09-07T15:44:56.148Z", "updated": "2018-06-29T10:35:44.959Z", "status": 2, "publish_date": "2016-09-07T15:44:56Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La technique Wave Field Synthesis (WFS) d&eacute;signe un proc&eacute;d&eacute; de reproduction holophonique qui permet, par analogie avec les hologrammes visuels, de capter ou synth&eacute;tiser une sc&egrave;ne sonore en pr&eacute;servant les informations spatiales de distance et de direction des sources qui la composent.</p>\r\n<p>Cette approche, initi&eacute;e par l&rsquo;universit&eacute; de Delft, d&eacute;passe les limites des syst&egrave;mes conventionnels en termes de fid&eacute;lit&eacute; de reproduction sur une zone d&rsquo;&eacute;coute &eacute;tendue. Tandis que les techniques st&eacute;r&eacute;ophoniques conventionnelles (st&eacute;r&eacute;o, 5.1) s&rsquo;apparentent au trompe-l&rsquo;&oelig;il et ne peuvent ainsi &ecirc;tre appr&eacute;ci&eacute;es que depuis le centre du dispositif, l&rsquo;holophonie a l&rsquo;ambition de reconstruire un champ sonore dans lequel les auditeurs peuvent se d&eacute;placer en gardant une perception coh&eacute;rente de la localisation des sources.</p>\r\n<p>L&rsquo;Ircam a acquis une exp&eacute;rience dans ce mode de reproduction gr&acirc;ce &agrave; sa participation au projet europ&eacute;en Carrouso et en collaboration avec l&rsquo;entreprise sonic emotion bas&eacute;e en Suisse. Ces &eacute;tudes ont permis de mener diff&eacute;rentes op&eacute;rations de production en partenariat avec le Centre Pompidou pour les expositions Dada (2005) et Beckett (2007) ainsi qu&rsquo;une installation interactive en juin 2006 (collaboration N+N Corsino).</p>\r\n<p>Au cours des ann&eacute;es 2008-2011, gr&acirc;ce au soutien de la r&eacute;gion &Icirc;le-de-France, du CNRS et de l&rsquo;UPMC, l&rsquo;Ircam a fait l&rsquo;acquisition d&rsquo;un syst&egrave;me de diffusion WFS install&eacute; dans l&rsquo;Espace de projection.&nbsp; Le syst&egrave;me est compos&eacute;, d&rsquo;une part, d&rsquo;une couronne horizontale de 264 haut-parleurs r&eacute;guli&egrave;rement r&eacute;partis autour de la sc&egrave;ne et du public pour la diffusion en WFS et d&rsquo;autre part d&rsquo;un d&ocirc;me de 75 haut-parleurs pour une diffusion tridimensionnelle en mode Ambisonique. Cet &eacute;quipement a pour double vocation de susciter l&rsquo;exploration de nouvelles modalit&eacute;s de spatialisation pour la cr&eacute;ation musicale et de permettre la mise en &oelig;uvre d&rsquo;exp&eacute;riences &agrave; caract&egrave;re scientifique consacr&eacute;es &agrave; la r&eacute;alit&eacute; virtuelle et la cognition spatiale. Un premier volet de cet &eacute;quipement, inaugur&eacute; en novembre 2008, a &eacute;t&eacute; exploit&eacute; depuis dans le cadre de cr&eacute;ations musicales (<em>Operspective H&ouml;lderlin</em> de P. Schoeller en juin 2009, <em>Le P&egrave;re</em> de M. Jarrell en juin 2010, <em>Mimesis</em> de M.Garcia-vitoria en octobre 2011) et de repr&eacute;sentations th&eacute;&acirc;trales dans la Cour d&rsquo;honneur du Palais des papes &agrave; Avignon (<em>La Trag&eacute;die du Roi Richard II</em>, mise en sc&egrave;ne J.-B. Sastre, juillet 2010). L&rsquo;&eacute;quipement complet a &eacute;t&eacute; inaugur&eacute; le 28 novembre 2012.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_fr": "<p>La technique Wave Field Synthesis (WFS) d&eacute;signe un proc&eacute;d&eacute; de reproduction holophonique qui permet, par analogie avec les hologrammes visuels, de capter ou synth&eacute;tiser une sc&egrave;ne sonore en pr&eacute;servant les informations spatiales de distance et de direction des sources qui la composent.</p>\r\n<p>Cette approche, initi&eacute;e par l&rsquo;universit&eacute; de Delft, d&eacute;passe les limites des syst&egrave;mes conventionnels en termes de fid&eacute;lit&eacute; de reproduction sur une zone d&rsquo;&eacute;coute &eacute;tendue. Tandis que les techniques st&eacute;r&eacute;ophoniques conventionnelles (st&eacute;r&eacute;o, 5.1) s&rsquo;apparentent au trompe-l&rsquo;&oelig;il et ne peuvent ainsi &ecirc;tre appr&eacute;ci&eacute;es que depuis le centre du dispositif, l&rsquo;holophonie a l&rsquo;ambition de reconstruire un champ sonore dans lequel les auditeurs peuvent se d&eacute;placer en gardant une perception coh&eacute;rente de la localisation des sources.</p>\r\n<p>L&rsquo;Ircam a acquis une exp&eacute;rience dans ce mode de reproduction gr&acirc;ce &agrave; sa participation au projet europ&eacute;en Carrouso et en collaboration avec l&rsquo;entreprise sonic emotion bas&eacute;e en Suisse. Ces &eacute;tudes ont permis de mener diff&eacute;rentes op&eacute;rations de production en partenariat avec le Centre Pompidou pour les expositions Dada (2005) et Beckett (2007) ainsi qu&rsquo;une installation interactive en juin 2006 (collaboration N+N Corsino).</p>\r\n<p>Au cours des ann&eacute;es 2008-2011, gr&acirc;ce au soutien de la r&eacute;gion &Icirc;le-de-France, du CNRS et de l&rsquo;UPMC, l&rsquo;Ircam a fait l&rsquo;acquisition d&rsquo;un syst&egrave;me de diffusion WFS install&eacute; dans l&rsquo;Espace de projection.&nbsp; Le syst&egrave;me est compos&eacute;, d&rsquo;une part, d&rsquo;une couronne horizontale de 264 haut-parleurs r&eacute;guli&egrave;rement r&eacute;partis autour de la sc&egrave;ne et du public pour la diffusion en WFS et d&rsquo;autre part d&rsquo;un d&ocirc;me de 75 haut-parleurs pour une diffusion tridimensionnelle en mode Ambisonique. Cet &eacute;quipement a pour double vocation de susciter l&rsquo;exploration de nouvelles modalit&eacute;s de spatialisation pour la cr&eacute;ation musicale et de permettre la mise en &oelig;uvre d&rsquo;exp&eacute;riences &agrave; caract&egrave;re scientifique consacr&eacute;es &agrave; la r&eacute;alit&eacute; virtuelle et la cognition spatiale. Un premier volet de cet &eacute;quipement, inaugur&eacute; en novembre 2008, a &eacute;t&eacute; exploit&eacute; depuis dans le cadre de cr&eacute;ations musicales (<em>Operspective H&ouml;lderlin</em> de P. Schoeller en juin 2009, <em>Le P&egrave;re</em> de M. Jarrell en juin 2010, <em>Mimesis</em> de M.Garcia-vitoria en octobre 2011) et de repr&eacute;sentations th&eacute;&acirc;trales dans la Cour d&rsquo;honneur du Palais des papes &agrave; Avignon (<em>La Trag&eacute;die du Roi Richard II</em>, mise en sc&egrave;ne J.-B. Sastre, juillet 2010). L&rsquo;&eacute;quipement complet a &eacute;t&eacute; inaugur&eacute; le 28 novembre 2012.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_en": "<p>The Wave Field Synthesis (WFS) technique is type of holophonic reproduction process that enables, by analogy with visual holograms, to capture or synthesize a sound scene while conserving the spatial characteristics of distance and direction.</p>\r\n<p>This approach, initiated by the University of Delft, goes well beyond the limits of conventional systems in terms of reproduction fidelity in a wide listening zone. While traditional stereophonic techniques (e.g. stereo, 5.1) are a kind of trompe-l&rsquo;&oelig;il and can only be truly appreciated when one is positioned in the center of the system, the goal of holophonic technology is to reproduce a sound field in which listeners can move freely while maintaining a coherent perception of the localization of the sound sources. IRCAM has gained experience in this type of reproduction through its participation in the European CARROUSO Project in collaboration with the Swiss company SonicEmotion. These studies have made it possible to carry out productions in partnership with the Centre Pompidou such as the production of an installation at the end of 2005 for the DADA exhibit, an interactive installation in June 2006 (in collaboration with N+N Corsino), and an <br />installation for the Samuel Beckett exhibit in 2007.</p>\r\n<p>From 2008&mdash;2011, IRCAM was able to acquire and install a WFS system in the Espace de Projection with the support of the &Icirc;le-de- France R&eacute;gion, the CNRS, and the UPMC. This system is made up of a horizontal crown of 264 loudspeakers placed at regular intervals around the stage and the audience for WFS sound diffusion and of a dome of 75 loudspeakers for three-dimensional Ambisonic sound diffusion. This equipment is used to experiment with new methods of spatialization for musical creation and for scientific experiments with virtual reality and spatial cognition. The WFS component of this installation, inaugurated in 2008, was used in the musical creations by P. Schoeller in June 2009 (<em>Operspective H&ouml;lderlin</em>), M. Jarrell in June 2010 (<em>Le P&egrave;re</em>), M. Garcia-vitoria in October 2011 (<em>Mimesis</em>), and in theatrical productions at the festival of Avignon (<em>Shakespeare&rsquo;s Richard II</em>, directed by J. B. Sastre, July 2010). The final system was inaugurated on November 28th, 2012.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Acoustic and Cognitive Spaces team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": 9, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [2, 1, 3], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 31, "fields": {"keywords_string": "", "site": 1, "title": "3DR3", "title_fr": "3DR3", "title_en": "3DR3", "slug": "3dr3", "_meta_title": "", "description": "Room Impulse Response Renderer", "description_fr": "Room Impulse Response Renderer", "description_en": "Room Impulse Response Renderer", "gen_description": false, "created": "2016-09-07T15:48:16.120Z", "updated": "2018-11-21T13:52:44.036Z", "status": 2, "publish_date": "2016-09-07T15:48:16Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet 3DR3 r&eacute;unit l&rsquo;&eacute;quipe EAC (R&amp;D) et l&rsquo;&eacute;quipe Son (Production) autour du d&eacute;veloppement d&rsquo;un environnement g&eacute;n&eacute;rique de mixage multicanal exploitant un mod&egrave;le original de r&eacute;verb&eacute;ration hybride r&eacute;cemment d&eacute;velopp&eacute; par l&rsquo;&eacute;quipe EAC. Ce mod&egrave;le innovant tire avantage des r&eacute;verb&eacute;rateurs &agrave; convolution qui reproduisent fid&egrave;lement la sonorit&eacute; &laquo; naturelle &raquo; de la r&eacute;verb&eacute;ration mesur&eacute;e dans une salle comparativement aux r&eacute;verb&eacute;rateurs &agrave; retards reboucl&eacute;s. Il en &eacute;tend cependant le principe au cas des r&eacute;ponses spatialis&eacute;es et y adjoint la flexibilit&eacute; du Spat~ et son mode de contr&ocirc;le par facteurs perceptifs. La mise en espace 3D des diff&eacute;rentes sources exploite des r&eacute;ponses impulsionnelles de salles enregistr&eacute;es dans le lieu m&ecirc;me du concert et assure ainsi une int&eacute;gration naturelle avec la prise de son principale. L&rsquo;application embl&eacute;matique de ce d&eacute;veloppement est la captation, le mixage et la diffusion 3D des &oelig;uvres spatialis&eacute;es.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_fr": "<p>Le projet 3DR3 r&eacute;unit l&rsquo;&eacute;quipe EAC (R&amp;D) et l&rsquo;&eacute;quipe Son (Production) autour du d&eacute;veloppement d&rsquo;un environnement g&eacute;n&eacute;rique de mixage multicanal exploitant un mod&egrave;le original de r&eacute;verb&eacute;ration hybride r&eacute;cemment d&eacute;velopp&eacute; par l&rsquo;&eacute;quipe EAC. Ce mod&egrave;le innovant tire avantage des r&eacute;verb&eacute;rateurs &agrave; convolution qui reproduisent fid&egrave;lement la sonorit&eacute; &laquo; naturelle &raquo; de la r&eacute;verb&eacute;ration mesur&eacute;e dans une salle comparativement aux r&eacute;verb&eacute;rateurs &agrave; retards reboucl&eacute;s. Il en &eacute;tend cependant le principe au cas des r&eacute;ponses spatialis&eacute;es et y adjoint la flexibilit&eacute; du Spat~ et son mode de contr&ocirc;le par facteurs perceptifs. La mise en espace 3D des diff&eacute;rentes sources exploite des r&eacute;ponses impulsionnelles de salles enregistr&eacute;es dans le lieu m&ecirc;me du concert et assure ainsi une int&eacute;gration naturelle avec la prise de son principale. L&rsquo;application embl&eacute;matique de ce d&eacute;veloppement est la captation, le mixage et la diffusion 3D des &oelig;uvres spatialis&eacute;es.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_en": "<p>3DR3 brings together the Acoustic and Cognitive Spaces research team with the Creation-Diffusion department&rsquo;s sound team to work on the development of a generic environment for multichannel mixing, using a unique model of hybrid reverberation recently developed by the Acoustic and Cognitive Spaces team. This innovative model takes advantage of convolution reverberators that accurately reproduce the &ldquo;natural&rdquo; sound of the reverberation measured in a room compared to feedback delay network-based reverberators. This extends the principle of spatialized responses while associating the flexibility of Spat~ and its control via perceptive factors. The spatial disposition in 3fD of the different sound sources exploits the room impulse responses of the rooms recorded in the same space as the concert, assuring the natural integration of the primary sound recording. The emblematic application of this development is the capture, mixing, and 3D diffusion of spatialized works.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Acoustic and Cognitive Spaces team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2, 9], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 33, "fields": {"keywords_string": "", "site": 1, "title": "Technologies de reproduction binaurale", "title_fr": "Technologies de reproduction binaurale", "title_en": "Binaural reproduction technology", "slug": "technologies-de-reproduction-binaurale", "_meta_title": "", "description": "", "description_fr": "", "description_en": "", "gen_description": false, "created": "2016-09-07T15:56:32.607Z", "updated": "2018-06-29T10:36:31.645Z", "status": 2, "publish_date": "2016-09-07T15:56:32Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La restitution r&eacute;aliste de sources ponctuelles sur casque d&rsquo;&eacute;coute implique l&rsquo;usage d&rsquo;une spatialisation binaurale. Celle-ci est bas&eacute;e sur le filtrage dynamique de la source sonore par les fonctions de transfert (Head-Related Transfer Function, HRTF) pr&eacute;alablement mesur&eacute;es sur la t&ecirc;te d&rsquo;un auditeur ou d&rsquo;un mannequin.</p>\r\n<p>Bien que son utilisation musicale soit encore limit&eacute;e (except&eacute; pour la r&eacute;alit&eacute; virtuelle ou les installations sonores interactives), la technologie binaurale repr&eacute;sente un cadre de restitution d&rsquo;une importance primordiale pour la situation de laboratoire. Associ&eacute;e &agrave; des dispositifs de suivi de position, c&rsquo;est, &agrave; ce jour, la seule technique, assortie de moyens de suivi de position, qui permette de restituer sans artefact la complexit&eacute; acoustique d&rsquo;une sc&egrave;ne sonore.</p>\r\n<p>Cette technique reste notamment irrempla&ccedil;able pour mener les travaux de validation perceptive.</p>\r\n<p>&Agrave; l&rsquo;Ircam, elle est utilis&eacute;e pour les &eacute;tudes sur la cognition spatiale auditive incluant la navigation de l&rsquo;auditeur ou des processus perception-action engendr&eacute;s par un contr&ocirc;le gestuel de la localisation de la source sonore.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_fr": "<p>La restitution r&eacute;aliste de sources ponctuelles sur casque d&rsquo;&eacute;coute implique l&rsquo;usage d&rsquo;une spatialisation binaurale. Celle-ci est bas&eacute;e sur le filtrage dynamique de la source sonore par les fonctions de transfert (Head-Related Transfer Function, HRTF) pr&eacute;alablement mesur&eacute;es sur la t&ecirc;te d&rsquo;un auditeur ou d&rsquo;un mannequin.</p>\r\n<p>Bien que son utilisation musicale soit encore limit&eacute;e (except&eacute; pour la r&eacute;alit&eacute; virtuelle ou les installations sonores interactives), la technologie binaurale repr&eacute;sente un cadre de restitution d&rsquo;une importance primordiale pour la situation de laboratoire. Associ&eacute;e &agrave; des dispositifs de suivi de position, c&rsquo;est, &agrave; ce jour, la seule technique, assortie de moyens de suivi de position, qui permette de restituer sans artefact la complexit&eacute; acoustique d&rsquo;une sc&egrave;ne sonore.</p>\r\n<p>Cette technique reste notamment irrempla&ccedil;able pour mener les travaux de validation perceptive.</p>\r\n<p>&Agrave; l&rsquo;Ircam, elle est utilis&eacute;e pour les &eacute;tudes sur la cognition spatiale auditive incluant la navigation de l&rsquo;auditeur ou des processus perception-action engendr&eacute;s par un contr&ocirc;le gestuel de la localisation de la source sonore.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_en": "<p>The realistic reproduction of sounds through headphones requires the use of binaural spatialization. This technique is based on a dynamic filtering of the sound source using transfer functions (HRTF - Head Related Transfer Functions) measured on the head of a listener or model.</p>\r\n<p>Despite the limited nature of its current application to music (except in virtual reality or interactive sound installations), binaural technology is a very important method of reproduction in the lab. Associated with systems that follow your position, this is currently the only technique that allows the complexity of a sound scene to be reproduced without artifact.</p>\r\n<p>This technique is particularly useful in perceptive validation work.</p>\r\n<p>At IRCAM it is used in the study of spatial auditory cognition including listener navigation and the perception-action process brought about by the motion control of a localized sound source.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Acoustic and Cognitive Spaces team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 34, "fields": {"keywords_string": "", "site": 1, "title": "BiLi", "title_fr": "BiLi", "title_en": "BiLi", "slug": "bili", "_meta_title": "", "description": "Binaural Listening", "description_fr": "Binaural Listening", "description_en": "Binaural Listening", "gen_description": false, "created": "2016-09-07T16:00:51.293Z", "updated": "2018-06-29T10:35:29.185Z", "status": 2, "publish_date": "2016-09-07T16:00:51Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les appareils personnels (smartphones, tablettes) concentrent d&eacute;sormais de multiples fonctions et repr&eacute;sentent l&rsquo;un des principaux vecteurs de diffusion de contenus musicaux, d&rsquo;&eacute;missions de radio ou de t&eacute;l&eacute;vision. &Agrave; mesure que l&rsquo;audience d&eacute;rive vers ces nouveaux &eacute;quipements, l&rsquo;&eacute;coute binaurale sur casque d&rsquo;&eacute;coute gagne du terrain et symbolise la notion d&rsquo;exp&eacute;rience personnelle en donnant acc&egrave;s en th&eacute;orie &agrave; la reproduction de sc&egrave;nes tri-dimensionnelles et immersives. Cependant, la d&eacute;pendance individuelle des fonctions de transfert d&rsquo;oreille (HRTF) &agrave; la base de la technologie binaurale a jusqu&rsquo;&agrave; pr&eacute;sent limit&eacute; sa diffusion grand public.</p>\r\n<p>Le projet BiLi vise &agrave; d&eacute;ployer des solutions d&rsquo;&eacute;coute binaurale individualis&eacute;e pour le grand public en s&rsquo;appuyant sur un tissu de laboratoires de recherche, de PME et de diffuseurs (France T&eacute;l&eacute;visions, Radio France, Orange). Les volets principaux du projet sont l&rsquo;&eacute;valuation de la qualit&eacute; d&rsquo;exp&eacute;rience offerte par le mode d&rsquo;&eacute;coute binaurale, la recherche et le d&eacute;veloppement de solutions d&rsquo;individualisation &eacute;vitant de recourir aux mesures fastidieuses en chambre an&eacute;cho&iuml;que et la d&eacute;finition d&rsquo;un format d&rsquo;&eacute;change des donn&eacute;es binaurales pr&eacute;figurant une standardisation au niveau international.</p>", "content_fr": "<p>Les appareils personnels (smartphones, tablettes) concentrent d&eacute;sormais de multiples fonctions et repr&eacute;sentent l&rsquo;un des principaux vecteurs de diffusion de contenus musicaux, d&rsquo;&eacute;missions de radio ou de t&eacute;l&eacute;vision. &Agrave; mesure que l&rsquo;audience d&eacute;rive vers ces nouveaux &eacute;quipements, l&rsquo;&eacute;coute binaurale sur casque d&rsquo;&eacute;coute gagne du terrain et symbolise la notion d&rsquo;exp&eacute;rience personnelle en donnant acc&egrave;s en th&eacute;orie &agrave; la reproduction de sc&egrave;nes tri-dimensionnelles et immersives. Cependant, la d&eacute;pendance individuelle des fonctions de transfert d&rsquo;oreille (HRTF) &agrave; la base de la technologie binaurale a jusqu&rsquo;&agrave; pr&eacute;sent limit&eacute; sa diffusion grand public.</p>\r\n<p>Le projet BiLi vise &agrave; d&eacute;ployer des solutions d&rsquo;&eacute;coute binaurale individualis&eacute;e pour le grand public en s&rsquo;appuyant sur un tissu de laboratoires de recherche, de PME et de diffuseurs (France T&eacute;l&eacute;visions, Radio France, Orange). Les volets principaux du projet sont l&rsquo;&eacute;valuation de la qualit&eacute; d&rsquo;exp&eacute;rience offerte par le mode d&rsquo;&eacute;coute binaurale, la recherche et le d&eacute;veloppement de solutions d&rsquo;individualisation &eacute;vitant de recourir aux mesures fastidieuses en chambre an&eacute;cho&iuml;que et la d&eacute;finition d&rsquo;un format d&rsquo;&eacute;change des donn&eacute;es binaurales pr&eacute;figurant une standardisation au niveau international.</p>", "content_en": "<p>Personal devices (e.g. smart phones, tablets) now have several functions and represent one of the main means of accessing music, radio and television programs. As the public increases their use of these devices, binaural listening with headphones becomes more frequent and symbolizes the idea of a personal experience, providing access to a reproduction of 3D immersive sound scenes. However, the individual dependence head-related transfer function (HRTF) that is the basis of binaural technology has limited its availability to the general public.</p>\r\n<p>The BiLi project endeavors to provide solutions for individualized binaural listening via the support a network of research labs, small companies, and broadcasting companies (France T&eacute;l&eacute;visions, Radio-France, Orange). The main focuses of the project are the assessment of the quality of the experience made possible by binaural listening, the research and development of solutions for individualizing the listening while avoiding tedious measurements in an anechoic chamber, and the definition of a format for sharing binaural data in anticipation of an international standard.</p>", "date_from": "2013-01-01", "date_to": "2016-06-30", "user": null, "type": "external", "external_id": "12018529", "program": 10, "program_type": null, "call": 13, "lead_team": null, "lead_organization": 97, "website": "http://www.bili-project.org/", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [100, 101, 1, 20, 98, 99, 94], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 35, "fields": {"keywords_string": "", "site": 1, "title": "Cognition spatiale auditive", "title_fr": "Cognition spatiale auditive", "title_en": "Auditory spatial cognition", "slug": "cognition-spatiale-auditive", "_meta_title": "", "description": "\u00c9tude de processus d\u2019int\u00e9gration multisensorielle", "description_fr": "\u00c9tude de processus d\u2019int\u00e9gration multisensorielle", "description_en": "", "gen_description": false, "created": "2016-09-08T13:29:55.187Z", "updated": "2018-06-29T10:37:14.505Z", "status": 2, "publish_date": "2016-09-08T13:29:55Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Dans le domaine de la reproduction sonore ou de la communication, les technologies audio futures tenteront de privil&eacute;gier les sensations d&rsquo;immersion et de pr&eacute;sence. Ces notions sont intimement li&eacute;es aux dimensions spatiales d&rsquo;une sc&egrave;ne multim&eacute;dia et en particulier sonore, et sont notamment renforc&eacute;es dans les situations impliquant une action de la part de l&rsquo;auditeur, soit &agrave; travers sa navigation dans la sc&egrave;ne, soit &agrave; travers une interaction gestuelle avec les objets qui la composent. Dans ces conditions, rendues possibles par les technologies holophoniques ou binaurales, la congruence et le rafra&icirc;chissement en temps r&eacute;el des indices auditifs spatiaux en fonction des mouvements ou actions de l&rsquo;auditeur ont un impact majeur sur la sensation de pr&eacute;sence.</p>\r\n<p>Ce nouveau contexte a motiv&eacute; le lancement d&rsquo;une s&eacute;rie d&rsquo;exp&eacute;riences consacr&eacute;es &agrave; la cognition spatiale auditive, notamment &agrave; travers l&rsquo;&eacute;tude de processus d&rsquo;int&eacute;gration multisensorielle. L&rsquo;accent est mis sur l&rsquo;interaction entre les modalit&eacute;s auditives et idioth&eacute;tiques (indices induits par le mouvement du sujet et incluant l&rsquo;&eacute;quilibre et la proprioception). La m&eacute;thodologie exp&eacute;rimentale fait appel &agrave; des exp&eacute;riences comportementales li&eacute;es &agrave; l&rsquo;observation des performances de localisation ou de navigation des sujets soumis &agrave; diff&eacute;rents contextes exploratoires. Dans cet axe de recherche, on s&rsquo;int&eacute;resse &eacute;galement aux rapports entre int&eacute;gration multisensorielle et dimension &eacute;motionnelle. Il peut s&rsquo;agir par exemple d&rsquo;&eacute;tudier les effets de conflits spatiaux entre le son et la vision sur la r&eacute;action &eacute;motionnelle de sujets, ou encore d&rsquo;&eacute;valuer la perception de la num&eacute;rosit&eacute; (e.g. quantification d&rsquo;une foule) en fonction de la modalit&eacute; sensorielle et ses liens avec l&rsquo;&eacute;motion.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_fr": "<p>Dans le domaine de la reproduction sonore ou de la communication, les technologies audio futures tenteront de privil&eacute;gier les sensations d&rsquo;immersion et de pr&eacute;sence. Ces notions sont intimement li&eacute;es aux dimensions spatiales d&rsquo;une sc&egrave;ne multim&eacute;dia et en particulier sonore, et sont notamment renforc&eacute;es dans les situations impliquant une action de la part de l&rsquo;auditeur, soit &agrave; travers sa navigation dans la sc&egrave;ne, soit &agrave; travers une interaction gestuelle avec les objets qui la composent. Dans ces conditions, rendues possibles par les technologies holophoniques ou binaurales, la congruence et le rafra&icirc;chissement en temps r&eacute;el des indices auditifs spatiaux en fonction des mouvements ou actions de l&rsquo;auditeur ont un impact majeur sur la sensation de pr&eacute;sence.</p>\r\n<p>Ce nouveau contexte a motiv&eacute; le lancement d&rsquo;une s&eacute;rie d&rsquo;exp&eacute;riences consacr&eacute;es &agrave; la cognition spatiale auditive, notamment &agrave; travers l&rsquo;&eacute;tude de processus d&rsquo;int&eacute;gration multisensorielle. L&rsquo;accent est mis sur l&rsquo;interaction entre les modalit&eacute;s auditives et idioth&eacute;tiques (indices induits par le mouvement du sujet et incluant l&rsquo;&eacute;quilibre et la proprioception). La m&eacute;thodologie exp&eacute;rimentale fait appel &agrave; des exp&eacute;riences comportementales li&eacute;es &agrave; l&rsquo;observation des performances de localisation ou de navigation des sujets soumis &agrave; diff&eacute;rents contextes exploratoires. Dans cet axe de recherche, on s&rsquo;int&eacute;resse &eacute;galement aux rapports entre int&eacute;gration multisensorielle et dimension &eacute;motionnelle. Il peut s&rsquo;agir par exemple d&rsquo;&eacute;tudier les effets de conflits spatiaux entre le son et la vision sur la r&eacute;action &eacute;motionnelle de sujets, ou encore d&rsquo;&eacute;valuer la perception de la num&eacute;rosit&eacute; (e.g. quantification d&rsquo;une foule) en fonction de la modalit&eacute; sensorielle et ses liens avec l&rsquo;&eacute;motion.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Espaces acoustiques et cognitifs</a>.</p>", "content_en": "<p>In the field of sound reproduction and communication, future audio technology will attempt to shift emphasis towards sensations of immersion and presence. Such notions are intimately linked to the spatial dimensions of a multimedia scene, and particularly in the field of sound, and are intensified in situations involving the participation of the listener. This participation may involve navigation within a scene or the gestural interaction of objects within it. Under these conditions, made possible by binaural and holophonic technology, the congruence and real-time updating of auditory spatial clues in accordance with the listener&rsquo;s movement or actions, have a major impact on the sensation of presence. Such a context led to the development of a set of experiments focusing on auditory spatial cognition, notably via the study of multi-sensorial integration processes, focusing on auditory and idiothetical modalities (clues induced by the subject&rsquo;s movements including balance and proprioception).</p>\r\n<p>Experimental methods call on behavioral experiences based on the observation of a subject&rsquo;s performance, in terms of localization and navigation, when submitted to different exploratory contexts. We are also interested in the relationships between multisensory integration and emotions. We may study, for example, the effects of spatial conflicts between sound and vision on the emotional reaction of subjects, or assess the perception of numerosity (e.g. the quantification of a crowd) based on a sensory mode and its connection to emotion.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement/\">Acoustic and Cognitive Spaces team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 36, "fields": {"keywords_string": "", "site": 1, "title": "Audioself", "title_fr": "Audioself", "title_en": "Audioself", "slug": "audioself", "_meta_title": "", "description": "Contribution des interactions auditives et vestibulaires pour la perception du corps propre", "description_fr": "Contribution des interactions auditives et vestibulaires pour la perception du corps propre", "description_en": "Contribution of audio and vestibular interactions in the perception of our own body", "gen_description": false, "created": "2016-09-08T13:32:59.093Z", "updated": "2018-06-29T10:36:56.796Z", "status": 2, "publish_date": "2016-09-08T13:32:59Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Notre perception repose sur le sentiment que notre &laquo; moi &raquo; (self) est localis&eacute; l&agrave; o&ugrave; est notre corps, autrement dit sur le sentiment d&rsquo;incarnation (embodiment) &ndash; le fait d&rsquo;habiter ce corps, d&rsquo;&ecirc;tre localis&eacute; dans les limites physiques de ce corps. Cette sensation n&rsquo;est pas gouvern&eacute;e par un organe sensoriel isol&eacute; mais d&eacute;pend au contraire de l&rsquo;int&eacute;gration des aff&eacute;rences multisensorielles. Nous &eacute;tudions cette sensation en nous int&eacute;ressant &agrave; la contribution des interactions auditives et vestibulaires pour la perception du corps propre, et en profitant des conditions d&rsquo;apesanteur provoqu&eacute;es lors de vols paraboliques. En situation d&rsquo;apesanteur, les indices vestibulaires sont naturellement perturb&eacute;s, ce qui peut alt&eacute;rer la sensation d&rsquo;unit&eacute; entre le sentiment de soi et son propre corps et en d&rsquo;autres termes modifier la perception de son corps comme r&eacute;f&eacute;rence spatiale.</p>", "content_fr": "<p>Notre perception repose sur le sentiment que notre &laquo; moi &raquo; (self) est localis&eacute; l&agrave; o&ugrave; est notre corps, autrement dit sur le sentiment d&rsquo;incarnation (embodiment) &ndash; le fait d&rsquo;habiter ce corps, d&rsquo;&ecirc;tre localis&eacute; dans les limites physiques de ce corps. Cette sensation n&rsquo;est pas gouvern&eacute;e par un organe sensoriel isol&eacute; mais d&eacute;pend au contraire de l&rsquo;int&eacute;gration des aff&eacute;rences multisensorielles. Nous &eacute;tudions cette sensation en nous int&eacute;ressant &agrave; la contribution des interactions auditives et vestibulaires pour la perception du corps propre, et en profitant des conditions d&rsquo;apesanteur provoqu&eacute;es lors de vols paraboliques. En situation d&rsquo;apesanteur, les indices vestibulaires sont naturellement perturb&eacute;s, ce qui peut alt&eacute;rer la sensation d&rsquo;unit&eacute; entre le sentiment de soi et son propre corps et en d&rsquo;autres termes modifier la perception de son corps comme r&eacute;f&eacute;rence spatiale.</p>", "content_en": "<p>Our perception is based on the impression that our &ldquo;self&rdquo; is located in the same position as our bodies; in other words, the feeling of embodiment, of living in a body, of being located within the physical confines of a body. This feeling is not governed by an isolated sensory organ, but depends on multisensory afferences. We study this feeling by looking at the contribution of audio and vestibular interactions in the perception of our own body, using zero gravity conditions created during parabolic flights. In zero gravity vestibular indices are naturally troubled and this may modify the feeling of unity between the feeling of &ldquo;self&rdquo; and one&rsquo;s own body. In other words, this may modify the perception of your body as a spatial reference.</p>", "date_from": "2013-01-01", "date_to": "2015-12-31", "user": null, "type": "external", "external_id": "", "program": 11, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [102, 103], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 37, "fields": {"keywords_string": "", "site": 1, "title": "Verve", "title_fr": "Verve", "title_en": "Verve", "slug": "verve", "_meta_title": "", "description": "Personalised Virtual Reality Scenarios for Groups at Risk of Social Exclusion", "description_fr": "Personalised Virtual Reality Scenarios for Groups at Risk of Social Exclusion", "description_en": "Personalised Virtual Reality Scenarios for Groups at Risk of Social Exclusion", "gen_description": false, "created": "2016-09-08T13:39:19.248Z", "updated": "2018-06-29T10:38:19.489Z", "status": 2, "publish_date": "2016-09-08T13:39:19Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet vise l&rsquo;am&eacute;lioration de la qualit&eacute; de vie de personnes &agrave; risque d&rsquo;exclusion sociale due &agrave; la peur et l&rsquo;apathie associ&eacute;es au vieillissement et aux troubles neurologiques. Le consortium travaille sur la sp&eacute;cification, le d&eacute;veloppement et le test d&rsquo;environnements virtuels personnalis&eacute;s et peupl&eacute;s d&rsquo;humano&iuml;des, qui peuvent &ecirc;tre utilis&eacute;s sur diff&eacute;rents types de plateformes, allant de la salle immersive (CAvE) au t&eacute;l&eacute;phone intelligent.</p>\r\n<p>Les efforts de vERvE se concentrent sur trois situations, chacune ciblant un groupe diff&eacute;rent de sympt&ocirc;mes : la peur de tomber et la maladie de Parkinson, l&rsquo;apathie et les troubles comportements reli&eacute;e au d&eacute;clin cognitif, en particulier dus &agrave; la maladie d&rsquo;Alzheimer, et d&rsquo;autres troubles &eacute;motionnels li&eacute;s &agrave; l&rsquo;anxi&eacute;t&eacute;. Bien que focalis&eacute;s sur ces domaines au d&eacute;part du projet, les r&eacute;sultats de la recherche devraient &ecirc;tre applicables &agrave; un &eacute;ventail beaucoup plus large de situations. Le son 3D est utilis&eacute; dans les situations immersives, de sorte &agrave; &eacute;tudier les liens entre l&rsquo;int&eacute;gration visuo-auditive et l&rsquo;&eacute;motion. La compr&eacute;hension de l&rsquo;impact affectif du rendu visuel et auditif d&rsquo;un environnement virtuel, au niveau de la perception &eacute;motionnelle et au niveau du ressenti affectif, doit permettre la mise en place de nouvelles strat&eacute;gies th&eacute;rapeutiques pour les troubles li&eacute;s &agrave; l&rsquo;anxi&eacute;t&eacute;.</p>", "content_fr": "<p>Le projet vise l&rsquo;am&eacute;lioration de la qualit&eacute; de vie de personnes &agrave; risque d&rsquo;exclusion sociale due &agrave; la peur et l&rsquo;apathie associ&eacute;es au vieillissement et aux troubles neurologiques. Le consortium travaille sur la sp&eacute;cification, le d&eacute;veloppement et le test d&rsquo;environnements virtuels personnalis&eacute;s et peupl&eacute;s d&rsquo;humano&iuml;des, qui peuvent &ecirc;tre utilis&eacute;s sur diff&eacute;rents types de plateformes, allant de la salle immersive (CAvE) au t&eacute;l&eacute;phone intelligent.</p>\r\n<p>Les efforts de vERvE se concentrent sur trois situations, chacune ciblant un groupe diff&eacute;rent de sympt&ocirc;mes : la peur de tomber et la maladie de Parkinson, l&rsquo;apathie et les troubles comportements reli&eacute;e au d&eacute;clin cognitif, en particulier dus &agrave; la maladie d&rsquo;Alzheimer, et d&rsquo;autres troubles &eacute;motionnels li&eacute;s &agrave; l&rsquo;anxi&eacute;t&eacute;. Bien que focalis&eacute;s sur ces domaines au d&eacute;part du projet, les r&eacute;sultats de la recherche devraient &ecirc;tre applicables &agrave; un &eacute;ventail beaucoup plus large de situations. Le son 3D est utilis&eacute; dans les situations immersives, de sorte &agrave; &eacute;tudier les liens entre l&rsquo;int&eacute;gration visuo-auditive et l&rsquo;&eacute;motion. La compr&eacute;hension de l&rsquo;impact affectif du rendu visuel et auditif d&rsquo;un environnement virtuel, au niveau de la perception &eacute;motionnelle et au niveau du ressenti affectif, doit permettre la mise en place de nouvelles strat&eacute;gies th&eacute;rapeutiques pour les troubles li&eacute;s &agrave; l&rsquo;anxi&eacute;t&eacute;.</p>", "content_en": "<p>The vERvE project aims to improve the quality of life of people at risk of social exclusion due to the fear and apathy associated with ageing and neurological troubles. The consortium works on the specification, development, and testing personalized and populated virtual environments that can be used on different types of platforms from immersive rooms (CAvE) to smart phones.</p>\r\n<p>vERvE&rsquo;s efforts will focus on three situations: fear of falling and Parkinson&rsquo;s disease; apathy related to cognitive decline and behavioral disturbances, in particular due to Alzheimer&rsquo;s Disease; and other emotional disturbances linked to anxiety. Although focusing on these areas initially, it is expected that the results of the research will be applicable to a much wider range of situations. 3D sound is used in immersive situations to study the connections between visual-audio integration and emotion. The understanding of the emotional impact of visual and audio rendering of a virtual environment, from an emotional perception point of view, must enable the implementation of new therapeutic strategies for troubles linked to anxiety.</p>", "date_from": "2011-10-01", "date_to": "2014-09-30", "user": null, "type": "external", "external_id": "288914", "program": 8, "program_type": 10, "call": 17, "lead_team": null, "lead_organization": 104, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [90, 105, 2, 106, 108, 11, 107, 104, 109], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 38, "fields": {"keywords_string": "", "site": 1, "title": "HC2", "title_fr": "HC2", "title_en": "HC2", "slug": "h2c", "_meta_title": "", "description": "Human Computer Confluence Research in Action", "description_fr": "Human Computer Confluence Research in Action", "description_en": "Human Computer Confluence Research in Action", "gen_description": false, "created": "2016-09-08T13:46:15.877Z", "updated": "2018-06-29T10:37:40.613Z", "status": 2, "publish_date": "2016-09-08T13:46:15Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les recherches sur la confluence entre l&rsquo;homme et l&rsquo;ordinateur sont faites dans le cadre de programmes ambitieux &eacute;tudiant comment la relation symbiotique &eacute;mergente entre les humains et les outils informatiques permet des formes radicalement nouvelles de perception, d&rsquo;interaction et de compr&eacute;hension. C&rsquo;est un champ de recherche hautement multidisciplinaire, couvrant des disciplines aussi diverses que les sciences cognitives, l&rsquo;informatique fondamentale et l&rsquo;&eacute;lectronique. Le projet HC2 a men&eacute; une activit&eacute; de coordination promouvant la construction d&rsquo;une identit&eacute; et proposant la d&eacute;finition de recherches futures et de programmes &eacute;ducatifs. HC2 a atteint ses objectifs en construisant un point d&rsquo;information central et en utilisant une m&eacute;thodologie de travail bas&eacute;e sur la participation active de la communaut&eacute; et la cr&eacute;ation d&rsquo;&eacute;v&egrave;nements (2 &eacute;coles d&rsquo;&eacute;t&eacute;, 2 workshops, une rencontre pour la cr&eacute;ation d&rsquo;un ERA NET, une journ&eacute;e entreprises).</p>", "content_fr": "<p>Les recherches sur la confluence entre l&rsquo;homme et l&rsquo;ordinateur sont faites dans le cadre de programmes ambitieux &eacute;tudiant comment la relation symbiotique &eacute;mergente entre les humains et les outils informatiques permet des formes radicalement nouvelles de perception, d&rsquo;interaction et de compr&eacute;hension. C&rsquo;est un champ de recherche hautement multidisciplinaire, couvrant des disciplines aussi diverses que les sciences cognitives, l&rsquo;informatique fondamentale et l&rsquo;&eacute;lectronique. Le projet HC2 a men&eacute; une activit&eacute; de coordination promouvant la construction d&rsquo;une identit&eacute; et proposant la d&eacute;finition de recherches futures et de programmes &eacute;ducatifs. HC2 a atteint ses objectifs en construisant un point d&rsquo;information central et en utilisant une m&eacute;thodologie de travail bas&eacute;e sur la participation active de la communaut&eacute; et la cr&eacute;ation d&rsquo;&eacute;v&egrave;nements (2 &eacute;coles d&rsquo;&eacute;t&eacute;, 2 workshops, une rencontre pour la cr&eacute;ation d&rsquo;un ERA NET, une journ&eacute;e entreprises).</p>", "content_en": "<p>Human-computer confluence is an ambitious research program studying how the emerging symbiotic relation between humans and computing devices can enable radically new forms of sensing, perception, interaction, and understanding. This is a multidisciplinary research field, covering fields as diverse as cognitive sciences, fundamental computer science, and electronics. The HC2 project coordinated the promotion of identity building and defining future research and educational programs. HC2&rsquo;s goals were reached by collecting updated information and by consolidating research agendas using a work methodology based on the active participation of the community and the creation of events (2 summer schools, 2 workshops, an encounter for the establishment of an ERA NET, an industry day).</p>", "date_from": "2010-10-01", "date_to": "2013-09-30", "user": null, "type": "external", "external_id": "258063", "program": 8, "program_type": 11, "call": 11, "lead_team": null, "lead_organization": 111, "website": "http://hcsquared.eu/consortium/ircam", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [111, 112, 113], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 39, "fields": {"keywords_string": "", "site": 1, "title": "Reva", "title_fr": "Reva", "title_en": "Reva", "slug": "reva", "_meta_title": "", "description": "R\u00e9alit\u00e9 virtuelle et acouph\u00e8ne", "description_fr": "R\u00e9alit\u00e9 virtuelle et acouph\u00e8ne", "description_en": "Virtual Reality and Tinnitus", "gen_description": false, "created": "2016-09-08T13:49:30.950Z", "updated": "2018-06-29T10:37:54.251Z", "status": 2, "publish_date": "2016-09-08T13:49:30Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Cette &eacute;tude s&rsquo;est consacr&eacute;e &agrave; l&rsquo;&eacute;laboration et &agrave; l&rsquo;&eacute;valuation d&rsquo;une th&eacute;rapie bas&eacute;e sur la r&eacute;alit&eacute; virtuelle pour le traitement des acouph&egrave;nes qui d&eacute;signent un ensemble de sensations auditives fant&ocirc;mes en l&rsquo;absence de stimulation acoustique ext&eacute;rieure.</p>\r\n<p>Le principe de l&rsquo;&eacute;tude a consist&eacute; &agrave; mettre les patients acouph&eacute;niques en situation de r&eacute;alit&eacute; virtuelle 3D (visuelle et auditive) pour favoriser la plasticit&eacute; c&eacute;r&eacute;brale et r&eacute;duire la g&ecirc;ne induite par l&rsquo;acouph&egrave;ne subjectif. En pratique, il s&rsquo;agit de construire un avatar sonore et visuel de l&rsquo;acouph&egrave;ne et de fournir au patient les moyens d&rsquo;en contr&ocirc;ler la localisation dans l&rsquo;espace, &agrave; la fois en direction et en distance.</p>", "content_fr": "<p>Cette &eacute;tude s&rsquo;est consacr&eacute;e &agrave; l&rsquo;&eacute;laboration et &agrave; l&rsquo;&eacute;valuation d&rsquo;une th&eacute;rapie bas&eacute;e sur la r&eacute;alit&eacute; virtuelle pour le traitement des acouph&egrave;nes qui d&eacute;signent un ensemble de sensations auditives fant&ocirc;mes en l&rsquo;absence de stimulation acoustique ext&eacute;rieure.</p>\r\n<p>Le principe de l&rsquo;&eacute;tude a consist&eacute; &agrave; mettre les patients acouph&eacute;niques en situation de r&eacute;alit&eacute; virtuelle 3D (visuelle et auditive) pour favoriser la plasticit&eacute; c&eacute;r&eacute;brale et r&eacute;duire la g&ecirc;ne induite par l&rsquo;acouph&egrave;ne subjectif. En pratique, il s&rsquo;agit de construire un avatar sonore et visuel de l&rsquo;acouph&egrave;ne et de fournir au patient les moyens d&rsquo;en contr&ocirc;ler la localisation dans l&rsquo;espace, &agrave; la fois en direction et en distance.</p>", "content_en": "<p>This project centered on the design and testing of a form of therapy based on virtual reality to treat tinnitus &mdash; phantom auditory sensations that are felt in the absence of any external acoustic stimulation.</p>\r\n<p>The principle of the study was to place patients suffering from tinnitus in a 3D virtual reality situation (visual and audio) to favor brain plasticity and reduce the discomfort caused by the subjective tinnitus. In practice, a sound and visual avatar of the tinnitus was created and gave the patient the means to controlling its location; both its direction and distance.</p>", "date_from": "2008-01-01", "date_to": "2009-06-30", "user": null, "type": "external", "external_id": "", "program": 12, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [114, 115], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 40, "fields": {"keywords_string": "", "site": 1, "title": "CROSSMOD", "title_fr": "CROSSMOD", "title_en": "CROSSMOD", "slug": "crossmod", "_meta_title": "", "description": "Cross-modal perceptual interaction and rendering: a New Generation of Audiovisual Virtual Environments", "description_fr": "Cross-modal perceptual interaction and rendering: a New Generation of Audiovisual Virtual Environments", "description_en": "Cross-modal perceptual interaction and rendering: a New Generation of Audiovisual Virtual Environments", "gen_description": false, "created": "2016-09-08T13:58:23.274Z", "updated": "2018-06-29T10:33:11.400Z", "status": 2, "publish_date": "2016-09-08T13:58:23Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;objet du projet &eacute;tait d&rsquo;exploiter les propri&eacute;t&eacute;s perceptives multisensorielles afin d&rsquo;optimiser la qualit&eacute; et l&rsquo;interactivit&eacute; des applications de r&eacute;alit&eacute; virtuelle. En l&rsquo;&eacute;tat actuel, les deux principaux canaux sensoriels exploit&eacute;s dans les Ev3D sont les canaux visuel et auditif. Les recherches r&eacute;centes men&eacute;es dans chacun de ces domaines ont montr&eacute; l&rsquo;int&eacute;r&ecirc;t de l&rsquo;int&eacute;gration de r&egrave;gles perceptives pour une meilleure efficacit&eacute; de restitution.</p>\r\n<p>Cependant, nos canaux sensoriels ne fonctionnent pas de mani&egrave;re s&eacute;par&eacute;e. Diff&eacute;rentes &eacute;tudes ont mis en &eacute;vidence des ph&eacute;nom&egrave;nes d&rsquo;int&eacute;gration sensorielle dans lesquels une modalit&eacute; sensorielle peut &ecirc;tre affect&eacute;e par une autre, notamment en termes de congruence spatiale ou temporelle. L&rsquo;id&eacute;e directrice du projet &eacute;tait d&rsquo;exploiter les propri&eacute;t&eacute;s de r&eacute;solution, de masquage ou de hi&eacute;rarchie entre les dimensions perceptives pour conduire la synth&egrave;se de la sc&egrave;ne sonore ou visuelle.</p>", "content_fr": "<p>L&rsquo;objet du projet &eacute;tait d&rsquo;exploiter les propri&eacute;t&eacute;s perceptives multisensorielles afin d&rsquo;optimiser la qualit&eacute; et l&rsquo;interactivit&eacute; des applications de r&eacute;alit&eacute; virtuelle. En l&rsquo;&eacute;tat actuel, les deux principaux canaux sensoriels exploit&eacute;s dans les Ev3D sont les canaux visuel et auditif. Les recherches r&eacute;centes men&eacute;es dans chacun de ces domaines ont montr&eacute; l&rsquo;int&eacute;r&ecirc;t de l&rsquo;int&eacute;gration de r&egrave;gles perceptives pour une meilleure efficacit&eacute; de restitution.</p>\r\n<p>Cependant, nos canaux sensoriels ne fonctionnent pas de mani&egrave;re s&eacute;par&eacute;e. Diff&eacute;rentes &eacute;tudes ont mis en &eacute;vidence des ph&eacute;nom&egrave;nes d&rsquo;int&eacute;gration sensorielle dans lesquels une modalit&eacute; sensorielle peut &ecirc;tre affect&eacute;e par une autre, notamment en termes de congruence spatiale ou temporelle. L&rsquo;id&eacute;e directrice du projet &eacute;tait d&rsquo;exploiter les propri&eacute;t&eacute;s de r&eacute;solution, de masquage ou de hi&eacute;rarchie entre les dimensions perceptives pour conduire la synth&egrave;se de la sc&egrave;ne sonore ou visuelle.</p>", "content_en": "<p>The project&rsquo;s goal was to capitalize multi-sensorial perceptive properties to optimize the quality and interactivity of virtual reality applications. Currently, the two principal senses that capitalized on in 3DEv are sight and hearing. Recent research carried out in these fields has shown the significance of integrating rules of perception for more effectual reproduction.</p>\r\n<p>However, our senses do not function independently. Different studies revealed phenomena of sensorial integration in which one sensorial structure may be affected by another, particularly in terms of spatial or temporal congruence. The main idea of the project was to make use of the properties of resolution, of masking, or of hierarchy among perceptive dimensions to control the synthesis of a sound or visual stage.</p>", "date_from": "2005-12-01", "date_to": "2008-11-30", "user": null, "type": "external", "external_id": "FP6-FET-014891", "program": 8, "program_type": 9, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [2, 120, 106, 116, 119, 117, 118], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 41, "fields": {"keywords_string": "", "site": 1, "title": "Analyse et reconnaissance du geste", "title_fr": "Analyse et reconnaissance du geste", "title_en": "Gesture analysIs and RecognItIon", "slug": "analyse-et-reconnaissance-du-geste", "_meta_title": "", "description": "\u00c9tude du geste instrumental et de sa relation \u00e0 la fois avec l\u2019\u00e9criture musicale et les caract\u00e9ristiques du signal sonore", "description_fr": "\u00c9tude du geste instrumental et de sa relation \u00e0 la fois avec l\u2019\u00e9criture musicale et les caract\u00e9ristiques du signal sonore", "description_en": "Study of instrumental gesture and its relationship with both musical writing and the characteristics of the sound signal", "gen_description": false, "created": "2016-09-08T14:04:19.628Z", "updated": "2018-06-29T09:41:47.974Z", "status": 2, "publish_date": "2016-09-08T14:04:19Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet de recherche r&eacute;pond &agrave; un int&eacute;r&ecirc;t accru pour les syst&egrave;mes musicaux interactifs bas&eacute;s sur un contr&ocirc;le gestuel. Les applications concernent non seulement la musique mais le spectacle vivant dans son ensemble, tels la danse ou le th&eacute;&acirc;tre. Il s&rsquo;agit de recherches &agrave; caract&egrave;re fortement interdisciplinaire int&eacute;grant les sciences de l&rsquo;ing&eacute;nieur, la physiologie et la biom&eacute;canique, les sciences cognitives et les domaines artistiques. Ces travaux s&rsquo;effectuent en synergie avec nos d&eacute;veloppements sur les interfaces gestuelles.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Un premier axe de recherche est d&eacute;di&eacute; &agrave; l&rsquo;&eacute;tude du geste instrumental et de sa relation &agrave; la fois avec l&rsquo;&eacute;criture musicale et les caract&eacute;ristiques du signal sonore. Des mesures ont par exemple &eacute;t&eacute; effectu&eacute;es en collaboration avec McGill University sur des violonistes et trompettistes. Dans le cadre des instruments &agrave; cordes, les mouvements de l&rsquo;archet, du violon ainsi que du corps entier de l&rsquo;instrumentiste peuvent &ecirc;tre mesur&eacute;s en utilisant de la captation optique 3D. Nous d&eacute;veloppons &eacute;galement des dispositifs de captation compl&eacute;mentaires, compatibles avec l&rsquo;utilisation sc&eacute;nique ou des contextes p&eacute;dagogiques.</p>\r\n<p>L&rsquo;ensemble de ces m&eacute;thodes nous permet de mesurer et de mod&eacute;liser les gestes d&rsquo;instrumentistes. Diverses probl&eacute;matiques sont abord&eacute;es comme le contr&ocirc;le moteur et l&rsquo;apprentissage dans le cas d&rsquo;un geste expert, la caract&eacute;risation de modes de jeu en consid&eacute;rant &agrave; la fois les param&egrave;tres sonores et gestuels, ainsi que la mod&eacute;lisation de ph&eacute;nom&egrave;nes de coarticulation gestuelle similaires &agrave; ceux de la parole.</p>\r\n<p>Un deuxi&egrave;me axe concerne le d&eacute;veloppement de syst&egrave;mes d&rsquo;analyse et de reconnaissance du geste. Nous favorisons des approches g&eacute;n&eacute;rales permettant d&rsquo;appliquer nos r&eacute;sultats aussi bien &agrave; la musique qu&rsquo;&agrave; la danse ou qu&rsquo;aux installations interactives. De tels syst&egrave;mes peuvent &ecirc;tre, par exemple, int&eacute;gr&eacute;s dans le contexte d&rsquo;un spectacle vivant pour la synchronisation et l&rsquo;interaction entre le mouvement des interpr&egrave;tes et divers processus sonores ou visuels. La reconnaissance est bas&eacute;e sur diverses caract&eacute;ristiques temporelles du mouvement, capt&eacute;es soit par vid&eacute;o soit par un ensemble de capteurs embarqu&eacute;s sur le corps. Les outils issus de ces recherches, comme le &laquo; suivi de geste &raquo;, permettent de reconna&icirc;tre et caract&eacute;riser pr&eacute;cis&eacute;ment divers &eacute;l&eacute;ments gestuels de haut niveau d&eacute;finis par les artistes eux-m&ecirc;mes.</p>\r\n<p>&Eacute;quipe Ircam :<a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\"> Interaction son musique mouvement</a>.</p>", "content_fr": "<p>Ce projet de recherche r&eacute;pond &agrave; un int&eacute;r&ecirc;t accru pour les syst&egrave;mes musicaux interactifs bas&eacute;s sur un contr&ocirc;le gestuel. Les applications concernent non seulement la musique mais le spectacle vivant dans son ensemble, tels la danse ou le th&eacute;&acirc;tre. Il s&rsquo;agit de recherches &agrave; caract&egrave;re fortement interdisciplinaire int&eacute;grant les sciences de l&rsquo;ing&eacute;nieur, la physiologie et la biom&eacute;canique, les sciences cognitives et les domaines artistiques. Ces travaux s&rsquo;effectuent en synergie avec nos d&eacute;veloppements sur les interfaces gestuelles.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Un premier axe de recherche est d&eacute;di&eacute; &agrave; l&rsquo;&eacute;tude du geste instrumental et de sa relation &agrave; la fois avec l&rsquo;&eacute;criture musicale et les caract&eacute;ristiques du signal sonore. Des mesures ont par exemple &eacute;t&eacute; effectu&eacute;es en collaboration avec McGill University sur des violonistes et trompettistes. Dans le cadre des instruments &agrave; cordes, les mouvements de l&rsquo;archet, du violon ainsi que du corps entier de l&rsquo;instrumentiste peuvent &ecirc;tre mesur&eacute;s en utilisant de la captation optique 3D. Nous d&eacute;veloppons &eacute;galement des dispositifs de captation compl&eacute;mentaires, compatibles avec l&rsquo;utilisation sc&eacute;nique ou des contextes p&eacute;dagogiques.</p>\r\n<p>L&rsquo;ensemble de ces m&eacute;thodes nous permet de mesurer et de mod&eacute;liser les gestes d&rsquo;instrumentistes. Diverses probl&eacute;matiques sont abord&eacute;es comme le contr&ocirc;le moteur et l&rsquo;apprentissage dans le cas d&rsquo;un geste expert, la caract&eacute;risation de modes de jeu en consid&eacute;rant &agrave; la fois les param&egrave;tres sonores et gestuels, ainsi que la mod&eacute;lisation de ph&eacute;nom&egrave;nes de coarticulation gestuelle similaires &agrave; ceux de la parole.</p>\r\n<p>Un deuxi&egrave;me axe concerne le d&eacute;veloppement de syst&egrave;mes d&rsquo;analyse et de reconnaissance du geste. Nous favorisons des approches g&eacute;n&eacute;rales permettant d&rsquo;appliquer nos r&eacute;sultats aussi bien &agrave; la musique qu&rsquo;&agrave; la danse ou qu&rsquo;aux installations interactives. De tels syst&egrave;mes peuvent &ecirc;tre, par exemple, int&eacute;gr&eacute;s dans le contexte d&rsquo;un spectacle vivant pour la synchronisation et l&rsquo;interaction entre le mouvement des interpr&egrave;tes et divers processus sonores ou visuels. La reconnaissance est bas&eacute;e sur diverses caract&eacute;ristiques temporelles du mouvement, capt&eacute;es soit par vid&eacute;o soit par un ensemble de capteurs embarqu&eacute;s sur le corps. Les outils issus de ces recherches, comme le &laquo; suivi de geste &raquo;, permettent de reconna&icirc;tre et caract&eacute;riser pr&eacute;cis&eacute;ment divers &eacute;l&eacute;ments gestuels de haut niveau d&eacute;finis par les artistes eux-m&ecirc;mes.</p>\r\n<p>&Eacute;quipe Ircam :<a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\"> Interaction son musique mouvement</a>.</p>", "content_en": "<p>This research project replies to an increased interest for interactive musical systems based on gestural control. The applications concern not only music, but also performances such as dance or theater. The research carried out in the framework of this project is multi-disciplinary and includes engineering, physiology and biomechanics, cognitive sciences, and artistic domains. This work is carried out in synergy with the team&rsquo;s developments on gestural interfaces.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The first axis of research focuses on the study of instrumental gesture and its relationship with both musical writing and the characteristics of the sound signal. Measurements were taken on violinists and trumpet players during a collaboration with McGill University. In the case of string instruments, the movements of the bow, the violin, and the musician&rsquo;s entire body can be measured using optical 3D measurement techniques. The team has also developed complementary systems for capture, compatible with use on stage or in educational settings.</p>\r\n<p>The ensemble of these methods makes it possible to measure and model musicians&rsquo; gestures. Diverse issues are also addressed in this study: motor control, learning in the case of the gesture of an expert, characterization of playing styles taking into account sound and gesture parameters, and the modeling of the phenomena connected to the gestural co-articulation similar to those of speech.</p>\r\n<p>A second axis concerns the development of systems for gesture analysis and recognition. The team is favorable to general approaches that make it possible to apply their results to music, dance, or to interactive installations. Such systems could be included in the context of a live performance for the synchronization <br />and interaction between the performers&rsquo; movements and a broad range of sound or visual processes. Recognition is based on a variety of temporal characteristics of movement, captured either by video, either by sensors attached to the performers&rsquo; bodies. The tools developed during this research, such as \"gesture <br />follower\", make it possible to accurately recognize and characterize diverse high-level gestural elements defined by the artists.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Sound Music Movement Interaction team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7, 9], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 42, "fields": {"keywords_string": "", "site": 1, "title": "Cosima", "title_fr": "Cosima", "title_en": "Cosima", "slug": "cosima", "_meta_title": "", "description": "M\u00e9dias collaboratifs situ\u00e9s", "description_fr": "M\u00e9dias collaboratifs situ\u00e9s", "description_en": "Collaborative Situated Media", "gen_description": false, "created": "2016-09-08T14:29:19.579Z", "updated": "2018-07-25T14:36:08.683Z", "status": 2, "publish_date": "2016-09-08T14:29:19Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les dix derni&egrave;res ann&eacute;es ont vu une forte &eacute;volution des m&eacute;dias dans leur relation au corps et &agrave; l&rsquo;espace avec les interfaces tangibles, la r&eacute;alit&eacute; augment&eacute;e et le web ambiant. Dans ce mouvement, COSIMA propose d&rsquo;explorer la relation entre corps, m&eacute;dia et espaces &agrave; travers de nouvelles interfaces et outils de cr&eacute;ation collaboratifs. COSIMA vise la mise en &oelig;uvre d&rsquo;une plateforme pour l&rsquo;&eacute;dition et la diffusion de m&eacute;dias situ&eacute;s dans l&rsquo;espace, le temps, et combinant plusieurs modalit&eacute;s sensorielles. Ces contenus associent proprioception et perception en engageant le corps dans leur phase de cr&eacute;ation et de r&eacute;ception. Le principe de r&eacute;alit&eacute; augment&eacute;e superpose un espace num&eacute;rique &agrave; l&rsquo;espace tangible. Le d&eacute;ploiement d&rsquo;un tel espace permet l&rsquo;&eacute;dition de m&eacute;dias situ&eacute;s et collaboratifs. Les applications de la plateforme COSIMA incluent des projets artistiques, des services publics innovants, l&rsquo;&eacute;v&eacute;nementiel et la communication.</p>\r\n<h3>Mise en &oelig;uvre d&rsquo;une plateforme accessible</h3>\r\n<p>L&rsquo;objectif principal de COSIMA est de d&eacute;mocratiser ce nouveau type de m&eacute;dia &agrave; travers une plateforme accessible, g&eacute;n&eacute;rique, ouverte, et interop&eacute;rable. Le projet vise la mise en place d&rsquo;une plateforme reposant sur des formats standards et ouverts pour permettre une mise en relation avec une vari&eacute;t&eacute; de technologies mobile et de dispositifs existants. La plateforme va consid&eacute;rablement faciliter la mise en &oelig;uvre de ce type d&rsquo;exp&eacute;rience &agrave; un co&ucirc;t r&eacute;duit et accessible &agrave; un large public (institutions culturels, services publiques, entreprises priv&eacute;es, artistes, etc.). La mise en &oelig;uvre d&rsquo;un tel environnement d&rsquo;expression multimodale dans l&rsquo;espace tangible n&eacute;cessite un dispositif comprenant diff&eacute;rents composants : des applications clientes install&eacute;es sur des terminaux mobiles connect&eacute;s au r&eacute;seau, un web-service proposant une API ouverte, un serveur de bases de donn&eacute;es ainsi qu&rsquo;une interface d&rsquo;administration des contenus.</p>\r\n<h3>Cr&eacute;er des nouvelles exp&eacute;riences participatives</h3>\r\n<p>L&rsquo;&eacute;laboration de la plateforme n&eacute;cessite &eacute;galement un travail sur les usages et de validation. Pour cela, nous d&eacute;velopperons des prototypes &agrave; chaque &eacute;tape du projet dans l&rsquo;objectif de mettre nos sc&eacute;narios &agrave; l&rsquo;&eacute;preuve et d&rsquo;en collecter et analyser les r&eacute;sultats pour am&eacute;liorer la plateforme. Le projet COSIMA d&eacute;finit ainsi un contexte d&rsquo;exp&eacute;rimentation selon diff&eacute;rents axes : la cr&eacute;ation de m&eacute;dias visuels et sonores associ&eacute;s &agrave; des informations de d&eacute;placement et de mouvement pour cr&eacute;er des cartographies ou des parcours en r&eacute;alit&eacute; augment&eacute;e. Le partage de m&eacute;dias situ&eacute;s dans un espace social pour la mise en sc&egrave;ne de jeux pervasifs ou de zones d&rsquo;expression publique. La diffusion temps r&eacute;el de m&eacute;dias situ&eacute;s vers une communaut&eacute; d&rsquo;utilisateurs permettant le d&eacute;ploiement de mobs, de spectacles vivants ou d&rsquo;exp&eacute;riences &laquo; large group &raquo;.</p>\r\n<h3>Soutenir des nouveaux mod&egrave;les &eacute;conomiques et le d&eacute;veloppement de communaut&eacute;s pour la cr&eacute;ation et diffusions de m&eacute;dias num&eacute;riques</h3>\r\n<p>L&rsquo;&eacute;volution combin&eacute;e du web et des plateformes mobiles d&eacute;finit de nouveaux paradigmes pour la diffusion de m&eacute;dias. La plateforme COSIMA favorisera l&rsquo;&eacute;mergence et la structuration de communaut&eacute;s autour de ces nouveaux m&eacute;dia. L&rsquo;&eacute;valuation et s&eacute;lection d&rsquo;un mod&egrave;le &eacute;conomique adapt&eacute; &agrave; cette plateforme fait partie son d&eacute;veloppement.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-13-CORD-010-01.</p>", "content_fr": "<p>Les dix derni&egrave;res ann&eacute;es ont vu une forte &eacute;volution des m&eacute;dias dans leur relation au corps et &agrave; l&rsquo;espace avec les interfaces tangibles, la r&eacute;alit&eacute; augment&eacute;e et le web ambiant. Dans ce mouvement, COSIMA propose d&rsquo;explorer la relation entre corps, m&eacute;dia et espaces &agrave; travers de nouvelles interfaces et outils de cr&eacute;ation collaboratifs. COSIMA vise la mise en &oelig;uvre d&rsquo;une plateforme pour l&rsquo;&eacute;dition et la diffusion de m&eacute;dias situ&eacute;s dans l&rsquo;espace, le temps, et combinant plusieurs modalit&eacute;s sensorielles. Ces contenus associent proprioception et perception en engageant le corps dans leur phase de cr&eacute;ation et de r&eacute;ception. Le principe de r&eacute;alit&eacute; augment&eacute;e superpose un espace num&eacute;rique &agrave; l&rsquo;espace tangible. Le d&eacute;ploiement d&rsquo;un tel espace permet l&rsquo;&eacute;dition de m&eacute;dias situ&eacute;s et collaboratifs. Les applications de la plateforme COSIMA incluent des projets artistiques, des services publics innovants, l&rsquo;&eacute;v&eacute;nementiel et la communication.</p>\r\n<h3>Mise en &oelig;uvre d&rsquo;une plateforme accessible</h3>\r\n<p>L&rsquo;objectif principal de COSIMA est de d&eacute;mocratiser ce nouveau type de m&eacute;dia &agrave; travers une plateforme accessible, g&eacute;n&eacute;rique, ouverte, et interop&eacute;rable. Le projet vise la mise en place d&rsquo;une plateforme reposant sur des formats standards et ouverts pour permettre une mise en relation avec une vari&eacute;t&eacute; de technologies mobile et de dispositifs existants. La plateforme va consid&eacute;rablement faciliter la mise en &oelig;uvre de ce type d&rsquo;exp&eacute;rience &agrave; un co&ucirc;t r&eacute;duit et accessible &agrave; un large public (institutions culturels, services publiques, entreprises priv&eacute;es, artistes, etc.). La mise en &oelig;uvre d&rsquo;un tel environnement d&rsquo;expression multimodale dans l&rsquo;espace tangible n&eacute;cessite un dispositif comprenant diff&eacute;rents composants : des applications clientes install&eacute;es sur des terminaux mobiles connect&eacute;s au r&eacute;seau, un web-service proposant une API ouverte, un serveur de bases de donn&eacute;es ainsi qu&rsquo;une interface d&rsquo;administration des contenus.</p>\r\n<h3>Cr&eacute;er des nouvelles exp&eacute;riences participatives</h3>\r\n<p>L&rsquo;&eacute;laboration de la plateforme n&eacute;cessite &eacute;galement un travail sur les usages et de validation. Pour cela, nous d&eacute;velopperons des prototypes &agrave; chaque &eacute;tape du projet dans l&rsquo;objectif de mettre nos sc&eacute;narios &agrave; l&rsquo;&eacute;preuve et d&rsquo;en collecter et analyser les r&eacute;sultats pour am&eacute;liorer la plateforme. Le projet COSIMA d&eacute;finit ainsi un contexte d&rsquo;exp&eacute;rimentation selon diff&eacute;rents axes : la cr&eacute;ation de m&eacute;dias visuels et sonores associ&eacute;s &agrave; des informations de d&eacute;placement et de mouvement pour cr&eacute;er des cartographies ou des parcours en r&eacute;alit&eacute; augment&eacute;e. Le partage de m&eacute;dias situ&eacute;s dans un espace social pour la mise en sc&egrave;ne de jeux pervasifs ou de zones d&rsquo;expression publique. La diffusion temps r&eacute;el de m&eacute;dias situ&eacute;s vers une communaut&eacute; d&rsquo;utilisateurs permettant le d&eacute;ploiement de mobs, de spectacles vivants ou d&rsquo;exp&eacute;riences &laquo; large group &raquo;.</p>\r\n<h3>Soutenir des nouveaux mod&egrave;les &eacute;conomiques et le d&eacute;veloppement de communaut&eacute;s pour la cr&eacute;ation et diffusions de m&eacute;dias num&eacute;riques</h3>\r\n<p>L&rsquo;&eacute;volution combin&eacute;e du web et des plateformes mobiles d&eacute;finit de nouveaux paradigmes pour la diffusion de m&eacute;dias. La plateforme COSIMA favorisera l&rsquo;&eacute;mergence et la structuration de communaut&eacute;s autour de ces nouveaux m&eacute;dia. L&rsquo;&eacute;valuation et s&eacute;lection d&rsquo;un mod&egrave;le &eacute;conomique adapt&eacute; &agrave; cette plateforme fait partie son d&eacute;veloppement.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-13-CORD-010-01.</p>", "content_en": "<p>In the past decade, we have seen a huge change in media and their relationship with bodies and space with tangible interfaces, augmented reality, and ambient Internet. The COSIMA project will explore the relationship between body, media, and space via new interfaces and tools for collaborative creation. The aim of COSIMA is to implement a platform for publishing and disseminating medias situated in space and time, combining several sensory modalities. These contents partner proprioception and perception, involving the entire body in their creation and reception phases. The principle of augmented reality combines a digital space with tangible space. The use of this kind of space makes it possible to edit collaborative situated medias. The COSIMA platform&rsquo;s applications include artistic projects, innovative public services, events, and communication.</p>\r\n<h3>Implementation of an Accessible Platform</h3>\r\n<p>The principle objective of COSIMA is to democratize this new type of media via an accessible, generic, open, and interoperable platform. The project aims at the implementation of a platform that uses standard and open formats, enabling relationships with a variety of mobile technologies and existing systems. The platform will make it easier to carry out this type of experience at a lesser cost and in a more accessible manner for the general public (cultural institutions, public services, artists, etc.). Putting in place an environment of multimodal expression in tangible space requires a system made up of different components: client applications installed on mobile terminals connected to a network, a web service that offers an open API, a database server, and an administration interface for the contents.&nbsp;</p>\r\n<h3>Create new Participative Experiences</h3>\r\n<p>The creation of a platform also requires studying different uses and validation. For this, prototypes are developed at each stage of the project to test different scenarios and to collect and analyze the results to improve the platform. The COSIMA project therefore defines a context for experimentation according to different themes: the creation of visual and sound media associated with information about movement and movement to create maps or paths in augmented reality; situated media is shared in a social space for staging pervasive games or zones of public expression; dissemination of situated media in real-time to a community of users makes it possible to create mobs, performances, or large group experiences.</p>\r\n<h2>Supporting New Economic Models and the Development of Communities for the Creation and Dissemination of Digital Media</h2>\r\n<p>The combined development of Internet technology and mobile platforms defines new paradigms for the dissemination of medias. The COSIMA platform favors the surfacing and structuring of communities around these new media. The assessment and selection of an adapted economic model will be a part of its development.&nbsp;</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Projet reference : ANR-13-CORD-010-01.</p>", "date_from": "2013-11-01", "date_to": "2017-04-30", "user": null, "type": "external", "external_id": "ANR-13-CORD-010-01", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 1, "website": "http://cosima.ircam.fr/", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2, 7], "organizations": [121, 123, 122, 124, 23], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 43, "fields": {"keywords_string": "", "site": 1, "title": "RapidMix", "title_fr": "RapidMix", "title_en": "RapidMix", "slug": "rapid-mix", "_meta_title": "", "description": "Outils et modules musicaux pour les designers num\u00e9riques et les cr\u00e9ateurs de contenus", "description_fr": "Outils et modules musicaux pour les designers num\u00e9riques et les cr\u00e9ateurs de contenus", "description_en": "Real-time Adaptive Prototyping for Industrial Design of Multimodal Interactive eXpressive technology", "gen_description": false, "created": "2016-09-08T14:33:06.394Z", "updated": "2018-06-29T09:43:44.293Z", "status": 2, "publish_date": "2016-09-08T14:33:06Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;objectif du projet europ&eacute;en Rapid-Mix est de d&eacute;velopper de nouveaux modes d&rsquo;interaction musicale en int&eacute;grant des donn&eacute;es multimodales li&eacute;es aux mouvements et au corps. D&rsquo;un point de vue m&eacute;thodologique, le projet se base sur des approches centr&eacute;es utilisateur et sur le d&eacute;veloppement rapide de prototypes. Des techniques avanc&eacute;es d&rsquo;analyses de signaux et d&rsquo;apprentissage automatique sont &eacute;galement utilis&eacute;es. Le transfert de ces technologies vers les PMEs participantes repr&eacute;sente un aspect important du projet. Dans ce projet, l&rsquo;Ircam est en charge d&rsquo;une t&acirc;che sur le d&eacute;veloppement d&rsquo;applications prototypes (agile prototyping) et participe &eacute;galement &agrave; toutes les autres t&acirc;ches du projet.</p>", "content_fr": "<p>L&rsquo;objectif du projet europ&eacute;en Rapid-Mix est de d&eacute;velopper de nouveaux modes d&rsquo;interaction musicale en int&eacute;grant des donn&eacute;es multimodales li&eacute;es aux mouvements et au corps. D&rsquo;un point de vue m&eacute;thodologique, le projet se base sur des approches centr&eacute;es utilisateur et sur le d&eacute;veloppement rapide de prototypes. Des techniques avanc&eacute;es d&rsquo;analyses de signaux et d&rsquo;apprentissage automatique sont &eacute;galement utilis&eacute;es. Le transfert de ces technologies vers les PMEs participantes repr&eacute;sente un aspect important du projet. Dans ce projet, l&rsquo;Ircam est en charge d&rsquo;une t&acirc;che sur le d&eacute;veloppement d&rsquo;applications prototypes (agile prototyping) et participe &eacute;galement &agrave; toutes les autres t&acirc;ches du projet.</p>", "content_en": "<p>Rapid-Mix&rsquo;s goal is to develop new modes of musical interaction by including multimodal data connected to movement and the body. From a methodology point of view, the project is based on user-centric evaluations and on the quick development of prototypes. Advanced techniques for signal analysis and automatic learning are also used. The transfer of these technologies to small business taking part in the project is an important aspect of the project. In this project, IRCAM is responsible for the development of application prototypes (agile prototyping) in addition to its implication in the other aspects of the project.</p>", "date_from": "2015-02-01", "date_to": "2018-01-31", "user": null, "type": "external", "external_id": "644862", "program": 4, "program_type": 12, "call": 9, "lead_team": null, "lead_organization": 598, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7], "organizations": [125, 129, 23, 126, 127, 128, 82], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 44, "fields": {"keywords_string": "", "site": 1, "title": "Music Bricks", "title_fr": "Music Bricks", "title_en": "Music Bricks", "slug": "musicbricks", "_meta_title": "", "description": "Outils et modules musicaux pour les designers num\u00e9riques et les cr\u00e9ateurs de contenus", "description_fr": "Outils et modules musicaux pour les designers num\u00e9riques et les cr\u00e9ateurs de contenus", "description_en": "Musical Building Blocks for Digital Makers and Content Creators", "gen_description": false, "created": "2016-09-08T14:39:21.576Z", "updated": "2018-06-29T09:38:46.241Z", "status": 2, "publish_date": "2016-09-08T14:39:21Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;objectif du projet europ&eacute;en MusicBricks est de faciliter le transfert de nouvelles technologies musicales issues de certains des principaux centres de recherche europ&eacute;ens du domaine vers des PMEs focalis&eacute;es sur la cr&eacute;ation num&eacute;rique. Le projet passe par la constitution d&rsquo;interfaces de programmation, d&rsquo;interfaces graphiques et tangibles, du d&eacute;veloppement d&rsquo;un &eacute;cosyst&egrave;me &agrave; partir des &eacute;v&eacute;nements MusicTechFest et d&rsquo;incubateurs des technologies s&eacute;lectionn&eacute;es en vue de les pr&eacute;parer &agrave; un acc&egrave;s au march&eacute;. Dans ce projet, l&rsquo;Ircam est principalement en charge du d&eacute;ploiement de technologies li&eacute;es aux interfaces tangibles et graphiques (TUI et GUI). Il s&rsquo;agira en particulier de d&eacute;velopper des modules d&rsquo;analyse de donn&eacute;es gestuelles et de mapping entre mouvements et sons.</p>\r\n<p>Nous d&eacute;veloppons &eacute;galement des dispositifs de captation compl&eacute;mentaires, compatibles avec l&rsquo;utilisation sc&eacute;nique ou des contextes p&eacute;dagogiques. L&rsquo;ensemble de ces m&eacute;thodes nous permet de mesurer et de mod&eacute;liser les gestes d&rsquo;instrumentistes. Diverses probl&eacute;matiques sont abord&eacute;es comme le contr&ocirc;le moteur et l&rsquo;apprentissage dans le cas d&rsquo;un geste expert, la caract&eacute;risation de modes de jeu en consid&eacute;rant &agrave; la fois les param&egrave;tres sonores et gestuels, ainsi que la mod&eacute;lisation de ph&eacute;nom&egrave;nes de coarticulation gestuelle similaires &agrave; ceux de la parole. Un deuxi&egrave;me axe concerne le d&eacute;veloppement de syst&egrave;mes d&rsquo;analyse et de reconnaissance du geste.</p>", "content_fr": "<p>L&rsquo;objectif du projet europ&eacute;en MusicBricks est de faciliter le transfert de nouvelles technologies musicales issues de certains des principaux centres de recherche europ&eacute;ens du domaine vers des PMEs focalis&eacute;es sur la cr&eacute;ation num&eacute;rique. Le projet passe par la constitution d&rsquo;interfaces de programmation, d&rsquo;interfaces graphiques et tangibles, du d&eacute;veloppement d&rsquo;un &eacute;cosyst&egrave;me &agrave; partir des &eacute;v&eacute;nements MusicTechFest et d&rsquo;incubateurs des technologies s&eacute;lectionn&eacute;es en vue de les pr&eacute;parer &agrave; un acc&egrave;s au march&eacute;. Dans ce projet, l&rsquo;Ircam est principalement en charge du d&eacute;ploiement de technologies li&eacute;es aux interfaces tangibles et graphiques (TUI et GUI). Il s&rsquo;agira en particulier de d&eacute;velopper des modules d&rsquo;analyse de donn&eacute;es gestuelles et de mapping entre mouvements et sons.</p>\r\n<p>Nous d&eacute;veloppons &eacute;galement des dispositifs de captation compl&eacute;mentaires, compatibles avec l&rsquo;utilisation sc&eacute;nique ou des contextes p&eacute;dagogiques. L&rsquo;ensemble de ces m&eacute;thodes nous permet de mesurer et de mod&eacute;liser les gestes d&rsquo;instrumentistes. Diverses probl&eacute;matiques sont abord&eacute;es comme le contr&ocirc;le moteur et l&rsquo;apprentissage dans le cas d&rsquo;un geste expert, la caract&eacute;risation de modes de jeu en consid&eacute;rant &agrave; la fois les param&egrave;tres sonores et gestuels, ainsi que la mod&eacute;lisation de ph&eacute;nom&egrave;nes de coarticulation gestuelle similaires &agrave; ceux de la parole. Un deuxi&egrave;me axe concerne le d&eacute;veloppement de syst&egrave;mes d&rsquo;analyse et de reconnaissance du geste.</p>", "content_en": "<p>The goal of the European project MusicBricks is to facilitate the transfer of new musical technologies from major European research centers specialized in the domain to small digital creation companies. The project involves the creation of programming interfaces, of graphic and tangible user interfaces, the development of an ecosystem based on events during Music Tech Fest and in selected technology incubators to prepare access to the market.</p>\r\n<p>In this project, IRCAM is in charge of the diffusion of technologies connected to tangible and graphic user interfaces (TUI and GUI). A particular focus of the project is to develop analysis modules of gestural data and mapping between movements and sounds.</p>", "date_from": "2015-01-01", "date_to": "2016-06-30", "user": null, "type": "external", "external_id": "644871", "program": 4, "program_type": 13, "call": 12, "lead_team": null, "lead_organization": 601, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7], "organizations": [81, 130, 73, 82, 118], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 45, "fields": {"keywords_string": "", "site": 1, "title": "MIM", "title_fr": "MIM", "title_en": "MIM", "slug": "mim", "_meta_title": "", "description": "Enhancing Motion Interaction through Music Performance", "description_fr": "Enhancing Motion Interaction through Music Performance", "description_en": "Enhancing Motion Interaction through Music Performance", "gen_description": false, "created": "2016-09-08T14:42:59.993Z", "updated": "2018-06-29T09:39:25.946Z", "status": 2, "publish_date": "2016-09-08T14:42:59Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet MIM concerne les interactions homme-machine bas&eacute;es sur le mouvement, en mettant &agrave; profit une approche multidisciplinaire entre la psychologie exp&eacute;rimentale, l&rsquo;informatique musicale et des m&eacute;thodes de mod&eacute;lisation computationnelle.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Dans un premier temps, le projet s&rsquo;int&eacute;resse aux gestes experts, comme ceux des musiciens, afin d&rsquo;&eacute;tudier &agrave; la fois les m&eacute;canismes d&rsquo;apprentissage sensori-moteur et de contr&ocirc;le expressif dans le mouvement humain. Des mod&egrave;les computationnels de ces m&eacute;canismes seront d&eacute;velopp&eacute;s &agrave; partir de donn&eacute;es exp&eacute;rimentales des mouvements d&rsquo;interpr&egrave;tes. Dans un deuxi&egrave;me temps, les mod&egrave;les d&eacute;velopp&eacute;s seront appliqu&eacute;s dans le domaine des Instruments de musique num&eacute;riques (DMI) afin d&rsquo;&eacute;laborer des nouveaux types d&rsquo;instrument prenant en compte explicitement les m&eacute;canismes d&rsquo;apprentissage sensori-moteur. Par cons&eacute;quent, le projet contribue &agrave; deux principaux domaines de recherche encore peu explor&eacute;s. Premi&egrave;rement, il contribue &agrave; la compr&eacute;hension fondamentale des processus d&rsquo;apprentissage sensori-moteur en consid&eacute;rant des mouvements humains complexes tels que les mouvements des musiciens. Deuxi&egrave;mement, il propose le d&eacute;veloppement et l&rsquo;&eacute;valuation de syst&egrave;mes interactifs musicaux originaux en s&rsquo;appuyant sur des mod&egrave;les computationnels de gestes musicaux expressifs.</p>", "content_fr": "<p>Le projet MIM concerne les interactions homme-machine bas&eacute;es sur le mouvement, en mettant &agrave; profit une approche multidisciplinaire entre la psychologie exp&eacute;rimentale, l&rsquo;informatique musicale et des m&eacute;thodes de mod&eacute;lisation computationnelle.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Dans un premier temps, le projet s&rsquo;int&eacute;resse aux gestes experts, comme ceux des musiciens, afin d&rsquo;&eacute;tudier &agrave; la fois les m&eacute;canismes d&rsquo;apprentissage sensori-moteur et de contr&ocirc;le expressif dans le mouvement humain. Des mod&egrave;les computationnels de ces m&eacute;canismes seront d&eacute;velopp&eacute;s &agrave; partir de donn&eacute;es exp&eacute;rimentales des mouvements d&rsquo;interpr&egrave;tes. Dans un deuxi&egrave;me temps, les mod&egrave;les d&eacute;velopp&eacute;s seront appliqu&eacute;s dans le domaine des Instruments de musique num&eacute;riques (DMI) afin d&rsquo;&eacute;laborer des nouveaux types d&rsquo;instrument prenant en compte explicitement les m&eacute;canismes d&rsquo;apprentissage sensori-moteur. Par cons&eacute;quent, le projet contribue &agrave; deux principaux domaines de recherche encore peu explor&eacute;s. Premi&egrave;rement, il contribue &agrave; la compr&eacute;hension fondamentale des processus d&rsquo;apprentissage sensori-moteur en consid&eacute;rant des mouvements humains complexes tels que les mouvements des musiciens. Deuxi&egrave;mement, il propose le d&eacute;veloppement et l&rsquo;&eacute;valuation de syst&egrave;mes interactifs musicaux originaux en s&rsquo;appuyant sur des mod&egrave;les computationnels de gestes musicaux expressifs.</p>", "content_en": "<p>This project focuses on Human-Computer interactions based on movement, leveraging a multidisciplinary approach between experimental psychology, music technology, and computational modeling. Initially, the project will look at sensorimotor learning mechanisms and expressive control in human movement.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>Computational models of these mechanisms will be developed based on experimental data gathered from the performers&rsquo; movements. Then, the models developed will be applied to the domain of Digital Musical Instruments (DMI), creating new types of instruments based on sensorimotor learning mechanisms. The project contributes to two fairly uncharted research areas. Firstly, it contributes to the fundamental understanding of sensorimotor learning processes by considering complex human motion such as the movements of musicians. Secondly, it represents the development and assessment of unique interactive musical systems using computational models of expressive musical gestures.</p>", "date_from": "2016-01-01", "date_to": "2018-12-31", "user": null, "type": "external", "external_id": "659232", "program": 4, "program_type": 14, "call": 5, "lead_team": null, "lead_organization": 1, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7], "organizations": [131], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 46, "fields": {"keywords_string": "", "site": 1, "title": "Legos", "title_fr": "Legos", "title_en": "Legos", "slug": "legos", "_meta_title": "", "description": "Apprentissage sensori-moteur dans les syst\u00e8mes interactifs sonores bas\u00e9s sur le geste", "description_fr": "Apprentissage sensori-moteur dans les syst\u00e8mes interactifs sonores bas\u00e9s sur le geste", "description_en": "Sensori-motor learning in gesture-based interactive sound systems", "gen_description": false, "created": "2016-09-08T14:51:47.883Z", "updated": "2018-07-25T14:45:49.061Z", "status": 2, "publish_date": "2016-09-08T14:51:47Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;id&eacute;e centrale du projet Legos est de croiser des expertises avanc&eacute;es sur les technologies de contr&ocirc;le sonore par le geste avec des probl&eacute;matiques li&eacute;es aux neurosciences et aux sciences cognitives de l&rsquo;audition, concernant en particulier les apprentissages sensori-moteurs. Nous pensons en effet que ces aspects sont insuffisamment int&eacute;gr&eacute;s aux d&eacute;veloppements des syst&egrave;mes sonores interactifs. Une meilleure compr&eacute;hension des m&eacute;canismes d&rsquo;apprentissage du couplage geste/son pour la r&eacute;alisation d&rsquo;une action est n&eacute;cessaire pour proposer des m&eacute;thodologies efficaces pour leur &eacute;valuation et optimisation. Cela permettra de d&eacute;passer de mani&egrave;re significative les limites auxquelles sont confront&eacute;s les syst&egrave;mes sonores interactifs actuels bas&eacute;s sur le geste, souvent d&eacute;velopp&eacute;s de mani&egrave;re empirique.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;objectif du projet Legos est d&rsquo;&eacute;tudier de mani&egrave;re syst&eacute;matique l&rsquo;&eacute;valuation de la qualit&eacute; du couplage geste-son dans des syst&egrave;mes sonores bas&eacute;s sur une interface gestuelle. Pour cela, nous &eacute;valuerons l&rsquo;apprentissage sensori-moteur et en particulier son &eacute;volution dans le temps dans divers dispositifs interactifs. Il s&rsquo;agit donc &agrave; la fois de d&eacute;velopper, d&rsquo;&eacute;valuer et comparer des syst&egrave;mes interactifs afin de proposer &agrave; moyen terme des nouvelles interfaces gestuelles de contr&ocirc;le de m&eacute;dias num&eacute;riques (dont les jeux vid&eacute;os et le design sonore) ainsi que des applications m&eacute;dicales comme la r&eacute;&eacute;ducation.</p>\r\n<p>Le projet permettra d&rsquo;apporter un nouvel &eacute;clairage sur la perception des sons dans un processus actif engageant une action de l&rsquo;auditeur. Le projet s&rsquo;appuie sur des m&eacute;thodes exp&eacute;rimentales, consid&eacute;rant les trois &eacute;clairages suivants :</p>\r\n<ul>\r\n<li><strong>Contr&ocirc;le sonore</strong><br />Ce premier point correspond &agrave; un cas d&rsquo;apprentissage sensori-moteur o&ugrave; la finalit&eacute; est de produire un son donn&eacute; gr&acirc;ce &agrave; la manipulation d&rsquo;une interface gestuelle, comme dans le cas des instruments de musique num&eacute;rique. L&rsquo;apprentissage sensorimoteur est &eacute;valu&eacute; au niveau de la qualit&eacute; du son produit.</li>\r\n<li><strong>Apprentissage de geste avec retour sonore</strong><br />Ce deuxi&egrave;me point correspond &agrave; l&rsquo;apprentissage sensori-moteur dans le cas o&ugrave; la finalit&eacute; est d&rsquo;effectuer un geste donn&eacute; en s&rsquo;aidant d&rsquo;un retour sonore. L&rsquo;apprentissage sensori-moteur est dans ce cas observ&eacute; au niveau de la qualit&eacute;/performance du geste reproduit.</li>\r\n<li><strong>Design sonore interactif</strong><br />Ce troisi&egrave;me point correspond &agrave; l&rsquo;apprentissage sensori-moteur dans le cas d&rsquo;interfaces tangibles, o&ugrave; la finalit&eacute; est la manipulation correcte d&rsquo;un objet. Dans ce dernier cas, l&rsquo;apprentissage sensori-moteur est jug&eacute; &agrave; travers la manipulation de l&rsquo;objet interactif pour r&eacute;pondre &agrave; un usage donn&eacute;.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-11-BS02-012-01.</p>", "content_fr": "<p>L&rsquo;id&eacute;e centrale du projet Legos est de croiser des expertises avanc&eacute;es sur les technologies de contr&ocirc;le sonore par le geste avec des probl&eacute;matiques li&eacute;es aux neurosciences et aux sciences cognitives de l&rsquo;audition, concernant en particulier les apprentissages sensori-moteurs. Nous pensons en effet que ces aspects sont insuffisamment int&eacute;gr&eacute;s aux d&eacute;veloppements des syst&egrave;mes sonores interactifs. Une meilleure compr&eacute;hension des m&eacute;canismes d&rsquo;apprentissage du couplage geste/son pour la r&eacute;alisation d&rsquo;une action est n&eacute;cessaire pour proposer des m&eacute;thodologies efficaces pour leur &eacute;valuation et optimisation. Cela permettra de d&eacute;passer de mani&egrave;re significative les limites auxquelles sont confront&eacute;s les syst&egrave;mes sonores interactifs actuels bas&eacute;s sur le geste, souvent d&eacute;velopp&eacute;s de mani&egrave;re empirique.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;objectif du projet Legos est d&rsquo;&eacute;tudier de mani&egrave;re syst&eacute;matique l&rsquo;&eacute;valuation de la qualit&eacute; du couplage geste-son dans des syst&egrave;mes sonores bas&eacute;s sur une interface gestuelle. Pour cela, nous &eacute;valuerons l&rsquo;apprentissage sensori-moteur et en particulier son &eacute;volution dans le temps dans divers dispositifs interactifs. Il s&rsquo;agit donc &agrave; la fois de d&eacute;velopper, d&rsquo;&eacute;valuer et comparer des syst&egrave;mes interactifs afin de proposer &agrave; moyen terme des nouvelles interfaces gestuelles de contr&ocirc;le de m&eacute;dias num&eacute;riques (dont les jeux vid&eacute;os et le design sonore) ainsi que des applications m&eacute;dicales comme la r&eacute;&eacute;ducation.</p>\r\n<p>Le projet permettra d&rsquo;apporter un nouvel &eacute;clairage sur la perception des sons dans un processus actif engageant une action de l&rsquo;auditeur. Le projet s&rsquo;appuie sur des m&eacute;thodes exp&eacute;rimentales, consid&eacute;rant les trois &eacute;clairages suivants :</p>\r\n<ul>\r\n<li><strong>Contr&ocirc;le sonore</strong><br />Ce premier point correspond &agrave; un cas d&rsquo;apprentissage sensori-moteur o&ugrave; la finalit&eacute; est de produire un son donn&eacute; gr&acirc;ce &agrave; la manipulation d&rsquo;une interface gestuelle, comme dans le cas des instruments de musique num&eacute;rique. L&rsquo;apprentissage sensorimoteur est &eacute;valu&eacute; au niveau de la qualit&eacute; du son produit.</li>\r\n<li><strong>Apprentissage de geste avec retour sonore</strong><br />Ce deuxi&egrave;me point correspond &agrave; l&rsquo;apprentissage sensori-moteur dans le cas o&ugrave; la finalit&eacute; est d&rsquo;effectuer un geste donn&eacute; en s&rsquo;aidant d&rsquo;un retour sonore. L&rsquo;apprentissage sensori-moteur est dans ce cas observ&eacute; au niveau de la qualit&eacute;/performance du geste reproduit.</li>\r\n<li><strong>Design sonore interactif</strong><br />Ce troisi&egrave;me point correspond &agrave; l&rsquo;apprentissage sensori-moteur dans le cas d&rsquo;interfaces tangibles, o&ugrave; la finalit&eacute; est la manipulation correcte d&rsquo;un objet. Dans ce dernier cas, l&rsquo;apprentissage sensori-moteur est jug&eacute; &agrave; travers la manipulation de l&rsquo;objet interactif pour r&eacute;pondre &agrave; un usage donn&eacute;.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-11-BS02-012-01.</p>", "content_en": "<p>The central idea of the LEGOS project is to fertilize interdisciplinary expertise in sonic gesture control technologies with neurosciences, especially in regards to sensori-motor learning. We believe that these aspects are not sufficiently taken into account in the development of interactive sound systems. A better understanding of the sensori-motor learning mechanisms of the gesture / sound coupling is necessary to provide efficient methodologies for their evaluation and optimization. Such advances would significantly expand the usability of today&rsquo;s gesture-based interactive sound systems, often developed empirically.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The objective of the LEGOS project is to study systematically the coupling quality in gesture-sound systems using gestural interfaces. For this, we will evaluate the sensori-motor learning, and particularly its evolution over time, in various interactive devices. The aims are therefore to develop, evaluate, and compare interactive systems, with the mid-term goal of offering renewed paradigms for gestural interfaces control of digital media (including video games and sound design), as well as prototypes for medical applications such as rehabilitation.</p>\r\n<p>The project will use extensively an experimental approach, considering these three perspectives:</p>\r\n<ul>\r\n<li><strong>Sound Control</strong>: The first point corresponds to a case of sensori-motor learning where the goal is to produce a given sound through the manipulation of a gestural interface, as in the case of digital musical instruments. The sensori-motor learning is assessed in terms of the quality of the sound production.</li>\r\n<li><strong>Learning Gesture with Audio Feedback</strong>: This second point corresponds to the sensori-motor learning where the goal is to make a gesture guided by an audio feedback. The sensori-motor learning in this case is assessed in terms of the gesture repeatability.</li>\r\n<li><strong>Interactive Sound Design</strong>: This third point corresponds to sensori-motor learning in the case of tangible interfaces, where the goal is the proper handling of an object. The sensori-motor learning in this case is assessed through the quality of the objet manipulation for a given use.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-11-BS02-012-01.</p>", "date_from": "2010-11-01", "date_to": "2015-03-31", "user": null, "type": "external", "external_id": "ANR-11-BS02-012-01", "program": 1, "program_type": 2, "call": 16, "lead_team": null, "lead_organization": 1, "website": "http://legos.ircam.fr/", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2, 7, 3], "organizations": [132, 115], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 47, "fields": {"keywords_string": "", "site": 1, "title": "Interlude", "title_fr": "Interlude", "title_en": "Interlude", "slug": "interlude", "_meta_title": "", "description": "\u00c9tudes num\u00e9riques sur l'exploration et l'interaction gestuelle expressive avec des contenus musicaux", "description_fr": "\u00c9tudes num\u00e9riques sur l'exploration et l'interaction gestuelle expressive avec des contenus musicaux", "description_en": "New Digital Paradigms for Exploration and Interaction of Expressive Movement with Music", "gen_description": false, "created": "2016-09-08T15:06:37.671Z", "updated": "2018-07-25T14:45:12.601Z", "status": 2, "publish_date": "2016-09-08T15:06:37Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet touchait les trois axes de recherche de l&rsquo;&eacute;quipe Interaction son musique mouvement : paradigmes d&rsquo;interactivit&eacute;, mod&eacute;lisation multimodale et interfaces gestuelles collaboratives. Les d&eacute;veloppements r&eacute;cents de l&rsquo;informatique musicale permettent d&rsquo;analyser, de traiter, de manipuler la musique et le son tant sur le plan du signal audio que sur le plan symbolique d&rsquo;une partition. Ces traitements et manipulations sont en g&eacute;n&eacute;ral effectu&eacute;s &agrave; l&rsquo;aide d&rsquo;interfaces classiques : clavier-souris ou &eacute;ventuellement des interfaces de mixage avec des potentiom&egrave;tres. De fait, les possibilit&eacute;s d&rsquo;interagir gestuellement et corporellement, comme dans le cas d&rsquo;instruments acoustiques, avec des &eacute;l&eacute;ments sonores num&eacute;riques, restent encore peu exploit&eacute;es.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le but du projet Interlude &eacute;tait pr&eacute;cis&eacute;ment d&rsquo;explorer de nouveaux moyens d&rsquo;expression musicale en couplant des syst&egrave;mes de captation de geste modulaires, des logiciels innovants de synth&egrave;se sonore interactive, et des syst&egrave;mes de visualisation dynamique. Les retomb&eacute;es attendues concernent &agrave; la fois la cr&eacute;ation artistique, la p&eacute;dagogie musicale et le monde des jeux musicaux. Plus g&eacute;n&eacute;ralement, ce projet vise une communaut&eacute; d&rsquo;utilisateurs en plein essor, compos&eacute;e aussi bien de professionnels que du grand public, qui s&rsquo;int&eacute;resse &agrave; une utilisation gestuelle et expressive des nouveaux outils num&eacute;riques.</p>\r\n<p>Les nouvelles interfaces musicales MO (Modular Musical Objects) issues du projet ont remport&eacute; le 1<sup>er</sup> prix du concours international Guthman 2011 des nouveaux instruments de musique. Ces interfaces ont fait partie de plusieurs expositions internationales, dont &laquo; Talk to Me &raquo; au Moma de New york, &agrave; la Biennale du design Saint-Etienne, Objet(s) du num&eacute;rique - design d&rsquo;un nouveau monde industriel, Lift Experience &agrave; Gen&egrave;ve.</p>\r\n<p>Les interfaces MO et les logiciels associ&eacute;s (MuBu, gesture follower) ont permis des applications concr&egrave;tes, en particulier pour la p&eacute;dagogie musicale. Celles-ci ont &eacute;t&eacute; appliqu&eacute;es avec succ&egrave;s par une &eacute;cole de musique, l&rsquo;Atelier des Feuillantines. De nouvelles formes de jeux musicaux ont &eacute;galement &eacute;t&eacute; cr&eacute;&eacute;es, comme l&rsquo;Urban Musical Game qui a &eacute;t&eacute; pr&eacute;sent&eacute; au festival Futur en Seine 2011 (jeux de balles musicales). Notons enfin que le projet a permis de faire &eacute;merger une start-up, Phonotonic, qui valorisera une partie de ces d&eacute;veloppements. Des valorisations industrielles sp&eacute;cifiques sont &eacute;galement en cours par les diff&eacute;rents partenaires du projet. Le projet a d&rsquo;ores et d&eacute;j&agrave; fait l&rsquo;objet de plus de 17 communications scientifiques, comprenant&nbsp; des journaux scientifiques et des actes de conf&eacute;rences nationales et internationales, de nombreuses communications dans la presse (&eacute;crite et internet) ainsi que de plusieurs pr&eacute;sentations publiques en&nbsp; Europe, aux &eacute;tats-Unis et en Asie.</p>\r\n<p>Le projet a re&ccedil;u le prix ANR du num&eacute;rique dans la cat&eacute;gorie &laquo; impact soci&eacute;tal &raquo; en 2013.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2008-CORD-010-01.</p>", "content_fr": "<p>Ce projet touchait les trois axes de recherche de l&rsquo;&eacute;quipe Interaction son musique mouvement : paradigmes d&rsquo;interactivit&eacute;, mod&eacute;lisation multimodale et interfaces gestuelles collaboratives. Les d&eacute;veloppements r&eacute;cents de l&rsquo;informatique musicale permettent d&rsquo;analyser, de traiter, de manipuler la musique et le son tant sur le plan du signal audio que sur le plan symbolique d&rsquo;une partition. Ces traitements et manipulations sont en g&eacute;n&eacute;ral effectu&eacute;s &agrave; l&rsquo;aide d&rsquo;interfaces classiques : clavier-souris ou &eacute;ventuellement des interfaces de mixage avec des potentiom&egrave;tres. De fait, les possibilit&eacute;s d&rsquo;interagir gestuellement et corporellement, comme dans le cas d&rsquo;instruments acoustiques, avec des &eacute;l&eacute;ments sonores num&eacute;riques, restent encore peu exploit&eacute;es.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le but du projet Interlude &eacute;tait pr&eacute;cis&eacute;ment d&rsquo;explorer de nouveaux moyens d&rsquo;expression musicale en couplant des syst&egrave;mes de captation de geste modulaires, des logiciels innovants de synth&egrave;se sonore interactive, et des syst&egrave;mes de visualisation dynamique. Les retomb&eacute;es attendues concernent &agrave; la fois la cr&eacute;ation artistique, la p&eacute;dagogie musicale et le monde des jeux musicaux. Plus g&eacute;n&eacute;ralement, ce projet vise une communaut&eacute; d&rsquo;utilisateurs en plein essor, compos&eacute;e aussi bien de professionnels que du grand public, qui s&rsquo;int&eacute;resse &agrave; une utilisation gestuelle et expressive des nouveaux outils num&eacute;riques.</p>\r\n<p>Les nouvelles interfaces musicales MO (Modular Musical Objects) issues du projet ont remport&eacute; le 1<sup>er</sup> prix du concours international Guthman 2011 des nouveaux instruments de musique. Ces interfaces ont fait partie de plusieurs expositions internationales, dont &laquo; Talk to Me &raquo; au Moma de New york, &agrave; la Biennale du design Saint-Etienne, Objet(s) du num&eacute;rique - design d&rsquo;un nouveau monde industriel, Lift Experience &agrave; Gen&egrave;ve.</p>\r\n<p>Les interfaces MO et les logiciels associ&eacute;s (MuBu, gesture follower) ont permis des applications concr&egrave;tes, en particulier pour la p&eacute;dagogie musicale. Celles-ci ont &eacute;t&eacute; appliqu&eacute;es avec succ&egrave;s par une &eacute;cole de musique, l&rsquo;Atelier des Feuillantines. De nouvelles formes de jeux musicaux ont &eacute;galement &eacute;t&eacute; cr&eacute;&eacute;es, comme l&rsquo;Urban Musical Game qui a &eacute;t&eacute; pr&eacute;sent&eacute; au festival Futur en Seine 2011 (jeux de balles musicales). Notons enfin que le projet a permis de faire &eacute;merger une start-up, Phonotonic, qui valorisera une partie de ces d&eacute;veloppements. Des valorisations industrielles sp&eacute;cifiques sont &eacute;galement en cours par les diff&eacute;rents partenaires du projet. Le projet a d&rsquo;ores et d&eacute;j&agrave; fait l&rsquo;objet de plus de 17 communications scientifiques, comprenant&nbsp; des journaux scientifiques et des actes de conf&eacute;rences nationales et internationales, de nombreuses communications dans la presse (&eacute;crite et internet) ainsi que de plusieurs pr&eacute;sentations publiques en&nbsp; Europe, aux &eacute;tats-Unis et en Asie.</p>\r\n<p>Le projet a re&ccedil;u le prix ANR du num&eacute;rique dans la cat&eacute;gorie &laquo; impact soci&eacute;tal &raquo; en 2013.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2008-CORD-010-01.</p>", "content_en": "<p>This project touched upon three major research topics in the Real-Time Musical Interaction team: paradigms for interactivity, multimodal modeling, and collaborative movement interfaces. Recent developments in computer music have made it possible to analyze, process, and manipulate music and sound; both the audio signal and sound&rsquo;s symbolic representation (i.e. the score). These processing techniques and manipulations are generally carried out using traditional interfaces such as a keyboard or a mouse, perhaps using interfaces for mixing with potentiometers. yet, the possibilities of interaction between gestures and larger body movements, as is the case with acoustic instruments with digital sound elements, still remains largely untapped.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The goal of the INTERLUDE project was to explore new means of musical expression by combining modular motion capture systems, innovative software programs for interactive sound synthesis, and dynamic systems for visualization. The expected findings touch artistic creation, musical education, and the world of musical games. This project focuses on a growing community of users that includes members of the general public who are interested in gestural and expressive use of new digital tools.</p>\r\n<p>The MO &ndash; Modular Musical Objects interfaces being used in different situations (photos: nodesign.net) The new musical MO (Modular Musical Objects) interfaces that were developed in this project won first prize in the international Guthman competition for new musical instruments in 2011. These interfaces were featured in several international exhibitions such as &ldquo;Talk to Me&rdquo; at the MoMa in New york, the Biennale du Design St-Etienne, Objet(s) du num&eacute;rique - Design d&rsquo;un nouveau monde Industriel in Paris, and the Lift Experience in Geneva.</p>\r\n<p>The MO &ndash; Modular Musical Objects interfaces being used in different situations (photos: nodesign.net). The MO interfaces and associated software (MuBu, gesture follower) have led to concrete applications, in particular for musical education. These applications have been used successfully in the Atelier des Feuillantines music school. New forms of musical games have also been created such as Urban Musical Game (a musical ball game), presented during the Futur en Seine festival in 2011. This project has also led to the creation of Phonotonic, a start-up that develops a certain number of these advances. Certain project partners <br />are also carrying out specific industrial developments.This project has already been the object of over 17 scientific communications, including scientific journals, the proceedings from national and international conferences, numerous mentions in the press (printed and online), as well as several public presentations in Europe, in the United States, and in Asia.</p>\r\n<p>This project was the winner of the 2013 ANR Digital award in the category \"societal impact\".</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-2008-CORD-010-01.</p>", "date_from": "2008-12-01", "date_to": "2010-07-31", "user": null, "type": "external", "external_id": "ANR-2008-CORD-010-01", "program": 1, "program_type": 1, "call": null, "lead_team": null, "lead_organization": 1, "website": "http://interlude.ircam.fr/", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 48, "fields": {"keywords_string": "", "site": 1, "title": "Instruments augment\u00e9s", "title_fr": "Instruments augment\u00e9s", "title_en": "The Augmented Instruments", "slug": "instruments-augmentes", "_meta_title": "", "description": "Instruments acoustiques auxquels sont int\u00e9gr\u00e9s des capteurs", "description_fr": "Instruments acoustiques auxquels sont int\u00e9gr\u00e9s des capteurs", "description_en": "Acoustic instruments that have been fitted with sensors", "gen_description": false, "created": "2016-09-08T15:09:08.891Z", "updated": "2019-01-11T14:30:10.939Z", "status": 2, "publish_date": "2016-09-08T15:09:08Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les instruments augment&eacute;s correspondent &agrave; des instruments acoustiques auxquels sont int&eacute;gr&eacute;s des capteurs, afin de transmettre en temps r&eacute;el des param&egrave;tres gestuels. Ces instruments sont sp&eacute;cialement bien adapt&eacute;s au contexte de musique mixte acoustique et &eacute;lectronique. Ces travaux s&rsquo;effectuent en &eacute;troite relation avec des compositeurs et interpr&egrave;tes dont le but est d&rsquo;int&eacute;grer ces technologies dans leurs &oelig;uvres. Ces d&eacute;veloppements s&rsquo;inscrivent &eacute;galement dans le cadre de recherche sur le geste instrumental.&nbsp;</p>\r\n<p>Ce projet avait &eacute;t&eacute; initi&eacute; par le d&eacute;veloppement du &laquo; violon augment&eacute; &raquo;, qui s&rsquo;est fortement d&eacute;velopp&eacute;, en raison d&rsquo;un int&eacute;r&ecirc;t accru des compositeurs. Nous travaillons d&eacute;sormais sur tous les instruments du quatuor &agrave; cordes, ainsi que sur certains instruments de percussions. Diverses techniques informatiques sont &eacute;galement d&eacute;velopp&eacute;es pour analyser, reconna&icirc;tre et suivre les gestes instrumentaux. Par exemple, un vocabulaire d&rsquo;&eacute;l&eacute;ments musicaux comme des modes de jeux ou des phrases musicales peut &ecirc;tre d&eacute;fini par le compo-siteur, et servir de base pour l&rsquo;interaction avec des processus sonores comme la synth&egrave;se ou la spatialisation. Ces outils permettent &eacute;galement le d&eacute;veloppement d&rsquo;une nouvelle g&eacute;n&eacute;ration de suivi de partition. Finalement, il est &agrave; noter que les instruments augment&eacute;s sont utilis&eacute;s dans des cr&eacute;ations musicales mais &eacute;galement dans le cadre d&rsquo;applications p&eacute;dagogiques.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Interaction son musique mouvement</a>, <a href=\"/recherche/equipes-recherche/systemes-et-signaux-sonores-audioacoustique-instruments-s3am/\">S3AM</a>.</p>", "content_fr": "<p>Les instruments augment&eacute;s correspondent &agrave; des instruments acoustiques auxquels sont int&eacute;gr&eacute;s des capteurs, afin de transmettre en temps r&eacute;el des param&egrave;tres gestuels. Ces instruments sont sp&eacute;cialement bien adapt&eacute;s au contexte de musique mixte acoustique et &eacute;lectronique. Ces travaux s&rsquo;effectuent en &eacute;troite relation avec des compositeurs et interpr&egrave;tes dont le but est d&rsquo;int&eacute;grer ces technologies dans leurs &oelig;uvres. Ces d&eacute;veloppements s&rsquo;inscrivent &eacute;galement dans le cadre de recherche sur le geste instrumental.&nbsp;</p>\r\n<p>Ce projet avait &eacute;t&eacute; initi&eacute; par le d&eacute;veloppement du &laquo; violon augment&eacute; &raquo;, qui s&rsquo;est fortement d&eacute;velopp&eacute;, en raison d&rsquo;un int&eacute;r&ecirc;t accru des compositeurs. Nous travaillons d&eacute;sormais sur tous les instruments du quatuor &agrave; cordes, ainsi que sur certains instruments de percussions. Diverses techniques informatiques sont &eacute;galement d&eacute;velopp&eacute;es pour analyser, reconna&icirc;tre et suivre les gestes instrumentaux. Par exemple, un vocabulaire d&rsquo;&eacute;l&eacute;ments musicaux comme des modes de jeux ou des phrases musicales peut &ecirc;tre d&eacute;fini par le compo-siteur, et servir de base pour l&rsquo;interaction avec des processus sonores comme la synth&egrave;se ou la spatialisation. Ces outils permettent &eacute;galement le d&eacute;veloppement d&rsquo;une nouvelle g&eacute;n&eacute;ration de suivi de partition. Finalement, il est &agrave; noter que les instruments augment&eacute;s sont utilis&eacute;s dans des cr&eacute;ations musicales mais &eacute;galement dans le cadre d&rsquo;applications p&eacute;dagogiques.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Interaction son musique mouvement</a>, <a href=\"/recherche/equipes-recherche/systemes-et-signaux-sonores-audioacoustique-instruments-s3am/\">S3AM</a>.</p>", "content_en": "<p>Augmented instruments are acoustic instruments that have been fitted with sensors so that information concerning gestural parameters can be transmitted in real-time. These instruments are specifically adapted for mixed acoustic and electronic music. This work is carried out in close collaboration with composers and performers, the goal being the integration of this technology in their works. These developments are also a part of IRCAM&rsquo;s research into instrumental gesture.</p>\r\n<p>This project began with the development of the augmented violin, which then took off due to the interest of various composers. We are now working on all the string quartet instruments as well as certain percussion instruments. Diverse computer techniques have also been developed to analyze, recognize, and follow instrumental gestures. For example, a list of musical elements such as playing styles or musical phrases could be defined by the composer and could be used as a foundation for interaction with sound processes including synthesis or spatialization. These tools make it possible to develop a new generation of score following. Finally, it is important to note that these augmented instruments are used in musical creations, but also in the educational arena.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/interaction-son-musique-mouvement-1/\">Sound Music Movement Interaction</a>, <a href=\"/recherche/equipes-recherche/systemes-et-signaux-sonores-audioacoustique-instruments-s3am/\">S3AM</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [7, 44], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 49, "fields": {"keywords_string": "", "site": 1, "title": "Same", "title_fr": "Same", "title_en": "Same", "slug": "same", "_meta_title": "", "description": "Sound And Music for Everyone Everyday Everywhere Every way", "description_fr": "Sound And Music for Everyone Everyday Everywhere Every way", "description_en": "Sound And Music for Everyone Everyday Everywhere Every way", "gen_description": false, "created": "2016-09-08T15:14:05.072Z", "updated": "2018-06-29T10:16:48.438Z", "status": 2, "publish_date": "2016-09-08T15:14:05Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les pratiques et l&rsquo;&eacute;coute musicales sont des cas particuli&egrave;rement repr&eacute;sentatifs d&rsquo;activit&eacute;s humaines sociales et interactives, deux grands d&eacute;fis actuels des technologies de la communication. Cependant, ces activit&eacute;s sont g&eacute;n&eacute;ralement v&eacute;cues de mani&egrave;re passive, non interactive et ind&eacute;pendante du contexte dans lequel elles s&rsquo;effectuent. Les technologies &eacute;lectroniques actuelles, avec tout le potentiel d&rsquo;interactivit&eacute; et de communication dont elles sont porteuses, n&rsquo;ont pas encore pu &ecirc;tre mises au service de ces aspects essentiels de la musique. Ceci peut &ecirc;tre consid&eacute;r&eacute; comme une d&eacute;gradation des pratiques et de l&rsquo;&eacute;coute musicales, dans lesquelles le public avait (et a encore) la possibilit&eacute; d&rsquo;interagir de nombreuses mani&egrave;res avec les interpr&egrave;tes pour modifier les caract&eacute;ristiques expressives d&rsquo;une &oelig;uvre musicale.</p>\r\n<p>L&rsquo;objectif principal du projet Same a &eacute;t&eacute; de constituer une cha&icirc;ne compl&egrave;te de syst&egrave;mes d&rsquo;&eacute;coute musicale active, sensibles au contexte, dans des situations de mobilit&eacute;. Le projet vise &agrave; r&eacute;pondre &agrave; des questions telles que : quel sera dans cinq ans l&rsquo;appareil &eacute;quivalent de l&rsquo;actuel iPod ?, quels nouveaux march&eacute;s de tels appareils sont-ils susceptibles d&rsquo;ouvrir ? Il a comport&eacute; trois aspects principaux :</p>\r\n<ul>\r\n<li>D&eacute;finir et d&eacute;velopper une plateforme de recherche innovante pour la r&eacute;alisation de bout en bout d&rsquo;applications musicales mobiles, s&rsquo;adressant tant &agrave; des utilisateurs m&eacute;lomanes avertis qu&rsquo;&agrave; des non experts ;</li>\r\n<li>Investiguer et mettre en &oelig;uvre de nouveaux paradigmes de communication et d&rsquo;interaction pour des applications musicales mobiles reposant sur des interfaces multimodales, non verbales de haut niveau, permettant &agrave; l&rsquo;utilisateur d&rsquo;influencer, de moduler, d&rsquo;interagir avec le contenu d&rsquo;&eacute;coute, en s&rsquo;investissant activement et physiquement dans l&rsquo;exp&eacute;rience ;</li>\r\n<li>D&eacute;velopper de nouvelles applications pour les mobiles sensibles au contexte, &agrave; partir du paradigme d&rsquo;&eacute;coute active, qui actualiseront les aspects sociaux et interactifs de la musique &agrave; l&rsquo;&acirc;ge des technologies de l&rsquo;information.</li>\r\n</ul>", "content_fr": "<p>Les pratiques et l&rsquo;&eacute;coute musicales sont des cas particuli&egrave;rement repr&eacute;sentatifs d&rsquo;activit&eacute;s humaines sociales et interactives, deux grands d&eacute;fis actuels des technologies de la communication. Cependant, ces activit&eacute;s sont g&eacute;n&eacute;ralement v&eacute;cues de mani&egrave;re passive, non interactive et ind&eacute;pendante du contexte dans lequel elles s&rsquo;effectuent. Les technologies &eacute;lectroniques actuelles, avec tout le potentiel d&rsquo;interactivit&eacute; et de communication dont elles sont porteuses, n&rsquo;ont pas encore pu &ecirc;tre mises au service de ces aspects essentiels de la musique. Ceci peut &ecirc;tre consid&eacute;r&eacute; comme une d&eacute;gradation des pratiques et de l&rsquo;&eacute;coute musicales, dans lesquelles le public avait (et a encore) la possibilit&eacute; d&rsquo;interagir de nombreuses mani&egrave;res avec les interpr&egrave;tes pour modifier les caract&eacute;ristiques expressives d&rsquo;une &oelig;uvre musicale.</p>\r\n<p>L&rsquo;objectif principal du projet Same a &eacute;t&eacute; de constituer une cha&icirc;ne compl&egrave;te de syst&egrave;mes d&rsquo;&eacute;coute musicale active, sensibles au contexte, dans des situations de mobilit&eacute;. Le projet vise &agrave; r&eacute;pondre &agrave; des questions telles que : quel sera dans cinq ans l&rsquo;appareil &eacute;quivalent de l&rsquo;actuel iPod ?, quels nouveaux march&eacute;s de tels appareils sont-ils susceptibles d&rsquo;ouvrir ? Il a comport&eacute; trois aspects principaux :</p>\r\n<ul>\r\n<li>D&eacute;finir et d&eacute;velopper une plateforme de recherche innovante pour la r&eacute;alisation de bout en bout d&rsquo;applications musicales mobiles, s&rsquo;adressant tant &agrave; des utilisateurs m&eacute;lomanes avertis qu&rsquo;&agrave; des non experts ;</li>\r\n<li>Investiguer et mettre en &oelig;uvre de nouveaux paradigmes de communication et d&rsquo;interaction pour des applications musicales mobiles reposant sur des interfaces multimodales, non verbales de haut niveau, permettant &agrave; l&rsquo;utilisateur d&rsquo;influencer, de moduler, d&rsquo;interagir avec le contenu d&rsquo;&eacute;coute, en s&rsquo;investissant activement et physiquement dans l&rsquo;exp&eacute;rience ;</li>\r\n<li>D&eacute;velopper de nouvelles applications pour les mobiles sensibles au contexte, &agrave; partir du paradigme d&rsquo;&eacute;coute active, qui actualiseront les aspects sociaux et interactifs de la musique &agrave; l&rsquo;&acirc;ge des technologies de l&rsquo;information.</li>\r\n</ul>", "content_en": "<p>Music making and listening are clear examples of a human activity that is above all interactive and social, two of the major issues facing new communication devices and applications. However, to date, music making and listening has been, in general, a passive, non&ndash;interactive, and non-context sensitive experience. The current electronic technologies, with their potential for interactivity and communication, have not yet been able to support and promote this essential aspect of music making and listening. This can be considered a significant degradation of the traditional listening and music making experience, in which the public was (and still is) able to interact in many ways with performers to modify the expressive features of a music piece.</p>\r\n<p>The main objective of the SAME project was to create new end-to-end systems for mobile active, experience-centric, and context-aware active music listening. The project tried to answer to questions like \"What device will correspond to today&rsquo;s iPod in 5 years?\" or \"What potential new markets would such new devices open up?\" The objectives of the SAME project were threefold:</p>\r\n<ul>\r\n<li>To define and develop an innovative end-to-end research platform for novel mobile music applications for participative, experience-centric, context-aware, social/shared active listening of music for a broad target of non-expert as well as expert users.</li>\r\n<li>To investigate and implement new communication and interaction paradigms for mobile music applications based on high- level, expressive, non-verbal multimodal interfaces, enabling the user to influence, interact, and mold and shape the listened content, by intervening actively and physically into the experience.</li>\r\n<li>To develop new mobile context-aware music applications, starting from the active listening paradigm, which will bring back the social and interactive aspects of music to our information technology age.</li>\r\n</ul>", "date_from": "2008-01-01", "date_to": "2010-12-31", "user": null, "type": "external", "external_id": "FP7-ICT", "program": 8, "program_type": 7, "call": null, "lead_team": null, "lead_organization": 606, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2, 7], "organizations": [135, 134, 133, 136, 82], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 50, "fields": {"keywords_string": "", "site": 1, "title": "Suivi de partition et \u00e9criture temps r\u00e9el", "title_fr": "Suivi de partition et \u00e9criture temps r\u00e9el", "title_en": "Score Following and Writing in Real-Time", "slug": "suivi-de-partition-et-ecriture-temps-reel", "_meta_title": "", "description": "Reconnaissance des instants pr\u00e9cis et valeurs musicales dans un flux audio", "description_fr": "Reconnaissance des instants pr\u00e9cis et valeurs musicales dans un flux audio", "description_en": "", "gen_description": false, "created": "2016-09-08T15:18:34.099Z", "updated": "2018-06-29T12:48:13.323Z", "status": 2, "publish_date": "2016-09-08T15:18:34Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le suivi de partition permet de reconna&icirc;tre dans un flux audio provenant des musiciens les instants pr&eacute;cis et valeurs musicales comme tempo associ&eacute; des &eacute;v&eacute;nements not&eacute;s dans la partition instrumentale et d&rsquo;entreprendre des actions &eacute;lectroniques dans l&rsquo;&eacute;crit de la partition synchrone avec des musiciens en temps r&eacute;el. Le but est de reconna&icirc;tre le r&ocirc;le de l&rsquo;ordinateur en tant qu&rsquo;interpr&egrave;te de la musique &eacute;lectronique en interaction avec des musiciens sur sc&egrave;ne.</p>\r\n<p>Dans le contexte de l&rsquo;ex&eacute;cution d&rsquo;&oelig;uvres contemporaines associant parties instrumentales et informatiques, le suivi de partition est une technique souvent employ&eacute;e pour la synchronisation de l&rsquo;accompagnement &eacute;lectronique avec un instrument soliste. La partition est enregistr&eacute;e dans l&rsquo;ordinateur dans un format sp&eacute;cifique contenant &agrave; la fois les &eacute;l&eacute;ments essentiels de la partition instrumentale et une &eacute;criture de la partie informatique avec un langage musical synchrone. Lors de l&rsquo;ex&eacute;cution, l&rsquo;analyse en temps r&eacute;el du son et/ou du geste capt&eacute; aupr&egrave;s de l&rsquo;interpr&egrave;te est mise en comparaison avec la partition enregistr&eacute;e. L&rsquo;algorithme de suivi d&eacute;termine &agrave; chaque instant de l&rsquo;interpr&eacute;tation la position correspondante dans la partition et synchronise les processus programm&eacute;s dans la partie &eacute;lectronique de l&rsquo;&oelig;uvre.</p>\r\n<p>Depuis 1986, l&rsquo;Ircam a d&eacute;velopp&eacute; des techniques de suivi de partition utilis&eacute;es avec diff&eacute;rents instruments parmi lesquels la fl&ucirc;te, le violon, la voix et plus r&eacute;cemment les instruments polyphoniques comme le piano, par des compositeurs tels que Pierre Boulez, Philippe Manoury et Marco Stroppa. De nouveaux objets Max pour le suivi de partition sont maintenant disponibles. La derni&egrave;re version du suiveur de partition int&egrave;gre &eacute;galement un langage synchrone temps r&eacute;el, permettant une &eacute;criture du temps et une interaction pour la partie &eacute;lectronique. L&rsquo;utilisation de cette technologie permet une &eacute;criture coh&eacute;rente entre les parties &eacute;lectroniques et instrumentales au temps de la composition, et une ex&eacute;cution synchrone et polyphonique des modules &eacute;lectroniques avec les musiciens en temps r&eacute;el. Son d&eacute;veloppement est pr&eacute;vu pour une adaptation aux diff&eacute;rentes familles d&rsquo;instruments et &agrave; la reconnaissance de formes musicales, ainsi qu&rsquo;une augmentation des paradigmes d&rsquo;&eacute;criture synchrone pour la partie &eacute;lectronique.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentation musicales</a>.</p>", "content_fr": "<p>Le suivi de partition permet de reconna&icirc;tre dans un flux audio provenant des musiciens les instants pr&eacute;cis et valeurs musicales comme tempo associ&eacute; des &eacute;v&eacute;nements not&eacute;s dans la partition instrumentale et d&rsquo;entreprendre des actions &eacute;lectroniques dans l&rsquo;&eacute;crit de la partition synchrone avec des musiciens en temps r&eacute;el. Le but est de reconna&icirc;tre le r&ocirc;le de l&rsquo;ordinateur en tant qu&rsquo;interpr&egrave;te de la musique &eacute;lectronique en interaction avec des musiciens sur sc&egrave;ne.</p>\r\n<p>Dans le contexte de l&rsquo;ex&eacute;cution d&rsquo;&oelig;uvres contemporaines associant parties instrumentales et informatiques, le suivi de partition est une technique souvent employ&eacute;e pour la synchronisation de l&rsquo;accompagnement &eacute;lectronique avec un instrument soliste. La partition est enregistr&eacute;e dans l&rsquo;ordinateur dans un format sp&eacute;cifique contenant &agrave; la fois les &eacute;l&eacute;ments essentiels de la partition instrumentale et une &eacute;criture de la partie informatique avec un langage musical synchrone. Lors de l&rsquo;ex&eacute;cution, l&rsquo;analyse en temps r&eacute;el du son et/ou du geste capt&eacute; aupr&egrave;s de l&rsquo;interpr&egrave;te est mise en comparaison avec la partition enregistr&eacute;e. L&rsquo;algorithme de suivi d&eacute;termine &agrave; chaque instant de l&rsquo;interpr&eacute;tation la position correspondante dans la partition et synchronise les processus programm&eacute;s dans la partie &eacute;lectronique de l&rsquo;&oelig;uvre.</p>\r\n<p>Depuis 1986, l&rsquo;Ircam a d&eacute;velopp&eacute; des techniques de suivi de partition utilis&eacute;es avec diff&eacute;rents instruments parmi lesquels la fl&ucirc;te, le violon, la voix et plus r&eacute;cemment les instruments polyphoniques comme le piano, par des compositeurs tels que Pierre Boulez, Philippe Manoury et Marco Stroppa. De nouveaux objets Max pour le suivi de partition sont maintenant disponibles. La derni&egrave;re version du suiveur de partition int&egrave;gre &eacute;galement un langage synchrone temps r&eacute;el, permettant une &eacute;criture du temps et une interaction pour la partie &eacute;lectronique. L&rsquo;utilisation de cette technologie permet une &eacute;criture coh&eacute;rente entre les parties &eacute;lectroniques et instrumentales au temps de la composition, et une ex&eacute;cution synchrone et polyphonique des modules &eacute;lectroniques avec les musiciens en temps r&eacute;el. Son d&eacute;veloppement est pr&eacute;vu pour une adaptation aux diff&eacute;rentes familles d&rsquo;instruments et &agrave; la reconnaissance de formes musicales, ainsi qu&rsquo;une augmentation des paradigmes d&rsquo;&eacute;criture synchrone pour la partie &eacute;lectronique.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentation musicales</a>.</p>", "content_en": "<p>Score following makes it possible to distinguish the precise moment and musical values&mdash;such as tempo&mdash;associated with events noted in the instrumental score and carry out electronic actions found in the writing in synchronization with the musicians in real-time within an audio flow produced by musicians. The goal is to recognize the role of the computer as a performer of electronic music who interacts with the musicians on stage.</p>\r\n<p>In the context of performing contemporary works that associate instrumental and computer music, score following is a technique often employed for the synchronization of the electronic accompaniment with an instrumental soloist. The score is recorded in the computer using a specific format that contains both the essential elements of the instrumental score and the writing of the computer element with a synchronous language musical. During the performance, the real-time analysis of the sound and/or gesture captured from the performer is compared with the recorded score. The score following algorithm constantly determines the position in the score of the performance and synchronizes the processes programmed in the electronic part of work.</p>\r\n<p>Score following techniques have been in development since 1986 at IRCAM, where they have been used with different instruments such as the flute, the violin, voice, and more recently polyphonic instruments like piano, by composers such as Pierre Boulez, Philippe Manoury, and Marco Stroppa. New Max objects for score following are now available. The latest incarnation of the score following also integrates a synchronous real-time language, making it possible to ensure the writing of time and interaction for the electronic part. The use of this technology also ensures coherent writing between the electronic and instrumental parts during composition as well as a synchronous and polyphonic execution of the electronic modules with musicians in real-time. Its development will continue to adapt different instrumental families and musical pattern recognition, as well as an improvement in the paradigms of synchronous writing for the electronic part of the score.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 52, "fields": {"keywords_string": "", "site": 1, "title": "Inedit", "title_fr": "Inedit", "title_en": "Inedit", "slug": "inedit", "_meta_title": "", "description": "Interactivit\u00e9 dans l'\u00e9criture de l'interaction et du temps", "description_fr": "Interactivit\u00e9 dans l'\u00e9criture de l'interaction et du temps", "description_en": "Interactivity in Writing of Interaction and Time", "gen_description": false, "created": "2016-09-08T15:32:21.460Z", "updated": "2018-07-25T14:41:51.782Z", "status": 2, "publish_date": "2016-09-08T15:32:21Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;objectif du projet INEDIT est de permettre l&rsquo;interop&eacute;rabilit&eacute; des outils de cr&eacute;ation sonore et musicale, afin d&rsquo;ouvrir la voie &agrave; de nouvelles dimensions cr&eacute;atives couplant &eacute;criture du temps et &eacute;criture de l&rsquo;interaction. Nos motivations refl&egrave;tent les efforts internationaux pour r&eacute;concilier la division actuelle entre les aspects &laquo; <br />compositionnels &raquo; et &laquo; performatifs &raquo; des outils existants de cr&eacute;ation sonores. Cette division est apparente dans la cat&eacute;gorisation des outils en &laquo; composition assist&eacute;e par ordinateur &raquo; et &laquo; temps r&eacute;el &raquo;.</p>\r\n<p>Pour le compositeur, les outils &laquo; orient&eacute;s performance &raquo; (synth&egrave;se et traitements, mixage, post-production audio) se limitent souvent &agrave; des m&eacute;taphores des sources de production et de traitement (notamment oscillateurs, filtres, mod&egrave;les physiques). Cependant, ces m&eacute;taphores doivent s&rsquo;int&eacute;grer dans un langage symbolique comme celui de la partition afin de permettre une r&eacute;elle &eacute;criture musicale et favoriser des modalit&eacute;s plus puissantes de repr&eacute;sentation, de conceptualisation et de communication.</p>\r\n<p>Inversement, les outils &laquo; orient&eacute;s composition &raquo; peinent &agrave; prendre en compte une nouvelle probl&eacute;matique, celle de l&rsquo;interaction : un dispositif sonore correspond de moins en moins &agrave; une &oelig;uvre ferm&eacute;e et sp&eacute;cifi&eacute;e totalement &agrave; l&rsquo;avance, mais doit de plus interagir en temps r&eacute;el avec un environnement. C&rsquo;est le cas par exemple pour les &oelig;uvres musicales interactives, les jeux vid&eacute;o, l&rsquo;habillage sonore, les dispositifs et installations multim&eacute;dia, etc.</p>\r\n<h2>Description des travaux</h2>\r\n<p>Notre approche repose sur une vision langage : une &oelig;uvre interactive est vue comme un interpr&egrave;te (au sens informatique) qui doit articuler des flux temporels bas niveaux localement synchrones (le signal audio) dans un temps &eacute;v&eacute;nementiel globalement asynchrone (les &eacute;v&eacute;nements pertinents pour le processus de composition). Le projet INEDIT promeut aussi une approche hybride permettant la coop&eacute;ration de diff&eacute;rents outils et approches stylistiques au sein d&rsquo;un environnement supportant toutes les phases du workflow musical, de la composition &agrave; la performance. Pour atteindre ces objectifs,&nbsp; il faut d&eacute;velopper de nouvelles technologies : ordonnanceur d&eacute;di&eacute;, m&eacute;canismes de couplage coop&eacute;ratif, compilation au vol, ainsi que les visualisations innovantes et les interfaces tangibles qui permettront de sp&eacute;cifier et de contr&ocirc;ler en temps r&eacute;el les processus musicaux sous-jacents d&rsquo;une mani&egrave;re naturelle pour le cr&eacute;ateur et le concepteur.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2012-CORD-009-01.</p>", "content_fr": "<p>L&rsquo;objectif du projet INEDIT est de permettre l&rsquo;interop&eacute;rabilit&eacute; des outils de cr&eacute;ation sonore et musicale, afin d&rsquo;ouvrir la voie &agrave; de nouvelles dimensions cr&eacute;atives couplant &eacute;criture du temps et &eacute;criture de l&rsquo;interaction. Nos motivations refl&egrave;tent les efforts internationaux pour r&eacute;concilier la division actuelle entre les aspects &laquo; <br />compositionnels &raquo; et &laquo; performatifs &raquo; des outils existants de cr&eacute;ation sonores. Cette division est apparente dans la cat&eacute;gorisation des outils en &laquo; composition assist&eacute;e par ordinateur &raquo; et &laquo; temps r&eacute;el &raquo;.</p>\r\n<p>Pour le compositeur, les outils &laquo; orient&eacute;s performance &raquo; (synth&egrave;se et traitements, mixage, post-production audio) se limitent souvent &agrave; des m&eacute;taphores des sources de production et de traitement (notamment oscillateurs, filtres, mod&egrave;les physiques). Cependant, ces m&eacute;taphores doivent s&rsquo;int&eacute;grer dans un langage symbolique comme celui de la partition afin de permettre une r&eacute;elle &eacute;criture musicale et favoriser des modalit&eacute;s plus puissantes de repr&eacute;sentation, de conceptualisation et de communication.</p>\r\n<p>Inversement, les outils &laquo; orient&eacute;s composition &raquo; peinent &agrave; prendre en compte une nouvelle probl&eacute;matique, celle de l&rsquo;interaction : un dispositif sonore correspond de moins en moins &agrave; une &oelig;uvre ferm&eacute;e et sp&eacute;cifi&eacute;e totalement &agrave; l&rsquo;avance, mais doit de plus interagir en temps r&eacute;el avec un environnement. C&rsquo;est le cas par exemple pour les &oelig;uvres musicales interactives, les jeux vid&eacute;o, l&rsquo;habillage sonore, les dispositifs et installations multim&eacute;dia, etc.</p>\r\n<h2>Description des travaux</h2>\r\n<p>Notre approche repose sur une vision langage : une &oelig;uvre interactive est vue comme un interpr&egrave;te (au sens informatique) qui doit articuler des flux temporels bas niveaux localement synchrones (le signal audio) dans un temps &eacute;v&eacute;nementiel globalement asynchrone (les &eacute;v&eacute;nements pertinents pour le processus de composition). Le projet INEDIT promeut aussi une approche hybride permettant la coop&eacute;ration de diff&eacute;rents outils et approches stylistiques au sein d&rsquo;un environnement supportant toutes les phases du workflow musical, de la composition &agrave; la performance. Pour atteindre ces objectifs,&nbsp; il faut d&eacute;velopper de nouvelles technologies : ordonnanceur d&eacute;di&eacute;, m&eacute;canismes de couplage coop&eacute;ratif, compilation au vol, ainsi que les visualisations innovantes et les interfaces tangibles qui permettront de sp&eacute;cifier et de contr&ocirc;ler en temps r&eacute;el les processus musicaux sous-jacents d&rsquo;une mani&egrave;re naturelle pour le cr&eacute;ateur et le concepteur.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2012-CORD-009-01.</p>", "content_en": "<p>This project aims to enable the interoperability of sonic and musical creation, opening the path to new creative dimensions that couple writing for time and writing for interaction. Our motivations are reflected in the international efforts to bridge the current gap between compositional and performance aspects of existing tools for sonic creation. This gap is apparent in the categorization of tools for computer-assisted composition and real-time.</p>\r\n<p>For a composer, performance-oriented tools (e.g. sound processing and synthesis, mixing, audio post-production) are often limited to the metaphors of production and sound-processing sources (notably oscillators, filters, and physical models). However, these metaphors should be included in a symbolic language like the final score, enabling real musical writing and favoring more powerful methods of representation, conceptualization, and communication.</p>\r\n<p>Inversely, composition-oriented tools still struggle to take into account a new problem, that of interaction: a sound system corresponds more or less to a work that is closed and entirely specified in advance, but must interact in real-time with an environment. This is the case, for example, for interactive musical works, video games, sound decors, or for multimedia systems and installations.</p>\r\n<h2>Project Description</h2>\r\n<p>Our approach is based on a language vision: an interactive work is seen like a performer (in the computer sense) who must articulate locally synchronous low-level temporal streams (the audio signal) in a globally asynchronous event time (pertinent events for the composition process). The INEDIT project promotes a hybrid approach that enables cooperation among different tools and stylistic approaches at the heart of an environment that supports all the phases of the musical workflow, from composition to performance. New technologies must be developed to reach these goals: dedicated scheduler, mechanisms for cooperative coupling, <br />on-the-go compilation, as well as innovative visualizations and tangible interfaces that enable the specification and control in real-time of musical processes in a natural process for the creator and designer.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-2012-CORD-009-01.</p>", "date_from": "2012-09-01", "date_to": "2015-08-31", "user": null, "type": "external", "external_id": "ANR-2012-CORD-009-01", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 1, "website": "http://inedit.ircam.fr", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [138, 139], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 53, "fields": {"keywords_string": "", "site": 1, "title": "Improtech", "title_fr": "Improtech", "title_en": "Improtech", "slug": "improtech", "_meta_title": "", "description": "Technologies et musiques improvise\u0301es", "description_fr": "Technologies et musiques improvise\u0301es", "description_en": "Improvised Technologies and Music", "gen_description": false, "created": "2016-09-08T15:42:04.781Z", "updated": "2018-07-25T14:41:22.968Z", "status": 2, "publish_date": "2016-09-08T15:42:04Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet a pour objectif d&rsquo;&eacute;tudier l&rsquo;impact des nouvelles technologies sur la cr&eacute;ation musicale du point de vue des savoirs mis en jeu.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;avanc&eacute;e scientifique attendue au terme de cette &eacute;tude est une meilleure compr&eacute;hension de l&rsquo;&eacute;volution actuelle des musiques populaires dans le contexte des bouleversements provoqu&eacute;s par la g&eacute;n&eacute;ralisation des technologies num&eacute;riques &agrave; tous les stades de leur production. Comme on l&rsquo;a vu plus haut, les musiques sont toutes li&eacute;es &agrave; des savoirs, mais l&rsquo;accent est mis dans ce projet sur celles qui, au sein des musiques populaires, reposent sur des capacit&eacute;s musicales sp&eacute;cifiques, la capacit&eacute; d&rsquo;improviser et de ce fait mettent en jeu des savoirs complexes. C&rsquo;est le cas du jazz notamment. Il est donc n&eacute;cessaire de s&rsquo;interroger sur la <br />nature de ce type de savoirs musicaux.</p>\r\n<p>Au-del&agrave; de l&rsquo;aspect technique, la musique a un aspect s&eacute;mantique. Cela veut dire que dans une improvisation, le support sonore &laquo; double &raquo; autre chose que lui-m&ecirc;me par le partage d&rsquo;&eacute;l&eacute;ments communs au sein d&rsquo;une communaut&eacute; de personnes qui jouent, &eacute;coutent et font vivre cette musique (m&ecirc;me si le terme de &laquo; <br />communaut&eacute; &raquo; pose plus de difficult&eacute;s que dans une ethnographie classique li&eacute;e &agrave; un territoire donn&eacute;). Au sein de cette communaut&eacute;, les tournures musicales sont partag&eacute;es dans un jeu complexe de reprises et d&rsquo;emprunts.</p>\r\n<p>L&rsquo;un des buts de ce projet est de suivre les voies de ce partage et de montrer comment les cr&eacute;ations individuelles s&rsquo;articulent les unes aux autres en laissant une place possible &agrave; l&rsquo;innovation. Le caract&egrave;re original de ce projet r&eacute;side dans la confrontation de deux types de savoirs exog&egrave;nes, savoirs musicaux d&rsquo;un c&ocirc;t&eacute;, savoirs technoscientifiques de l&rsquo;autre, encore que ce dualisme soit &agrave; nuancer. L&rsquo;id&eacute;e est d&rsquo;observer si une sorte de &laquo; greffe &raquo; s&rsquo;op&egrave;re actuellement dans le monde de la musique improvis&eacute;e du fait de l&rsquo;influence croissante que prennent les outils informatiques.</p>\r\n<p>Le crit&egrave;re de r&eacute;ussite d&rsquo;un tel projet est la vision claire qu&rsquo;il contribuera &agrave; donner de la place actuelle des technologies dans les musiques improvis&eacute;es, qui sont en pleine effervescence cr&eacute;atrice comme on l&rsquo;a dit, mais dont il est difficile aujourd&rsquo;hui de dresser un tableau synth&eacute;tique. Sa mise en &oelig;uvre passe par le choix d&rsquo;un certain nombre de musiciens avec qui travailler, dont la repr&eacute;sentativit&eacute; est une condition de r&eacute;ussite du projet.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-09-SSOC-068.</p>", "content_fr": "<p>Ce projet a pour objectif d&rsquo;&eacute;tudier l&rsquo;impact des nouvelles technologies sur la cr&eacute;ation musicale du point de vue des savoirs mis en jeu.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>L&rsquo;avanc&eacute;e scientifique attendue au terme de cette &eacute;tude est une meilleure compr&eacute;hension de l&rsquo;&eacute;volution actuelle des musiques populaires dans le contexte des bouleversements provoqu&eacute;s par la g&eacute;n&eacute;ralisation des technologies num&eacute;riques &agrave; tous les stades de leur production. Comme on l&rsquo;a vu plus haut, les musiques sont toutes li&eacute;es &agrave; des savoirs, mais l&rsquo;accent est mis dans ce projet sur celles qui, au sein des musiques populaires, reposent sur des capacit&eacute;s musicales sp&eacute;cifiques, la capacit&eacute; d&rsquo;improviser et de ce fait mettent en jeu des savoirs complexes. C&rsquo;est le cas du jazz notamment. Il est donc n&eacute;cessaire de s&rsquo;interroger sur la <br />nature de ce type de savoirs musicaux.</p>\r\n<p>Au-del&agrave; de l&rsquo;aspect technique, la musique a un aspect s&eacute;mantique. Cela veut dire que dans une improvisation, le support sonore &laquo; double &raquo; autre chose que lui-m&ecirc;me par le partage d&rsquo;&eacute;l&eacute;ments communs au sein d&rsquo;une communaut&eacute; de personnes qui jouent, &eacute;coutent et font vivre cette musique (m&ecirc;me si le terme de &laquo; <br />communaut&eacute; &raquo; pose plus de difficult&eacute;s que dans une ethnographie classique li&eacute;e &agrave; un territoire donn&eacute;). Au sein de cette communaut&eacute;, les tournures musicales sont partag&eacute;es dans un jeu complexe de reprises et d&rsquo;emprunts.</p>\r\n<p>L&rsquo;un des buts de ce projet est de suivre les voies de ce partage et de montrer comment les cr&eacute;ations individuelles s&rsquo;articulent les unes aux autres en laissant une place possible &agrave; l&rsquo;innovation. Le caract&egrave;re original de ce projet r&eacute;side dans la confrontation de deux types de savoirs exog&egrave;nes, savoirs musicaux d&rsquo;un c&ocirc;t&eacute;, savoirs technoscientifiques de l&rsquo;autre, encore que ce dualisme soit &agrave; nuancer. L&rsquo;id&eacute;e est d&rsquo;observer si une sorte de &laquo; greffe &raquo; s&rsquo;op&egrave;re actuellement dans le monde de la musique improvis&eacute;e du fait de l&rsquo;influence croissante que prennent les outils informatiques.</p>\r\n<p>Le crit&egrave;re de r&eacute;ussite d&rsquo;un tel projet est la vision claire qu&rsquo;il contribuera &agrave; donner de la place actuelle des technologies dans les musiques improvis&eacute;es, qui sont en pleine effervescence cr&eacute;atrice comme on l&rsquo;a dit, mais dont il est difficile aujourd&rsquo;hui de dresser un tableau synth&eacute;tique. Sa mise en &oelig;uvre passe par le choix d&rsquo;un certain nombre de musiciens avec qui travailler, dont la repr&eacute;sentativit&eacute; est une condition de r&eacute;ussite du projet.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-09-SSOC-068.</p>", "content_en": "<p>This project aims to study the impact of new technologies on musical creation considering the knowledge put to use.</p>\r\n<h2>Project Description &amp; Goals</h2>\r\n<p>The scientific advances expected at the end of this study include a better understanding of the current evolution of the popular music in the context of the disorder caused by the generalization of digital technologies now found in all stages of production. As seen above, all music is related to knowledge, but the emphasis here is laid on that which, within the popular music, relies on specific musical capacities, such as the capacity to improvise, and given this, put in practice complex knowledge. This is the case of jazz, in particular. It is therefore necessary to question the nature of this type of musical knowledge.</p>\r\n<p>Beyond the technical aspect, music has a semantic aspect. This means that during an improvisation, the sound support \"doubles\" as something else via the sharing of common elements at the heart of a community made up of people who play, listen to, and promote this music (even if the word \"community\" creates more problems than in traditional ethnography connected to a given territory). At the heart of this community, musical phrases are shared during a complex game of covers and borrowing. One of the goals of this project is to follow the paths of this sharing and demonstrate how individual creations connect among themselves, leaving space for innovation.</p>\r\n<p>The unique aspect of this project lies in the comparison of two types of exogenic knowledge, musical knowledge on one hand, techno-scientific knowledge on the other, although this dualism must be moderated. The idea is to see if a sort of \"transplant\" works in the world of improvised music because of the increasing influence of digital tools.</p>\r\n<p>The criterion for success for this type of project is the clear vision that it will provide to understand the place of technology in improvised music today. It has been said that this music is full of creative energy, but that it is difficult today to draw up an overall picture of the situation. The implementation of this music is a choice made by a certain number of musicians with whom we work, and their presence is an essential element of the project&rsquo;s success.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-09-SSOC-068.</p>", "date_from": "2010-01-01", "date_to": "2012-12-31", "user": null, "type": "external", "external_id": "ANR-09-SSOC-068", "program": 1, "program_type": 16, "call": 23, "lead_team": null, "lead_organization": 147, "website": "http://ehess.modelisationsavoirs.fr/improtech/", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [140, 142, 143, 141], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 54, "fields": {"keywords_string": "", "site": 1, "title": "React", "title_fr": "React", "title_en": "React", "slug": "react", "_meta_title": "", "description": "Robust Theories for Emerging Applications in Concurrency Theory", "description_fr": "Robust Theories for Emerging Applications in Concurrency Theory", "description_en": "Robust Theories for Emerging Applications in Concurrency Theory", "gen_description": false, "created": "2016-09-08T15:46:24.872Z", "updated": "2018-06-29T10:57:27.504Z", "status": 2, "publish_date": "2016-09-08T15:46:24Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet REACT, financ&eacute; en partie par un programme Colciencias (l&rsquo;&eacute;quivalent du CNRS en Colombie) rassemble deux partenaires fran&ccedil;ais (l&rsquo;Ircam et le laboratoire LIx de l&rsquo;&eacute;cole polytechnique) et plusieurs universit&eacute;s colombiennes. L&rsquo;objectif est d&rsquo;explorer, &agrave; un niveau fondamental et pratique, comment les r&eacute;centes avanc&eacute;es en programmation concurrente par contraintes peuvent s&rsquo;appliquer &agrave; trois domaines : les protocoles de s&eacute;curit&eacute;, les syst&egrave;mes biologiques et la musique (contribution de l&rsquo;Ircam).</p>\r\n<p>Les calculs de processus comme la programmation concurrente par contraintes (ccp) ou le pi-calcul ont &eacute;t&eacute; invent&eacute;s pour d&eacute;crire et raisonner sur les syst&egrave;mes concurrents. Les calculs ccp ont &eacute;t&eacute; utilis&eacute;s &agrave; l&rsquo;Ircam dans la mod&eacute;lisation de diff&eacute;rents processus musicaux tels que l&rsquo;interaction, le calcul massif de contraintes musicales, l&rsquo;improvisation. Dans toutes ces applications, les calculs de processus sont utilis&eacute;s pour au moins deux raisons. D&rsquo;abord, de par leur d&eacute;finition math&eacute;matique rigoureuse, ces calculs peuvent fournir une s&eacute;mantique formelle de haut niveau aux applications ainsi sp&eacute;cifi&eacute;es. En outre, on peut raisonner sur le comportement ou les propri&eacute;t&eacute;s des processus. En musique, cela signifie par exemple qu&rsquo;un syst&egrave;me tr&egrave;s lourd de r&egrave;gles musicales (contraintes) pourrait &ecirc;tre formellement valid&eacute; pour d&eacute;terminer s&rsquo;il mod&eacute;lise bien le probl&egrave;me avant de lancer un calcul co&ucirc;teux.</p>\r\n<p>Malgr&eacute; la grande diversit&eacute; des applications, on remarque une surprenante similarit&eacute; dans la nature des analyses qu&rsquo;on cherche &agrave; faire dans chaque cas. Par exemple, dans le domaine de la s&eacute;curit&eacute;, on a souvent besoin d&rsquo;une &eacute;tude des configurations atteignables : s&rsquo;il est possible d&rsquo;atteindre un &eacute;tat o&ugrave; l&rsquo;attaquant conna&icirc;t un secret, alors le protocole ne fonctionne pas correctement.</p>\r\n<p>En mod&eacute;lisation musicale, on s&rsquo;int&eacute;resse &agrave; des questions similaires, par exemple : &laquo; Est-ce que le processus musical atteint un &eacute;tat o&ugrave; les voix forment un canon tout en gardant un champ harmonique donn&eacute; ? &raquo;</p>", "content_fr": "<p>Le projet REACT, financ&eacute; en partie par un programme Colciencias (l&rsquo;&eacute;quivalent du CNRS en Colombie) rassemble deux partenaires fran&ccedil;ais (l&rsquo;Ircam et le laboratoire LIx de l&rsquo;&eacute;cole polytechnique) et plusieurs universit&eacute;s colombiennes. L&rsquo;objectif est d&rsquo;explorer, &agrave; un niveau fondamental et pratique, comment les r&eacute;centes avanc&eacute;es en programmation concurrente par contraintes peuvent s&rsquo;appliquer &agrave; trois domaines : les protocoles de s&eacute;curit&eacute;, les syst&egrave;mes biologiques et la musique (contribution de l&rsquo;Ircam).</p>\r\n<p>Les calculs de processus comme la programmation concurrente par contraintes (ccp) ou le pi-calcul ont &eacute;t&eacute; invent&eacute;s pour d&eacute;crire et raisonner sur les syst&egrave;mes concurrents. Les calculs ccp ont &eacute;t&eacute; utilis&eacute;s &agrave; l&rsquo;Ircam dans la mod&eacute;lisation de diff&eacute;rents processus musicaux tels que l&rsquo;interaction, le calcul massif de contraintes musicales, l&rsquo;improvisation. Dans toutes ces applications, les calculs de processus sont utilis&eacute;s pour au moins deux raisons. D&rsquo;abord, de par leur d&eacute;finition math&eacute;matique rigoureuse, ces calculs peuvent fournir une s&eacute;mantique formelle de haut niveau aux applications ainsi sp&eacute;cifi&eacute;es. En outre, on peut raisonner sur le comportement ou les propri&eacute;t&eacute;s des processus. En musique, cela signifie par exemple qu&rsquo;un syst&egrave;me tr&egrave;s lourd de r&egrave;gles musicales (contraintes) pourrait &ecirc;tre formellement valid&eacute; pour d&eacute;terminer s&rsquo;il mod&eacute;lise bien le probl&egrave;me avant de lancer un calcul co&ucirc;teux.</p>\r\n<p>Malgr&eacute; la grande diversit&eacute; des applications, on remarque une surprenante similarit&eacute; dans la nature des analyses qu&rsquo;on cherche &agrave; faire dans chaque cas. Par exemple, dans le domaine de la s&eacute;curit&eacute;, on a souvent besoin d&rsquo;une &eacute;tude des configurations atteignables : s&rsquo;il est possible d&rsquo;atteindre un &eacute;tat o&ugrave; l&rsquo;attaquant conna&icirc;t un secret, alors le protocole ne fonctionne pas correctement.</p>\r\n<p>En mod&eacute;lisation musicale, on s&rsquo;int&eacute;resse &agrave; des questions similaires, par exemple : &laquo; Est-ce que le processus musical atteint un &eacute;tat o&ugrave; les voix forment un canon tout en gardant un champ harmonique donn&eacute; ? &raquo;</p>", "content_en": "<p>The React Project, funded in part by the Colciencias (The Colombian Agency for Science and Technology Development), brings together two French partners&mdash;IRCAM and the LIx laboratory at the &Eacute;cole Polytechnique&mdash;and several Columbian universities. The objective is to explore, at a basic and practical level, how recent developments in concurrent constraint programming (CCP) can be applied to three areas: security protocols, biological systems, and multimedia semantic interaction (IRCAM&rsquo;s contribution).</p>\r\n<p>Process calculi such as concurrent constraint programming or the pi-calculus were originally designed to describe and reason about concurrent systems. Concurrent constraint programming has been used at IRCAM in modeling different musical processes, such as interaction, the massive calculations for musical constraints, or improvisation. In all these applications, process calculi are used for at least two reasons. Firstly, since these calculi have careful, mathematical definitions, they can be used to provide careful and high-level meaning to the applications specified using them. Secondly, it can be argued that these calculi have <br />developed rich reasoning methods to reason about meaning and properties of processes. For music, this signifies that a complicated system with musical rules (constraints) could be formally valid in order to determine if it properly models the problem before beginning a calculus.</p>\r\n<p>Despite the broad range of applications, there is a surprising resemblance among them in the kind of analyses that are carried out in each domain.</p>\r\n<p>For example, in the field of security, it is often necessary to study possible situations: if it is possible for an attacker knows a secret, then the protocol does not work correctly. In musical modeling, we are interested in similar questions such as, \"Has the musical process reached a state where the voices form a cannon while preserving the given harmony?\".</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [144, 146, 145], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 55, "fields": {"keywords_string": "", "site": 1, "title": "Interactions musicales improvis\u00e9es - OMax & co", "title_fr": "Interactions musicales improvis\u00e9es - OMax & co", "title_en": "Improvised Musical Interactions - OMax & Co", "slug": "omax", "_meta_title": "", "description": "D\u00e9veloppement de situations d\u2019interactions musicales improvis\u00e9es humains/ordinateur", "description_fr": "D\u00e9veloppement de situations d\u2019interactions musicales improvis\u00e9es humains/ordinateur", "description_en": "Development of improvised man-machine musical interactions", "gen_description": false, "created": "2016-09-08T16:07:57.742Z", "updated": "2018-06-29T09:48:42.866Z", "status": 2, "publish_date": "2016-09-08T16:07:57Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet concerne le d&eacute;veloppement de situations d&rsquo;interactions musicales improvis&eacute;es humains/ordinateur. Un nouveau paradigme d&rsquo;interaction a &eacute;t&eacute; invent&eacute; par l&rsquo;&eacute;quipe et s&rsquo;est largement diffus&eacute;, port&eacute; par le logiciel OMax.</p>\r\n<p>Utilisant des techniques issues de l&rsquo;apprentissage automatique (Machine Learning) et des langages formels, OMax apprend ses connaissances de mani&egrave;re non supervis&eacute;e &agrave; partir d&rsquo;un flux MIDI ou audio, produit par le musicien. Le processus sous-jacent &agrave; cette interaction peut &ecirc;tre nomm&eacute; &laquo; r&eacute;injection stylistique &raquo;. Le musicien est inform&eacute; en continu par plusieurs sources formant un feed-back complexe. Il s&rsquo;&eacute;coute jouer, il &eacute;coute les autres dans le pr&eacute;sent, tout en m&eacute;morisant des images sonores qui d&eacute;rivent ainsi du pr&eacute;sent vers le pass&eacute;. De la m&eacute;moire &agrave; moyen et &agrave; long terme, ces motifs, combin&eacute;s &agrave; des images encore plus anciennes (r&eacute;pertoire, culture musicale), peuvent revenir au pr&eacute;sent en ayant subi plusieurs transformations, dont une des plus communes en improvisation est la recombinaison formelle. OMax mod&eacute;lise ce processus m&eacute;moriel lui-m&ecirc;me et permet de le &laquo; r&eacute;ifier &raquo; donc de le donner &agrave; entendre sur sc&egrave;ne. Il r&eacute;injecte alors des figures musicales issues de la m&eacute;moire &agrave; court et long terme sous forme de reconstruction &agrave; la fois semblable et innovante, il fournit ainsi au musicien des stimuli &agrave; la fois familiers et provocants.</p>\r\n<p>Ce projet a donn&eacute; lieu &agrave; deux nouvelles recherches, SoMax qui explore la r&eacute;activit&eacute; imm&eacute;diate de l&rsquo;agent artificiel &agrave; son environnement sonore, et Improtek (avec l&rsquo;EHESS) qui explore la notion d&rsquo;improvisation guid&eacute;e dans le cadre d&rsquo;un sc&eacute;nario convenu (e.g. grille harmonique). Le projet ANR DyCI2 a pour vocation d&rsquo;&eacute;tudier la synth&egrave;se de ces approches avec des techniques innovantes d&rsquo;&eacute;coute artificielle.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>Ce projet concerne le d&eacute;veloppement de situations d&rsquo;interactions musicales improvis&eacute;es humains/ordinateur. Un nouveau paradigme d&rsquo;interaction a &eacute;t&eacute; invent&eacute; par l&rsquo;&eacute;quipe et s&rsquo;est largement diffus&eacute;, port&eacute; par le logiciel OMax.</p>\r\n<p>Utilisant des techniques issues de l&rsquo;apprentissage automatique (Machine Learning) et des langages formels, OMax apprend ses connaissances de mani&egrave;re non supervis&eacute;e &agrave; partir d&rsquo;un flux MIDI ou audio, produit par le musicien. Le processus sous-jacent &agrave; cette interaction peut &ecirc;tre nomm&eacute; &laquo; r&eacute;injection stylistique &raquo;. Le musicien est inform&eacute; en continu par plusieurs sources formant un feed-back complexe. Il s&rsquo;&eacute;coute jouer, il &eacute;coute les autres dans le pr&eacute;sent, tout en m&eacute;morisant des images sonores qui d&eacute;rivent ainsi du pr&eacute;sent vers le pass&eacute;. De la m&eacute;moire &agrave; moyen et &agrave; long terme, ces motifs, combin&eacute;s &agrave; des images encore plus anciennes (r&eacute;pertoire, culture musicale), peuvent revenir au pr&eacute;sent en ayant subi plusieurs transformations, dont une des plus communes en improvisation est la recombinaison formelle. OMax mod&eacute;lise ce processus m&eacute;moriel lui-m&ecirc;me et permet de le &laquo; r&eacute;ifier &raquo; donc de le donner &agrave; entendre sur sc&egrave;ne. Il r&eacute;injecte alors des figures musicales issues de la m&eacute;moire &agrave; court et long terme sous forme de reconstruction &agrave; la fois semblable et innovante, il fournit ainsi au musicien des stimuli &agrave; la fois familiers et provocants.</p>\r\n<p>Ce projet a donn&eacute; lieu &agrave; deux nouvelles recherches, SoMax qui explore la r&eacute;activit&eacute; imm&eacute;diate de l&rsquo;agent artificiel &agrave; son environnement sonore, et Improtek (avec l&rsquo;EHESS) qui explore la notion d&rsquo;improvisation guid&eacute;e dans le cadre d&rsquo;un sc&eacute;nario convenu (e.g. grille harmonique). Le projet ANR DyCI2 a pour vocation d&rsquo;&eacute;tudier la synth&egrave;se de ces approches avec des techniques innovantes d&rsquo;&eacute;coute artificielle.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>This project focuses on the development of improvised man-machine musical interactions. A new paradigm for interaction was invented at IRCAM and has been made available to the general public via the OMax software program.</p>\r\n<p>Using machine learning techniques and formal languages, OMax learns in an unsupervised way from either a MIDI or an audio stream produced by a musician. The underlying process behind this interaction could be called \"stylistic reinjection\". The musician is continually kept informed by several sources providing complex feedback. He hears himself play, he listens to others while memorizing sound images that flow from the present towards the past. Using medium-term and long-term memory, these motifs, combined with even older images taken from the repertoire or musical culture, for example, can return to the present after undergoing several transformations, including one of the most common transformations in improvisation: formal recombination. OMax models this memory-based process and makes it possible to \"reify\" it, to make it heard on stage. It then re-injects musical figures taken from its short-term and long-term memory and reconstructs them in a manner that is both similar and innovative, providing the musician with stimuli that are familiar and stimulating.</p>\r\n<p>This project has led to two new research projects: SoMax that explores the immediate reactivity of an artificial agent to its sound environment and Improtek (in collaboration with the EHESS) that explores the notion of guided improvisation in the framework of a specific scenario (e.g. a chord chart). The vocation of the ANR-funded project DyCI2 is to study the synthesis of these two different approaches with innovative artificial listening techniques.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 57, "fields": {"keywords_string": "", "site": 1, "title": "Sample Orchestrator", "title_fr": "Sample Orchestrator", "title_en": "Sample Orchestrator", "slug": "sample-orchestrator", "_meta_title": "", "description": "R\u00e9alisation d'applications sur la gestion et la manipulation par le contenu de banques d\u2019\u00e9chantillons sonores", "description_fr": "R\u00e9alisation d'applications sur la gestion et la manipulation par le contenu de banques d\u2019\u00e9chantillons sonores", "description_en": "Produce new applications based on content management and manipulation of sample banks", "gen_description": false, "created": "2016-09-09T08:10:42.002Z", "updated": "2018-06-29T09:56:49.585Z", "status": 2, "publish_date": "2016-09-09T08:10:41Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Sample Orchestrator a &eacute;t&eacute; con&ccedil;u pour la r&eacute;alisation et l&rsquo;exp&eacute;rimentation de nouvelles applications reposant sur la gestion et la manipulation par le contenu de banques d&rsquo;&eacute;chantillons sonores (sons isol&eacute;s pr&eacute;enregistr&eacute;s).</p>\r\n<p>Sa r&eacute;alisation s&rsquo;est inscrite &agrave; la conjonction de deux processus : d&rsquo;une part, la disponibilit&eacute; commerciale de grandes banques d&rsquo;&eacute;chantillons diffus&eacute;es sur diff&eacute;rents supports (CD et DvD, bases en ligne), mais limit&eacute;es dans leurs applications (synth&eacute;tiseurs par &eacute;chantillonnage) ; d&rsquo;autre part, des avanc&eacute;es scientifiques et technologiques r&eacute;centes en mati&egrave;re de m&eacute;thodes d&rsquo;indexation et de syst&egrave;mes de gestion de bases de donn&eacute;es audio, permettant d&rsquo;envisager des fonctions musicales encore in&eacute;dites, faisant appel &agrave; des modes de gestion globale et de manipulation par le contenu de l&rsquo;ensemble des &eacute;chantillons disponibles :</p>\r\n<ul>\r\n<li>Gestion par le contenu de banques d&rsquo;&eacute;chantillons : classification automatique, recherche par similarit&eacute;, synth&egrave;se concat&eacute;native sur la base de descriptions de haut niveau ;</li>\r\n<li>Traitement audio par le contenu (se fondant sur une analyse pr&eacute;alable des caract&eacute;ristiques des signaux trait&eacute;s) : transposition, dilatation, hybridation, etc. Ces fonctions de traitement se d&eacute;composent en fonctions de pr&eacute;-traitement, visant la pr&eacute;paration d&rsquo;&eacute;chantillons en studio, et celles de post-traitement, intervenant en temps r&eacute;el lors de l&rsquo;utilisation de banques de sons par un dispositif instrumental d&rsquo;&eacute;chantillonneur de nouvelle g&eacute;n&eacute;ration ;</li>\r\n<li>Outil d&rsquo;aide &agrave; l&rsquo;orchestration, int&eacute;gr&eacute; &agrave; l&rsquo;environnement OpenMusic, trouvant, sur la base de la mod&eacute;lisation de connaissances musicales, g&eacute;n&eacute;ralement empiriques de la part de compositeurs, les meilleures combinaisons de sons en vue de l&rsquo;obtention de l&rsquo;effet musical recherch&eacute; (fusion/s&eacute;paration, r&eacute;orchestration &agrave; partir de sons existants, etc.).</li>\r\n</ul>\r\n<p>L&rsquo;organisation du projet a int&eacute;gr&eacute; la coordination d&rsquo;activit&eacute;s de recherche de plusieurs &eacute;quipes de l&rsquo;Ircam autour des principaux verrous scientifiques et technologiques identifi&eacute;s : description, indexation et classification automatique des contenus sonores et musicaux, traitement sonore par le contenu, ing&eacute;nierie des connaissances musicales et leur application &agrave; l&rsquo;orchestration, environnements logiciels pour le traitement audio temps r&eacute;el. Le projet a fait l&rsquo;objet d&rsquo;une importante production scientifique (2 th&egrave;ses de doctorat, 10 articles dans des revues et livres, 18 conf&eacute;rences), d&rsquo;une valorisation industrielle (les technologies d&eacute;velopp&eacute;es dans le projet ont permis la r&eacute;alisation du logiciel MachFive 3 d&rsquo;Univers Sons commercialis&eacute; par la soci&eacute;t&eacute; am&eacute;ricaine Mark of the Unicorn) et de nombreuses cr&eacute;ations musicales &agrave; l&rsquo;Ircam.</p>\r\n<p>Le projet a &eacute;t&eacute; s&eacute;lectionn&eacute; au titre &laquo; d&rsquo;avanc&eacute;e scientifique majeure &raquo; par l&rsquo;ANR dans son rapport d&rsquo;activit&eacute; 2006.</p>", "content_fr": "<p>Le projet Sample Orchestrator a &eacute;t&eacute; con&ccedil;u pour la r&eacute;alisation et l&rsquo;exp&eacute;rimentation de nouvelles applications reposant sur la gestion et la manipulation par le contenu de banques d&rsquo;&eacute;chantillons sonores (sons isol&eacute;s pr&eacute;enregistr&eacute;s).</p>\r\n<p>Sa r&eacute;alisation s&rsquo;est inscrite &agrave; la conjonction de deux processus : d&rsquo;une part, la disponibilit&eacute; commerciale de grandes banques d&rsquo;&eacute;chantillons diffus&eacute;es sur diff&eacute;rents supports (CD et DvD, bases en ligne), mais limit&eacute;es dans leurs applications (synth&eacute;tiseurs par &eacute;chantillonnage) ; d&rsquo;autre part, des avanc&eacute;es scientifiques et technologiques r&eacute;centes en mati&egrave;re de m&eacute;thodes d&rsquo;indexation et de syst&egrave;mes de gestion de bases de donn&eacute;es audio, permettant d&rsquo;envisager des fonctions musicales encore in&eacute;dites, faisant appel &agrave; des modes de gestion globale et de manipulation par le contenu de l&rsquo;ensemble des &eacute;chantillons disponibles :</p>\r\n<ul>\r\n<li>Gestion par le contenu de banques d&rsquo;&eacute;chantillons : classification automatique, recherche par similarit&eacute;, synth&egrave;se concat&eacute;native sur la base de descriptions de haut niveau ;</li>\r\n<li>Traitement audio par le contenu (se fondant sur une analyse pr&eacute;alable des caract&eacute;ristiques des signaux trait&eacute;s) : transposition, dilatation, hybridation, etc. Ces fonctions de traitement se d&eacute;composent en fonctions de pr&eacute;-traitement, visant la pr&eacute;paration d&rsquo;&eacute;chantillons en studio, et celles de post-traitement, intervenant en temps r&eacute;el lors de l&rsquo;utilisation de banques de sons par un dispositif instrumental d&rsquo;&eacute;chantillonneur de nouvelle g&eacute;n&eacute;ration ;</li>\r\n<li>Outil d&rsquo;aide &agrave; l&rsquo;orchestration, int&eacute;gr&eacute; &agrave; l&rsquo;environnement OpenMusic, trouvant, sur la base de la mod&eacute;lisation de connaissances musicales, g&eacute;n&eacute;ralement empiriques de la part de compositeurs, les meilleures combinaisons de sons en vue de l&rsquo;obtention de l&rsquo;effet musical recherch&eacute; (fusion/s&eacute;paration, r&eacute;orchestration &agrave; partir de sons existants, etc.).</li>\r\n</ul>\r\n<p>L&rsquo;organisation du projet a int&eacute;gr&eacute; la coordination d&rsquo;activit&eacute;s de recherche de plusieurs &eacute;quipes de l&rsquo;Ircam autour des principaux verrous scientifiques et technologiques identifi&eacute;s : description, indexation et classification automatique des contenus sonores et musicaux, traitement sonore par le contenu, ing&eacute;nierie des connaissances musicales et leur application &agrave; l&rsquo;orchestration, environnements logiciels pour le traitement audio temps r&eacute;el. Le projet a fait l&rsquo;objet d&rsquo;une importante production scientifique (2 th&egrave;ses de doctorat, 10 articles dans des revues et livres, 18 conf&eacute;rences), d&rsquo;une valorisation industrielle (les technologies d&eacute;velopp&eacute;es dans le projet ont permis la r&eacute;alisation du logiciel MachFive 3 d&rsquo;Univers Sons commercialis&eacute; par la soci&eacute;t&eacute; am&eacute;ricaine Mark of the Unicorn) et de nombreuses cr&eacute;ations musicales &agrave; l&rsquo;Ircam.</p>\r\n<p>Le projet a &eacute;t&eacute; s&eacute;lectionn&eacute; au titre &laquo; d&rsquo;avanc&eacute;e scientifique majeure &raquo; par l&rsquo;ANR dans son rapport d&rsquo;activit&eacute; 2006.</p>", "content_en": "<p>The Sample Orchestrator project aimed to produce new applications based on content management and manipulation of sample (isolated pre-recorded sounds) banks.</p>\r\n<p>Its production corresponds to the conjunction of two elements: the widespread availability of large sample banks on different supports (e.g. CD and DvD, online databases) but that present a limited number of applications (e.g. synthesizer samples) and recent scientific and technologic developments in indexation methods and management systems for audio databases, making it possible to imagine new musical functions, calling on global methods of content management and manipulation of the entire corpus of available samples.</p>\r\n<ul>\r\n<li>Content management of the sample bank: automatic classification, search by resemblance, concatenative synthesis based on high-level descriptions</li>\r\n<li>Audio processing by contents (based on a previous analysis of characteristics of the processed signals): transposition, dilation, hybridization, etc. These processing functions can be divided in pre-processing functions that address the preparation of samples in the studio, and post-processing functions that intervene in real-time when the sound banks are used via a new generation instrumental sampler.</li>\r\n<li>Orchestration tool, integrated in the OpenMusic environment, which finds, based on models of musical knowledge (generally empirical for composers), the best combinations of sounds with a specific musical effect in mind (fusion/separation, reorchestration from existing sounds, etc.)</li>\r\n</ul>\r\n<p>Research activities on the identified major scientific and technological issues were planned as a part of the project: description, indexation, automatic classification of musical and sound contents, sound processing by content, engineering musical knowledge and its application for orchestration, software environments for audio processing in real-time. This project was the subject of numerous scientific publications (2 doctoral theses, 10 articles in journals and books, 18 conferences), of an industrial valorization (the technologies developed in the project led to the creation of the MachFive 3 software program by Univers Sons, marketed by the American company Mark of the Unicorn), and several musical creations at IRCAM.</p>\r\n<p>The project was selected for the label \"major scientific advance\" by the ANR in its 2006 report.</p>", "date_from": "2006-12-01", "date_to": "2009-06-30", "user": null, "type": "external", "external_id": "ANR-06-RIAM-27", "program": 1, "program_type": 18, "call": null, "lead_team": null, "lead_organization": 1, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 7, 3, 5], "organizations": [16], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 58, "fields": {"keywords_string": "", "site": 1, "title": "Ecrins", "title_fr": "Ecrins", "title_en": "Ecrins", "slug": "ecrins", "_meta_title": "", "description": "Environnement de classification et de recherche intelligente de sons", "description_fr": "Environnement de classification et de recherche intelligente de sons", "description_en": "Classification and Smart Search Environments for Sounds", "gen_description": false, "created": "2016-09-09T08:14:44.818Z", "updated": "2018-06-29T11:21:19.132Z", "status": 1, "publish_date": "2016-09-09T08:14:44Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Ecrins a eu pour ambition de construire, &agrave; l&rsquo;attention des professionnels de la musique et du son, un syst&egrave;me de gestion d&rsquo;&eacute;chantillons sonores disponible en ligne ou en intranet, dot&eacute; de fonctions de classification et d&rsquo;acc&egrave;s &laquo; intelligentes &raquo;.</p>", "content_fr": "<p>Le projet Ecrins a eu pour ambition de construire, &agrave; l&rsquo;attention des professionnels de la musique et du son, un syst&egrave;me de gestion d&rsquo;&eacute;chantillons sonores disponible en ligne ou en intranet, dot&eacute; de fonctions de classification et d&rsquo;acc&egrave;s &laquo; intelligentes &raquo;.</p>", "content_en": "<p>The goal of the ECRINS project was to construct a sound sample database&mdash;available online or via the intranet&mdash;for music and sound professionals, complete with \"smart\" classification and access functions, based on perceptual or cognitive criteria proposed by the system.</p>", "date_from": "2000-11-01", "date_to": "2002-05-31", "user": null, "type": "external", "external_id": "", "program": null, "program_type": 19, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 3], "organizations": [150, 50], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 59, "fields": {"keywords_string": "", "site": 1, "title": "Aide \u00e0 l'orchestration", "title_fr": "Aide \u00e0 l'orchestration", "title_en": "Orchestration Assistance", "slug": "aide-a-lorchestration", "_meta_title": "", "description": "Outil d\u2019aide \u00e0 l\u2019orchestration int\u00e9gr\u00e9 aux logiciels de composition de l\u2019Ircam", "description_fr": "Outil d\u2019aide \u00e0 l\u2019orchestration int\u00e9gr\u00e9 aux logiciels de composition de l\u2019Ircam", "description_en": "Tool to assist orchestration that is integrated in the software created at IRCAM", "gen_description": false, "created": "2016-09-09T08:20:33.163Z", "updated": "2017-02-10T16:28:30.255Z", "status": 1, "publish_date": "2016-09-09T08:20:33Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Orchestration est partie int&eacute;grante du projet Sample Orchestrator.</p>\r\n<p>Il a pour ambition de fournir aux compositeurs un outil d&rsquo;aide &agrave; l&rsquo;orchestration int&eacute;gr&eacute; aux environnements logiciels de composition de l&rsquo;Ircam tels que OpenMusic. En mettant &agrave; profit les connaissances acquises gr&acirc;ce &agrave; l&rsquo;analyse de larges bases de donn&eacute;es de sons instrumentaux &ndash; rendant compte de l&rsquo;&eacute;tendue des possibilit&eacute;s des instruments de musique &ndash; et les avanc&eacute;es dans la compr&eacute;hension du timbre, nous souhaitons aider les compositeurs &agrave; explorer l&rsquo;espace des possibilit&eacute;s sonores offertes par un orchestre. Le probl&egrave;me consiste &agrave; trouver les combinaisons de sons instrumentaux qui s&rsquo;approchent le plus, selon des crit&egrave;res de similarit&eacute; d&eacute;finissables par l&rsquo;utilisateur, d&rsquo;une cible sp&eacute;cifi&eacute;e soit &agrave; partir d&rsquo;un son enregistr&eacute;, soit de mani&egrave;re plus abstraite (superposition de hauteurs par exemple).</p>\r\n<p>Les principaux verrous scientifiques r&eacute;sident, du point de vue de l&rsquo;analyse du signal, dans le choix d&rsquo;un ensemble de &laquo; caract&eacute;ristiques &raquo; calculables &agrave; partir d&rsquo;&eacute;chantillons de sons d&rsquo;instruments, pertinentes quant &agrave; la description du timbre, et permettant de pr&eacute;dire, sans avoir &agrave; l&rsquo;&eacute;couter ni &agrave; l&rsquo;analyser, le timbre d&rsquo;une superposition de sons. L&rsquo;approche retenue consiste &agrave; agr&eacute;ger la connaissance tir&eacute;e de l&rsquo;analyse de larges bases de donn&eacute;es sonores en un jeu de &laquo; mod&egrave;les d&rsquo;instruments &raquo;, permettant d&rsquo;&eacute;valuer la probabilit&eacute; qu&rsquo;un son donn&eacute; soit jou&eacute; par un instrument ou un groupe d&rsquo;instruments.</p>\r\n<p>Pour le moment limit&eacute;e &agrave; des sons statiques harmoniques et aux variations temporelles p&eacute;riodiques (telles un tremolo ou un vibrato), l&rsquo;application sera amen&eacute;e &agrave; s&rsquo;&eacute;toffer dans les ann&eacute;es &agrave; venir pour &ecirc;tre capable, &agrave; terme, de travailler avec tout type de sons.</p>\r\n<p>Un autre verrou concerne une gestion de la combinatoire adapt&eacute;e aux donn&eacute;es manipul&eacute;es, la complexit&eacute; du probl&egrave;me interdisant d&rsquo;&eacute;valuer toutes les solutions possibles. La m&eacute;thode actuellement explor&eacute;e permet de proposer au compositeur, en un temps raisonnable, un ensemble de solutions approch&eacute;es sur la base desquelles, via un environnement interactif, certaines zones de l&rsquo;espace de recherche pourront &ecirc;tre favoris&eacute;es au d&eacute;triment d&rsquo;autres, moins susceptibles de conduire &agrave; des solutions int&eacute;ressantes.</p>\r\n<p>La recherche d&rsquo;une orchestration se pr&eacute;sente alors comme un processus it&eacute;ratif au cours duquel &eacute;mergent conjointement solutions pertinentes et pr&eacute;f&eacute;rences de l&rsquo;utilisateur. Techniquement parlant, les solutions int&eacute;ressantes sont proches du front de Pareto d&rsquo;un probl&egrave;me d&rsquo;optimisation (sac &agrave; dos) multicrit&egrave;res.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>, <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_fr": "<p>Le projet Orchestration est partie int&eacute;grante du projet Sample Orchestrator.</p>\r\n<p>Il a pour ambition de fournir aux compositeurs un outil d&rsquo;aide &agrave; l&rsquo;orchestration int&eacute;gr&eacute; aux environnements logiciels de composition de l&rsquo;Ircam tels que OpenMusic. En mettant &agrave; profit les connaissances acquises gr&acirc;ce &agrave; l&rsquo;analyse de larges bases de donn&eacute;es de sons instrumentaux &ndash; rendant compte de l&rsquo;&eacute;tendue des possibilit&eacute;s des instruments de musique &ndash; et les avanc&eacute;es dans la compr&eacute;hension du timbre, nous souhaitons aider les compositeurs &agrave; explorer l&rsquo;espace des possibilit&eacute;s sonores offertes par un orchestre. Le probl&egrave;me consiste &agrave; trouver les combinaisons de sons instrumentaux qui s&rsquo;approchent le plus, selon des crit&egrave;res de similarit&eacute; d&eacute;finissables par l&rsquo;utilisateur, d&rsquo;une cible sp&eacute;cifi&eacute;e soit &agrave; partir d&rsquo;un son enregistr&eacute;, soit de mani&egrave;re plus abstraite (superposition de hauteurs par exemple).</p>\r\n<p>Les principaux verrous scientifiques r&eacute;sident, du point de vue de l&rsquo;analyse du signal, dans le choix d&rsquo;un ensemble de &laquo; caract&eacute;ristiques &raquo; calculables &agrave; partir d&rsquo;&eacute;chantillons de sons d&rsquo;instruments, pertinentes quant &agrave; la description du timbre, et permettant de pr&eacute;dire, sans avoir &agrave; l&rsquo;&eacute;couter ni &agrave; l&rsquo;analyser, le timbre d&rsquo;une superposition de sons. L&rsquo;approche retenue consiste &agrave; agr&eacute;ger la connaissance tir&eacute;e de l&rsquo;analyse de larges bases de donn&eacute;es sonores en un jeu de &laquo; mod&egrave;les d&rsquo;instruments &raquo;, permettant d&rsquo;&eacute;valuer la probabilit&eacute; qu&rsquo;un son donn&eacute; soit jou&eacute; par un instrument ou un groupe d&rsquo;instruments.</p>\r\n<p>Pour le moment limit&eacute;e &agrave; des sons statiques harmoniques et aux variations temporelles p&eacute;riodiques (telles un tremolo ou un vibrato), l&rsquo;application sera amen&eacute;e &agrave; s&rsquo;&eacute;toffer dans les ann&eacute;es &agrave; venir pour &ecirc;tre capable, &agrave; terme, de travailler avec tout type de sons.</p>\r\n<p>Un autre verrou concerne une gestion de la combinatoire adapt&eacute;e aux donn&eacute;es manipul&eacute;es, la complexit&eacute; du probl&egrave;me interdisant d&rsquo;&eacute;valuer toutes les solutions possibles. La m&eacute;thode actuellement explor&eacute;e permet de proposer au compositeur, en un temps raisonnable, un ensemble de solutions approch&eacute;es sur la base desquelles, via un environnement interactif, certaines zones de l&rsquo;espace de recherche pourront &ecirc;tre favoris&eacute;es au d&eacute;triment d&rsquo;autres, moins susceptibles de conduire &agrave; des solutions int&eacute;ressantes.</p>\r\n<p>La recherche d&rsquo;une orchestration se pr&eacute;sente alors comme un processus it&eacute;ratif au cours duquel &eacute;mergent conjointement solutions pertinentes et pr&eacute;f&eacute;rences de l&rsquo;utilisateur. Techniquement parlant, les solutions int&eacute;ressantes sont proches du front de Pareto d&rsquo;un probl&egrave;me d&rsquo;optimisation (sac &agrave; dos) multicrit&egrave;res.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>, <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Analyse et synth&egrave;se des sons</a>.</p>", "content_en": "<p>The Orchestration project is an integral part of Sample Orchestrator.</p>\r\n<p>It hopes to provide composers with a tool to assist orchestration that is integrated in the software environments created at IRCAM to assist composition, such as OpenMusic. By taking advantage of the knowledge acquired through large databases of instrumental sounds&mdash;taking into account the breadth of the possibilities of musical instruments&mdash;and the progress in the understanding of pitch, we hope to help composers explore the array of sound possibilities available with an orchestra. The problem consists of finding the combinations of instrumental sounds that are the closest to a target defined either from a recorded sound or from a more abstract process (overlapping pitches, for example) via a search by similarity defined by the user.</p>\r\n<p>The major scientific issues lie, from a signal analysis point of view, in the choice of a group of &lsquo;characteristics&rsquo; that can be calculated from samples of instrumental sounds, pertinent in terms of their timbre description, and that make it possible to predict&mdash;without having to listen or to analyze&mdash;the timbre of an overlapping of sounds. The chosen approach consists of incorporating the knowledge gained from the analysis of large sound databases and a set of \"instrument models\", making it possible to estimate the probability that a certain sound will be played by an instrument or by a group of instruments.</p>\r\n<p>For the time being, this is limited to static harmonic sounds and to periodic temporal vibrations (such as a tremolo or a vibrato) but in time the application will be improved to the point where will work for all types of sounds.</p>\r\n<p>Another issue concerns the management of the combinatorial analysis adapted to the manipulated data, the complexity of the problem makes it impossible to assess the range of possible solutions. The method currently being explored through an interactive environment lets us offer a group of solutions to a composer, in a reasonable time frame, where certain zones of research could be favored over others that are less likely to lead to interesting solutions.</p>\r\n<p>The search for an orchestration therefore becomes an iterative process, during with pertinent solutions and user preferences surface simultaneously. Technically speaking, the interesting solutions are close to a multi-criteria Pareto distribution optimization problem.</p>\r\n<p>IRCAM's Teams: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>, <a href=\"/recherche/equipes-de-recherches/analyse-et-synthese-des-sons/\">Sound Analysis &amp; Synthesis team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 60, "fields": {"keywords_string": "", "site": 1, "title": "\u00c9criture du son et de l\u2019espace", "title_fr": "\u00c9criture du son et de l\u2019espace", "title_en": "Writing for Sound and Space", "slug": "ecriture-du-son-et-de-lespace", "_meta_title": "", "description": "Nouvelle approche pour la repr\u00e9sentation et le traitement sonore", "description_fr": "Nouvelle approche pour la repr\u00e9sentation et le traitement sonore", "description_en": "New approach to the representation of sounds via high-level programs", "gen_description": false, "created": "2016-09-09T08:50:53.491Z", "updated": "2018-06-29T09:43:14.529Z", "status": 2, "publish_date": "2016-09-09T08:50:53Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les technologies d&rsquo;analyse, traitement et synth&egrave;se du signal sonore permettent d&rsquo;entrevoir des modalit&eacute;s d&rsquo;&eacute;criture in&eacute;dites assimilant la cr&eacute;ation sonore au c&oelig;ur de la composition musicale. OpenMusic permet l&rsquo;int&eacute;gration de telles technologies via un ensemble de biblioth&egrave;ques sp&eacute;cialis&eacute;es liant les programmes cr&eacute;&eacute;s dans l&rsquo;environnement de CAO aux processus de traitement, de synth&egrave;se ou de spatialisation sonore (r&eacute;alis&eacute;s notamment par des outils de l&rsquo;Ircam : SupervP, Pm2, Chant, Modalys, Spat, mais &eacute;galement des outils externes comme Csound ou Faust). Ce rapprochement des domaines du son et de la CAO constitue une approche nouvelle pour la repr&eacute;sentation et le traitement sonore &agrave; travers des programmes et structures de donn&eacute;es symboliques de haut niveau.</p>\r\n<p>D&eacute;velopp&eacute;e en collaboration avec le compositeur Marco Stroppa, la biblioth&egrave;que OMChroma permet de contr&ocirc;ler des processus de synth&egrave;se sonore &agrave; l&rsquo;aide de structures de donn&eacute;es matricielles. Son extension au domaine de la spatialisation, OMPrisma, permet de r&eacute;aliser des processus de &laquo; synth&egrave;se sonore spatialis&eacute;e &raquo;, faisant intervenir la spatialisation (positions et trajectoires, mais &eacute;galement caract&eacute;ristiques de salle, orientation ou directivit&eacute; des sources sonores) au moment de la production des sons. Contr&ocirc;l&eacute;s dans OpenMusic gr&acirc;ce &agrave; un ensemble d&rsquo;&eacute;diteurs graphiques et d&rsquo;op&eacute;rateurs, ces outils offrent une grande richesse dans la sp&eacute;cification conjointe des sons de synth&egrave;se et des sc&egrave;nes spatiales.</p>\r\n<p>Le projet OM-Chant a r&eacute;cemment permis de remettre sur le devant de la sc&egrave;ne la technologie de synth&egrave;se par FOFs (fonctions d&rsquo;ondes formantiques), et de r&eacute;aliser au c&oelig;ur des processus de CAO des sons de synth&egrave;ses inspir&eacute;s du mod&egrave;le de production vocal.</p>\r\n<p>La th&eacute;matique de l&rsquo;espace, et la collaboration avec l&rsquo;&eacute;quipe <a href=\"/recherche/equipes-recherche/eac/\">EAC</a>, a &eacute;t&eacute; renforc&eacute;e avec un projet de conception d&rsquo;interfaces pour le contr&ocirc;le des processus de spatialisation sonore. Suivant une approche de conception participative, des entretiens ont &eacute;t&eacute; r&eacute;alis&eacute;s avec des compositeurs afin de mieux comprendre leurs besoins, dans le but de proposer des outils facilitant le contr&ocirc;le et l&rsquo;&eacute;criture de la spatialisation. Ces entretiens ont mis en &eacute;vidence la n&eacute;cessit&eacute; d&rsquo;outils interactifs pour la saisie, la visualisation et la manipulation de donn&eacute;es de contr&ocirc;le pour la spatialisation, et ont conduit la conception de diff&eacute;rents prototypes.</p>\r\n<p>Les objets et outils de conception spatiaux 2D/3D <a href=\"http://forumnet.ircam.fr/fr/produit/openmusic/\" target=\"_blank\">OpenMusic</a> ont &eacute;t&eacute; fondus dans un mod&egrave;le de donn&eacute;es temporis&eacute;es, permettant une gestion homog&egrave;ne des sp&eacute;cifications et transformations temporelles. Connect&eacute;es au moteur d&rsquo;ordonnancement et &agrave; des structures temporelles de plus haut niveau, ces donn&eacute;es permettent de repr&eacute;senter des sc&egrave;nes sonores spatiales et leur &eacute;volution dans le temps. Un objet interactif a &eacute;t&eacute; d&eacute;velopp&eacute;, utilisant les modules de visualisation, d&rsquo;interaction et de rendu spatialis&eacute; de la biblioth&egrave;que Spat.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>Les technologies d&rsquo;analyse, traitement et synth&egrave;se du signal sonore permettent d&rsquo;entrevoir des modalit&eacute;s d&rsquo;&eacute;criture in&eacute;dites assimilant la cr&eacute;ation sonore au c&oelig;ur de la composition musicale. OpenMusic permet l&rsquo;int&eacute;gration de telles technologies via un ensemble de biblioth&egrave;ques sp&eacute;cialis&eacute;es liant les programmes cr&eacute;&eacute;s dans l&rsquo;environnement de CAO aux processus de traitement, de synth&egrave;se ou de spatialisation sonore (r&eacute;alis&eacute;s notamment par des outils de l&rsquo;Ircam : SupervP, Pm2, Chant, Modalys, Spat, mais &eacute;galement des outils externes comme Csound ou Faust). Ce rapprochement des domaines du son et de la CAO constitue une approche nouvelle pour la repr&eacute;sentation et le traitement sonore &agrave; travers des programmes et structures de donn&eacute;es symboliques de haut niveau.</p>\r\n<p>D&eacute;velopp&eacute;e en collaboration avec le compositeur Marco Stroppa, la biblioth&egrave;que OMChroma permet de contr&ocirc;ler des processus de synth&egrave;se sonore &agrave; l&rsquo;aide de structures de donn&eacute;es matricielles. Son extension au domaine de la spatialisation, OMPrisma, permet de r&eacute;aliser des processus de &laquo; synth&egrave;se sonore spatialis&eacute;e &raquo;, faisant intervenir la spatialisation (positions et trajectoires, mais &eacute;galement caract&eacute;ristiques de salle, orientation ou directivit&eacute; des sources sonores) au moment de la production des sons. Contr&ocirc;l&eacute;s dans OpenMusic gr&acirc;ce &agrave; un ensemble d&rsquo;&eacute;diteurs graphiques et d&rsquo;op&eacute;rateurs, ces outils offrent une grande richesse dans la sp&eacute;cification conjointe des sons de synth&egrave;se et des sc&egrave;nes spatiales.</p>\r\n<p>Le projet OM-Chant a r&eacute;cemment permis de remettre sur le devant de la sc&egrave;ne la technologie de synth&egrave;se par FOFs (fonctions d&rsquo;ondes formantiques), et de r&eacute;aliser au c&oelig;ur des processus de CAO des sons de synth&egrave;ses inspir&eacute;s du mod&egrave;le de production vocal.</p>\r\n<p>La th&eacute;matique de l&rsquo;espace, et la collaboration avec l&rsquo;&eacute;quipe <a href=\"/recherche/equipes-recherche/eac/\">EAC</a>, a &eacute;t&eacute; renforc&eacute;e avec un projet de conception d&rsquo;interfaces pour le contr&ocirc;le des processus de spatialisation sonore. Suivant une approche de conception participative, des entretiens ont &eacute;t&eacute; r&eacute;alis&eacute;s avec des compositeurs afin de mieux comprendre leurs besoins, dans le but de proposer des outils facilitant le contr&ocirc;le et l&rsquo;&eacute;criture de la spatialisation. Ces entretiens ont mis en &eacute;vidence la n&eacute;cessit&eacute; d&rsquo;outils interactifs pour la saisie, la visualisation et la manipulation de donn&eacute;es de contr&ocirc;le pour la spatialisation, et ont conduit la conception de diff&eacute;rents prototypes.</p>\r\n<p>Les objets et outils de conception spatiaux 2D/3D <a href=\"http://forumnet.ircam.fr/fr/produit/openmusic/\" target=\"_blank\">OpenMusic</a> ont &eacute;t&eacute; fondus dans un mod&egrave;le de donn&eacute;es temporis&eacute;es, permettant une gestion homog&egrave;ne des sp&eacute;cifications et transformations temporelles. Connect&eacute;es au moteur d&rsquo;ordonnancement et &agrave; des structures temporelles de plus haut niveau, ces donn&eacute;es permettent de repr&eacute;senter des sc&egrave;nes sonores spatiales et leur &eacute;volution dans le temps. Un objet interactif a &eacute;t&eacute; d&eacute;velopp&eacute;, utilisant les modules de visualisation, d&rsquo;interaction et de rendu spatialis&eacute; de la biblioth&egrave;que Spat.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>The technology used for sound analysis, synthesis and signal processing have made it possible to imagine significant, even new, possibilities for composition. In this prospect, new functions have been developed in the OpenMusic environment to include these technologies in the context of the compositional process. Several specialized libraries make it possible to connect programs created in a computer-assisted composition environment with processes for sound processing or synthesis (created by IRCAM tools such as SupervP, pm2, CHANT, Modalys, Spat, but also tools such as Csound and Faust). Bringing the domain of sound synthesis and computer-assisted composition together is a new approach to the representation of sounds via high-level programs that put structures of abstract data and models of advanced temporal structures to work, permitting total control of the processes of sound processing and generation of synthesis data.</p>\r\n<p>Developed in collaboration with Marco Stroppa, the OMChroma library makes it possible to control the processes of sound synthesis with the help of matrix data structures. OMChroma&rsquo;s extension for spatialization, OMPrisma, enables to implement \"spatialized sound synthesis\" processes, calling on spatialization (positions and <br />trajectories, but also room characteristics, sound source orientation and directivity) when sounds are produced. Controlled in OpenMusic via an ensemble of graphical editors and operators, these tools propose a wealth of possibilities in the conjoint specification of synthesized sounds and spatialized spaces.</p>\r\n<p>The OM-Chant project also made it possible to bring back the technology of FOF (Formant Wave Functions) synthesis at the heart of the process of computer-assisted composition, and to create at the core of CAC processes synthesized sounds inspired by the model of vocal production.</p>\r\n<p>The theme of space, and the collaboration with the <a href=\"/recherche/equipes-recherche/eac/\">Acoustic and Cognitive Spaces team</a>, has been reinforced with a project on the conception of interfaces to control sound spatialization processes. Using a participatory design approach, interviews were held with composers to better understand their needs with the goal of offering tools to facilitate the control and writing of spatialization. These interviews revealed the necessity of interactive tools to enter, visualize, and manipulate control data for spatialization, and led to the design of different prototypes.</p>\r\n<p><a href=\"http://forumnet.ircam.fr/product/openmusic-en/\" target=\"_blank\">OpenMusic</a> objects and tools for 2D/3D spatial conception are based on a model of delayed data, enabling a homogenous management of temporal specifications and transformations. Connected to a sequencing motor and high-level temporal structures, these data make it possible to represent sound scenes and their evolution over time. An interactive object was developed using models of visualization, interaction, and spatialized rendering from the Spat library.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 61, "fields": {"keywords_string": "", "site": 1, "title": "Papier augment\u00e9 pour la CAO", "title_fr": "Papier augment\u00e9 pour la CAO", "title_en": "Augmented Paper for CAC", "slug": "papier-augmente-pour-la-cao", "_meta_title": "", "description": "Identifier les applications musicales possibles issues de l\u2019articulation entre le support informatique et le papier augment\u00e9", "description_fr": "Identifier les applications musicales possibles issues de l\u2019articulation entre le support informatique et le papier augment\u00e9", "description_en": "Identify the possible musical applications that can come from the link between the computer support and augmented paper.", "gen_description": false, "created": "2016-09-09T08:56:07.063Z", "updated": "2018-09-05T13:04:33.242Z", "status": 2, "publish_date": "2016-09-09T08:56:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Gr&acirc;ce aux technologies de papier augment&eacute; contenant un motif invisible mais d&eacute;tectable par une petite cam&eacute;ra introduite dans un stylo, l&rsquo;ordinateur peut d&eacute;tecter ce qu&rsquo;&eacute;crit le compositeur. Ce lien &laquo; amont &raquo; entre le papier et l&rsquo;ordinateur est compl&eacute;t&eacute; par un lien &laquo; aval &raquo; de l&rsquo;ordinateur vers le papier gr&acirc;ce &agrave; l&rsquo;impression sur papier augment&eacute;, cr&eacute;ant un cycle de production in&eacute;dit.</p>\r\n<p>Le but de ce projet, dont le prolongement fait l&rsquo;objet d&rsquo;une demande ANR, est d&rsquo;identifier, en collaboration avec des artistes et des chercheurs, les applications musicales possibles issues de l&rsquo;articulation entre le support informatique et le papier augment&eacute;. Plut&ocirc;t que de remplacer le papier, dont les propri&eacute;t&eacute;s de flexibilit&eacute;, de confort et d&rsquo;associativit&eacute; libres sont reconnues, notre approche consiste &agrave; d&eacute;velopper des applications qui combinent les avantages des documents papier et des documents &eacute;lectroniques. &Agrave; long terme, nous envisageons de d&eacute;velopper dans ce projet des prototypes d&rsquo;applications sur trois diff&eacute;rents axes :</p>\r\n<ul>\r\n<li><strong>La notation</strong> <br />Dans le domaine de la composition musicale, on s&rsquo;int&eacute;ressera &agrave; la fois aux aspects de notation et d&rsquo;annotation, l&rsquo;un et l&rsquo;autre &eacute;tant en r&eacute;alit&eacute; compl&eacute;mentaires de par la nature r&eacute;flexive de la cr&eacute;ation musicale.</li>\r\n<li><strong>L&rsquo;&eacute;criture de la synth&egrave;se</strong> <br />De par sa souplesse d&rsquo;utilisation et la finesse de l&rsquo;interaction manuscrite compar&eacute;e &agrave; la souris ou m&ecirc;me &agrave; une tablette graphique, le papier reste le support privil&eacute;gi&eacute; pour l&rsquo;expression informelle d&rsquo;id&eacute;es artistiques gestuelles et en particulier pour l&rsquo;&eacute;criture de la synth&egrave;se. En collaboration avec le logiciel OpenMusic, cette technologie permettra une r&eacute;alisation naturelle de l&rsquo;&eacute;volution dans le temps des divers param&egrave;tres de synth&egrave;se.</li>\r\n<li><strong>L&rsquo;enseignement</strong> <br />La technologie de papier augment&eacute; int&eacute;resse particuli&egrave;rement les musicologues et enseignants de musique. Elle permet de travailler de fa&ccedil;on collaborative sur un support simple, la partition imprim&eacute;e, mise en relation avec le logiciel Musique Lab 2 afin de produire de nouvelles formes d&rsquo;interaction.</li>\r\n</ul>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>, <a href=\"/recherche/equipes-recherche/apm/\">Analyse des pratiques musicales</a>.</p>", "content_fr": "<p>Gr&acirc;ce aux technologies de papier augment&eacute; contenant un motif invisible mais d&eacute;tectable par une petite cam&eacute;ra introduite dans un stylo, l&rsquo;ordinateur peut d&eacute;tecter ce qu&rsquo;&eacute;crit le compositeur. Ce lien &laquo; amont &raquo; entre le papier et l&rsquo;ordinateur est compl&eacute;t&eacute; par un lien &laquo; aval &raquo; de l&rsquo;ordinateur vers le papier gr&acirc;ce &agrave; l&rsquo;impression sur papier augment&eacute;, cr&eacute;ant un cycle de production in&eacute;dit.</p>\r\n<p>Le but de ce projet, dont le prolongement fait l&rsquo;objet d&rsquo;une demande ANR, est d&rsquo;identifier, en collaboration avec des artistes et des chercheurs, les applications musicales possibles issues de l&rsquo;articulation entre le support informatique et le papier augment&eacute;. Plut&ocirc;t que de remplacer le papier, dont les propri&eacute;t&eacute;s de flexibilit&eacute;, de confort et d&rsquo;associativit&eacute; libres sont reconnues, notre approche consiste &agrave; d&eacute;velopper des applications qui combinent les avantages des documents papier et des documents &eacute;lectroniques. &Agrave; long terme, nous envisageons de d&eacute;velopper dans ce projet des prototypes d&rsquo;applications sur trois diff&eacute;rents axes :</p>\r\n<ul>\r\n<li><strong>La notation</strong> <br />Dans le domaine de la composition musicale, on s&rsquo;int&eacute;ressera &agrave; la fois aux aspects de notation et d&rsquo;annotation, l&rsquo;un et l&rsquo;autre &eacute;tant en r&eacute;alit&eacute; compl&eacute;mentaires de par la nature r&eacute;flexive de la cr&eacute;ation musicale.</li>\r\n<li><strong>L&rsquo;&eacute;criture de la synth&egrave;se</strong> <br />De par sa souplesse d&rsquo;utilisation et la finesse de l&rsquo;interaction manuscrite compar&eacute;e &agrave; la souris ou m&ecirc;me &agrave; une tablette graphique, le papier reste le support privil&eacute;gi&eacute; pour l&rsquo;expression informelle d&rsquo;id&eacute;es artistiques gestuelles et en particulier pour l&rsquo;&eacute;criture de la synth&egrave;se. En collaboration avec le logiciel OpenMusic, cette technologie permettra une r&eacute;alisation naturelle de l&rsquo;&eacute;volution dans le temps des divers param&egrave;tres de synth&egrave;se.</li>\r\n<li><strong>L&rsquo;enseignement</strong> <br />La technologie de papier augment&eacute; int&eacute;resse particuli&egrave;rement les musicologues et enseignants de musique. Elle permet de travailler de fa&ccedil;on collaborative sur un support simple, la partition imprim&eacute;e, mise en relation avec le logiciel Musique Lab 2 afin de produire de nouvelles formes d&rsquo;interaction.</li>\r\n</ul>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>, <a href=\"/recherche/equipes-recherche/apm/\">Analyse des pratiques musicales</a>.</p>", "content_en": "<p>Through the technology present in augmented paper that contains a motif visible only to the small camera inserted in a special pen, the computer can detect what the composer is writing. This &lsquo;before&rsquo; connection between paper and computer is completed by an &lsquo;after&rsquo; connection from the computer to paper by printing on augmented paper, therefore creating an entirely new production cycle.</p>\r\n<p>The goal of this project, extended upon request by the ANR, is to work in collaboration with artists and research workers to identify the possible musical applications that can come from the link between the computer support and augmented paper. Rather than replace paper, with its recognized properties of flexibility, comfort, and free association our approach consists of developing applications that combine the advantages of paper and electronic documents. In the long run, we would like to develop prototypes of applications in three core fields:</p>\r\n<ul>\r\n<li><strong>Notation</strong><br />In the field of musical composition, we are interested in both notation and annotation as both are complementary in their reflective nature for musical creation.</li>\r\n<li><strong>Writing Synthesis</strong><br />Due to its flexibility of use and the subtlety of handwritten interaction compared to interaction via a mouse or even with a graphical tablet, paper remains the preferred support for the informal expression of artistic gestural ideas, and especially for writing down ideas for synthesis. In collaboration with the OpenMusic software program, this technology facilitates a natural evolution of various parameters for synthesis.</li>\r\n<li><strong>Teaching<br /></strong>The technology present in augmented paper is exceptionally interesting for musicologists and music teachers. By connecting a simple support, the printed score, to the MusiqueLab 2 software program, it is possible to work collaboratively and create new forms of interaction.</li>\r\n</ul>\r\n<p>IRCAM'sTeams: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a>, <a href=\"/recherche/equipes-recherche/apm/\">Analysis of Musical Practices</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6, 5], "organizations": [4, 1, 152], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 62, "fields": {"keywords_string": "", "site": 1, "title": "Math\u00e9matiques et musique", "title_fr": "Math\u00e9matiques et musique", "title_en": "Mathematics and Music", "slug": "modelisation-informatique-des-structures-algebriques-en-musique-et-musicologie", "_meta_title": "", "description": "Mod\u00e8les alge\u0301briques, topologiques et cate\u0301goriels en musicologie computationnelle", "description_fr": "Mod\u00e8les alge\u0301briques, topologiques et cate\u0301goriels en musicologie computationnelle", "description_en": "Algebraic Models, Topologies, and Categories in Computational Musicology", "gen_description": false, "created": "2016-09-09T09:04:54.521Z", "updated": "2018-06-29T09:48:13.486Z", "status": 2, "publish_date": "2016-09-09T09:04:54Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet &laquo; Mod&egrave;les alg&eacute;briques, topologiques et cate\u0301goriels en musicologie computationnelle &raquo; a &eacute;t&eacute; retenu par le <a href=\"http://www.cnrs.fr/\" target=\"_blank\">CNRS</a> &agrave; l&rsquo;occasion de la cr&eacute;ation d&rsquo;un poste de directeur de recherche au sein de l&rsquo;&eacute;quipe <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>. Ce projet fait suite au projet MISA (Mod&eacute;lisation informatique des structures alg&eacute;briques en musique et musicologie) dont il &eacute;largit le spectre d&rsquo;outils math&eacute;matiques au service du musicologue computationnel (des outils issus non seulement de l&rsquo;alg&egrave;bre mais aussi de la topologie et de la th&eacute;orie des cat&eacute;gories). En m&ecirc;me temps, il s&rsquo;attaque aux articulations entre musique savante et popular music (rock, pop, jazz et chanson), dans une dimension &agrave; la fois th&eacute;orique mais aussi pratique. Le projet b&eacute;n&eacute;ficie d&rsquo;un quadruple ancrage institutionnel : au sein de la&nbsp; <a href=\"http://www.smcm-net.info/\" target=\"_blank\">Society for Mathematics and Computation in Music</a> (soci&eacute;t&eacute; internationale dont l&rsquo;activit&eacute; a &eacute;t&eacute; f&eacute;d&eacute;r&eacute;e par le pr&eacute;c&eacute;dent projet MISA), du <a href=\"http://esars.scicog.fr/\" target=\"_blank\">GDR ESARS</a> (Esth&eacute;tique, Art et Science), d&rsquo;une collaboration avec l&rsquo;<a href=\"http://www.iremus.cnrs.fr/\" target=\"_blank\">IReMus de Sorbonne Universit&eacute;s</a> (dans le cadre des rencontres internationales du Centre de Recherche sur les Musiques Populaires) et d&rsquo;un partenariat avec l&rsquo;<a href=\"https://www.unistra.fr/index.php?id=accueil&amp;utm_source=unistra_fr&amp;utm_medium=unistra_fr_homepage\" target=\"_blank\">universit&eacute; de Strasbourg</a> (en particulier l&rsquo;IRMA et le Labex GREAM). Ce projet alimente, de surcro&icirc;t, le <a href=\"http://www.entretemps.asso.fr/maths/\" target=\"_blank\">s&eacute;minaire mamuphi</a> (math&eacute;matiques, musique et philosophie), coorganis&eacute; avec l&rsquo;<a href=\"http://www.ens.fr/\" target=\"_blank\">&eacute;cole normale sup&eacute;rieure</a>, ainsi que les deux collections Musique/Sciences (chez Delatour France) et Computational Music Sciences (chez Springer).</p>\r\n<p>La programmation spatiale vise, elle, &agrave; mod&eacute;liser des probl&egrave;mes comme d&eacute;placements dans un espace ou comme transformation de structures spatiales. Elle fournit des outils informatiques permettant de d&eacute;velopper des analyses dans la lign&eacute;e de la Set Theory. Ce travail a d&eacute;j&agrave; permis d&rsquo;explorer la pertinence d&rsquo;outils topologiques pour la repr&eacute;sentation et la classification d&rsquo;objets musicaux tels le calcul des s&eacute;ries tous intervalles, la th&eacute;orie harmonique n&eacute;oriemannienne et la repr&eacute;sentation g&eacute;om&eacute;trique de suites d&rsquo;accords.</p>\r\n<p>Il en est r&eacute;sult&eacute; un environnement exp&eacute;rimental d&rsquo;aide &agrave; l&rsquo;analyse de s&eacute;quences musicales appel&eacute; HexaChord. HexaChord est un environnement permettant de construire des repr&eacute;sentations spatiales associ&eacute;es &agrave; un ensemble d&rsquo;accords et de les analyser &agrave; travers plusieurs notions topologiques. Les repr&eacute;sentations spatiales propos&eacute;es comportent divers Tonnetz et les complexes simpliciaux correspondant aux ensembles de hauteurs des accords. Le logiciel propose des visualisations 2D et 3D des repr&eacute;sentations produites.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>Le projet &laquo; Mod&egrave;les alg&eacute;briques, topologiques et cate\u0301goriels en musicologie computationnelle &raquo; a &eacute;t&eacute; retenu par le <a href=\"http://www.cnrs.fr/\" target=\"_blank\">CNRS</a> &agrave; l&rsquo;occasion de la cr&eacute;ation d&rsquo;un poste de directeur de recherche au sein de l&rsquo;&eacute;quipe <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>. Ce projet fait suite au projet MISA (Mod&eacute;lisation informatique des structures alg&eacute;briques en musique et musicologie) dont il &eacute;largit le spectre d&rsquo;outils math&eacute;matiques au service du musicologue computationnel (des outils issus non seulement de l&rsquo;alg&egrave;bre mais aussi de la topologie et de la th&eacute;orie des cat&eacute;gories). En m&ecirc;me temps, il s&rsquo;attaque aux articulations entre musique savante et popular music (rock, pop, jazz et chanson), dans une dimension &agrave; la fois th&eacute;orique mais aussi pratique. Le projet b&eacute;n&eacute;ficie d&rsquo;un quadruple ancrage institutionnel : au sein de la&nbsp; <a href=\"http://www.smcm-net.info/\" target=\"_blank\">Society for Mathematics and Computation in Music</a> (soci&eacute;t&eacute; internationale dont l&rsquo;activit&eacute; a &eacute;t&eacute; f&eacute;d&eacute;r&eacute;e par le pr&eacute;c&eacute;dent projet MISA), du <a href=\"http://esars.scicog.fr/\" target=\"_blank\">GDR ESARS</a> (Esth&eacute;tique, Art et Science), d&rsquo;une collaboration avec l&rsquo;<a href=\"http://www.iremus.cnrs.fr/\" target=\"_blank\">IReMus de Sorbonne Universit&eacute;s</a> (dans le cadre des rencontres internationales du Centre de Recherche sur les Musiques Populaires) et d&rsquo;un partenariat avec l&rsquo;<a href=\"https://www.unistra.fr/index.php?id=accueil&amp;utm_source=unistra_fr&amp;utm_medium=unistra_fr_homepage\" target=\"_blank\">universit&eacute; de Strasbourg</a> (en particulier l&rsquo;IRMA et le Labex GREAM). Ce projet alimente, de surcro&icirc;t, le <a href=\"http://www.entretemps.asso.fr/maths/\" target=\"_blank\">s&eacute;minaire mamuphi</a> (math&eacute;matiques, musique et philosophie), coorganis&eacute; avec l&rsquo;<a href=\"http://www.ens.fr/\" target=\"_blank\">&eacute;cole normale sup&eacute;rieure</a>, ainsi que les deux collections Musique/Sciences (chez Delatour France) et Computational Music Sciences (chez Springer).</p>\r\n<p>La programmation spatiale vise, elle, &agrave; mod&eacute;liser des probl&egrave;mes comme d&eacute;placements dans un espace ou comme transformation de structures spatiales. Elle fournit des outils informatiques permettant de d&eacute;velopper des analyses dans la lign&eacute;e de la Set Theory. Ce travail a d&eacute;j&agrave; permis d&rsquo;explorer la pertinence d&rsquo;outils topologiques pour la repr&eacute;sentation et la classification d&rsquo;objets musicaux tels le calcul des s&eacute;ries tous intervalles, la th&eacute;orie harmonique n&eacute;oriemannienne et la repr&eacute;sentation g&eacute;om&eacute;trique de suites d&rsquo;accords.</p>\r\n<p>Il en est r&eacute;sult&eacute; un environnement exp&eacute;rimental d&rsquo;aide &agrave; l&rsquo;analyse de s&eacute;quences musicales appel&eacute; HexaChord. HexaChord est un environnement permettant de construire des repr&eacute;sentations spatiales associ&eacute;es &agrave; un ensemble d&rsquo;accords et de les analyser &agrave; travers plusieurs notions topologiques. Les repr&eacute;sentations spatiales propos&eacute;es comportent divers Tonnetz et les complexes simpliciaux correspondant aux ensembles de hauteurs des accords. Le logiciel propose des visualisations 2D et 3D des repr&eacute;sentations produites.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>The project \"Mod&egrave;les alg&eacute;briques, topologiques et cat&eacute;goriels en musicologie&nbsp; computationnelle&nbsp; (Algebraic Models, Topologies, and Categories in Computational Musicology)\" was selected by the <a href=\"http://www.cnrs.fr/index.php\" target=\"_blank\">CNRS</a> upon the creation of a director&rsquo;s position in the <a href=\"/recherche/equipes-recherche/repmus/\">Musical Representations team</a>. This project follows the MISA project (Computer Modeling of Algebraic Structures in Music and Musicology), broadening the spectrum of mathematical tools for computational musicology (tools from algebra and also from topology and category theory). At the same time, this project attacks the theoretical and practical articulations between classical and popular music (rock, pop, jazz, song). Four institutions support the project: the <a href=\"http://www.smcm-net.info/\" target=\"_blank\">Society for Mathematics and Computation in Music</a> (an international society for which the MISA project was a federating force), the <a href=\"http://esars.scicog.fr/\" target=\"_blank\">GDR ESARS</a> (Esth&eacute;tique, Art et Science), a collaboration with Sorbonne Universit&eacute;s&rsquo; <a href=\"http://www.iremus.cnrs.fr/\" target=\"_blank\">IReMus</a> (during international encounters held at the Centre de Recherche on popular music), and a partnership with <a href=\"http://www.en.unistra.fr/index.php?id=21304\" target=\"_blank\">universit&eacute; de Strasbourg</a> (in particular with IRMA and Labex GREAM). This project also supports the <a href=\"http://www.entretemps.asso.fr/maths/\" target=\"_blank\">Mamuphi seminar</a> on mathematics, music, and philosophy organized in collaboration with the <a href=\"http://www.ens.fr/\" target=\"_blank\">&eacute;cole normale sup&eacute;rieure</a> and the book collections: Musique/Sciences (Delatour France) and Computational Music Sciences (Springer).</p>\r\n<p>The spatial program aims to model problems such as movements in a specific space or the transformation of spatial structures. It provides computer tools that enable the development of analyses in line with Set Theory. This work has already made it possible to explore the pertinence of topological tools for the representation and classification of musical objects such as calculating all-interval series, Neo-Reimannian harmonic theory, and the geometric representation of chord progressions.</p>\r\n<p>The result is an experimental environment to assist analysis of musical sequences called HexaChord.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />&nbsp;HexaChord is an environment that makes it possible to build spatial representations associated with a group of chords and analyzes them via several topological notions. The spatial representations proposed include divers Tonnetz and simplical complexes corresponding to groups of chords&rsquo; pitches. The software offers 2D and 3D visualizations of the representations produced.</p>\r\n<p>IRCAM's Teams: <a href=\"/recherche/equipes-de-recherches/representations-musicales/\">Music Representations team</a><a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">.</a></p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "http://repmus.ircam.fr/mamux/home", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 63, "fields": {"keywords_string": "", "site": 1, "title": "Gemme", "title_fr": "Gemme", "title_en": "Gemme", "slug": "gemme", "_meta_title": "", "description": "Geste musical : mod\u00e8les et exp\u00e9riences", "description_fr": "Geste musical : mod\u00e8les et exp\u00e9riences", "description_en": "Musical Gesture: Models and Experiments", "gen_description": false, "created": "2016-09-09T09:12:05.706Z", "updated": "2018-07-25T14:39:02.906Z", "status": 2, "publish_date": "2016-09-09T09:12:05Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Au cours des ann&eacute;es 2000, le geste est devenu un moyen privil&eacute;gi&eacute; d&rsquo;interaction avec les technologies, aupr&egrave;s du grand public comme au sein de la communaut&eacute; des musiciens. Si l&rsquo;&eacute;criture musicale d&eacute;mat&eacute;rialise, d&eacute;compose et reconstruit le corps du musicien-interpr&egrave;te depuis presque cinquante ans, on observe plus particuli&egrave;rement, depuis une dizaine d&rsquo;ann&eacute;es, une forte convergence interdisciplinaire sur cet objet de recherche/cr&eacute;ation int&eacute;ressant compositeurs, interpr&egrave;tes et informaticiens, mais aussi sciences de l&rsquo;ing&eacute;nieur, psychologie, physiologie, biom&eacute;canique et sciences cognitives. Or, cette notion de geste, par ailleurs couramment employ&eacute;e dans nombre de domaines, notamment, depuis longtemps, dans les arts du spectacle (th&eacute;&acirc;tre, danse, performance...), n&rsquo;a encore fait l&rsquo;objet que d&rsquo;embryonnaires recherches en musicologie.</p>\r\n<p>Dans ce contexte, le projet GEMME propose une analyse serr&eacute;e de textes th&eacute;oriques et d&rsquo;&oelig;uvres musicales, mais aussi m&egrave;ne des enqu&ecirc;tes sur l&rsquo;amont et l&rsquo;aval de la partition : de quelles possibilit&eacute;s th&eacute;oriques et techniques de formalisation du geste disposent les compositeurs ? quelles proc&eacute;dures gestuelles exp&eacute;rimentent-ils sur le papier et lors de la r&eacute;alisation pratique de l&rsquo;&oelig;uvre ? quelles modalit&eacute;s de transmission de l&rsquo;information gestuelle s&rsquo;&eacute;laborent non seulement dans la collaboration entre compositeurs et interpr&egrave;tes, mais aussi dans l&rsquo;enseignement de l&rsquo;interpr&eacute;tation ? Autant de questions auxquelles ce programme se propose de r&eacute;pondre &agrave; travers quatre chantiers principaux :</p>\r\n<p>1) <em>Th&eacute;ories implicites du geste</em> (g&eacute;n&eacute;alogie de la notion compositionnelle de geste, avec ses cat&eacute;gorisations et ses p&eacute;riodisations, et son &eacute;tat de l&rsquo;art actuel) ;<br />2) <em>Geste et sc&egrave;ne</em> (&eacute;tude d&rsquo;une d&eacute;marche paradigmatique, celle de Kagel, o&ugrave; la notion musicale se noue &agrave; son expression sc&eacute;nique, dans le cadre du th&eacute;&acirc;tre musical et instrumental) ;<br />3) <em>Geste et instrument</em> (&eacute;tude d&rsquo;une d&eacute;marche paradigmatique contrastante, celle de Lachenmann, o&ugrave; la composition interroge le d&eacute;tail des possibilit&eacute;s organologiques de production du son en relation avec une critique politique et sociale des conventions expressives) ;<br />4) <em>Geste et technologie</em> (s&eacute;rie d&rsquo;analyses musicales d&rsquo;un ensemble de partitions de r&eacute;f&eacute;rence, de <em>Time and Motion Study II</em> de Ferneyhough jusqu&rsquo;&agrave;<em> Luna Park</em> d&rsquo;Aperghis, qui d&eacute;clinent plusieurs paradigmes techniques et informatiques formalisant et/ou accompagnant le geste instrumental).</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-12-BSH3-0007.</p>", "content_fr": "<p>Au cours des ann&eacute;es 2000, le geste est devenu un moyen privil&eacute;gi&eacute; d&rsquo;interaction avec les technologies, aupr&egrave;s du grand public comme au sein de la communaut&eacute; des musiciens. Si l&rsquo;&eacute;criture musicale d&eacute;mat&eacute;rialise, d&eacute;compose et reconstruit le corps du musicien-interpr&egrave;te depuis presque cinquante ans, on observe plus particuli&egrave;rement, depuis une dizaine d&rsquo;ann&eacute;es, une forte convergence interdisciplinaire sur cet objet de recherche/cr&eacute;ation int&eacute;ressant compositeurs, interpr&egrave;tes et informaticiens, mais aussi sciences de l&rsquo;ing&eacute;nieur, psychologie, physiologie, biom&eacute;canique et sciences cognitives. Or, cette notion de geste, par ailleurs couramment employ&eacute;e dans nombre de domaines, notamment, depuis longtemps, dans les arts du spectacle (th&eacute;&acirc;tre, danse, performance...), n&rsquo;a encore fait l&rsquo;objet que d&rsquo;embryonnaires recherches en musicologie.</p>\r\n<p>Dans ce contexte, le projet GEMME propose une analyse serr&eacute;e de textes th&eacute;oriques et d&rsquo;&oelig;uvres musicales, mais aussi m&egrave;ne des enqu&ecirc;tes sur l&rsquo;amont et l&rsquo;aval de la partition : de quelles possibilit&eacute;s th&eacute;oriques et techniques de formalisation du geste disposent les compositeurs ? quelles proc&eacute;dures gestuelles exp&eacute;rimentent-ils sur le papier et lors de la r&eacute;alisation pratique de l&rsquo;&oelig;uvre ? quelles modalit&eacute;s de transmission de l&rsquo;information gestuelle s&rsquo;&eacute;laborent non seulement dans la collaboration entre compositeurs et interpr&egrave;tes, mais aussi dans l&rsquo;enseignement de l&rsquo;interpr&eacute;tation ? Autant de questions auxquelles ce programme se propose de r&eacute;pondre &agrave; travers quatre chantiers principaux :</p>\r\n<p>1) <em>Th&eacute;ories implicites du geste</em> (g&eacute;n&eacute;alogie de la notion compositionnelle de geste, avec ses cat&eacute;gorisations et ses p&eacute;riodisations, et son &eacute;tat de l&rsquo;art actuel) ;<br />2) <em>Geste et sc&egrave;ne</em> (&eacute;tude d&rsquo;une d&eacute;marche paradigmatique, celle de Kagel, o&ugrave; la notion musicale se noue &agrave; son expression sc&eacute;nique, dans le cadre du th&eacute;&acirc;tre musical et instrumental) ;<br />3) <em>Geste et instrument</em> (&eacute;tude d&rsquo;une d&eacute;marche paradigmatique contrastante, celle de Lachenmann, o&ugrave; la composition interroge le d&eacute;tail des possibilit&eacute;s organologiques de production du son en relation avec une critique politique et sociale des conventions expressives) ;<br />4) <em>Geste et technologie</em> (s&eacute;rie d&rsquo;analyses musicales d&rsquo;un ensemble de partitions de r&eacute;f&eacute;rence, de <em>Time and Motion Study II</em> de Ferneyhough jusqu&rsquo;&agrave;<em> Luna Park</em> d&rsquo;Aperghis, qui d&eacute;clinent plusieurs paradigmes techniques et informatiques formalisant et/ou accompagnant le geste instrumental).</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-12-BSH3-0007.</p>", "content_en": "<p>In the beginning of the 21st century, gesture became a significant means of interaction with technology for the general public, and also within the musician community. While musical writing has put a strong emphasis on deconstructing and reshaping the acting body of the musician-performer for nearly 50 years, it is interesting to note that for the past 10 years there has been a strong multidisciplinary convergence on this research/creation topic, drawing the attention of composers, performers, and computer scientists as well as the domains of engineering, psychology, physiology, biomechanics, and cognitive sciences. This concept of gesture, commonly used in numerous domains, notably in the performing arts such as theater and dance, has only been the subject of embryonic research in the domain of musicology.</p>\r\n<p>The GEMME project offers an analysis of theoretical texts and musical works, and also carries out investigations before and after the premiere of a score: what theoretical and technical possibilities of the formalization of gestures are available to composers? What gestural procedures can they test on paper and during the performance of a work? What means of transmission of the gestural information are created not only during the collaboration between composer and performer, but also when the performance of the work is taught? This project endeavors to answer these questions via four main themes:</p>\r\n<p>1. Tacit Theories of Gesture: genealogy of the compositional notion of gesture, its categorizations and periodization, the current state of the art<br />2. Gesture and Stage: study of a paradigmatic method&mdash;that of kagel&mdash;where the musical idea is connected to its staged expression in the framework of musical and instrumental theater<br />3.Gesture and Instrument: study of a contrasting paradigmatic method&mdash;that of Lachenmann&mdash;where the composition calls upon a breakdown of the organological possibilities of sound production in relationship with a political and social criticism of expressive conventions<br />4.Gesture and Technology: a series of musical analyses of a group of seminal scores, from Ferneyhough&rsquo;s <em>Time and Motion Study II</em> to <em>Luna Park</em> by Aperghis, that offer a variety of technical and computing paradigms that formalize and/or accompany the instrumental gesture.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference : ANR-12-BSH3-0007.</p>", "date_from": "2012-11-01", "date_to": "2016-06-30", "user": null, "type": "external", "external_id": "ANR-12-BSH3-0007", "program": 1, "program_type": 20, "call": 16, "lead_team": null, "lead_organization": 1, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6, 7], "organizations": [157], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 64, "fields": {"keywords_string": "", "site": 1, "title": "Th\u00e9ories de la composition musicale au XXe si\u00e8cle", "title_fr": "Th\u00e9ories de la composition musicale au XXe si\u00e8cle", "title_en": "Theories of Musical Composition of the 20th Century", "slug": "theories-de-la-composition-musicale-au-xxe-siecle", "_meta_title": "", "description": "Publication collective de r\u00e9f\u00e9rence sur les th\u00e9ories compositionnelles", "description_fr": "Publication collective de r\u00e9f\u00e9rence sur les th\u00e9ories compositionnelles", "description_en": "Collective reference publication on the compositional theories", "gen_description": false, "created": "2016-09-09T09:17:50.512Z", "updated": "2018-06-29T09:50:03.309Z", "status": 2, "publish_date": "2016-09-09T09:17:50Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet &eacute;ditorial commenc&eacute; en 2003 visait &agrave; publier un panorama substantiel des principales th&eacute;ories compositionnelles du XX<sup>e</sup> si&egrave;cle. Alors que certains corpus th&eacute;oriques ont &eacute;t&eacute; largement diffus&eacute;s et comment&eacute;s (Schoenberg, Xenakis, Boulez, Stockhausen...), d&rsquo;autres, tout aussi importants pour l&rsquo;histoire et l&rsquo;esth&eacute;tique musicales, restent mal connus faute d&rsquo;introductions synth&eacute;tiques disponibles. Musiciens et musicologues ne disposaient pas, &agrave; ce jour, d&rsquo;un ouvrage de r&eacute;f&eacute;rence sur la relation f&eacute;conde entre composition et th&eacute;orie au cours du si&egrave;cle pass&eacute;.</p>\r\n<p>Pourtant, la f&eacute;condit&eacute; de cette relation a &eacute;t&eacute; d&eacute;terminante dans le d&eacute;veloppement de la musique contemporaine, et notamment de l&rsquo;informatique musicale. Croisant musicologie historique, ex&eacute;g&egrave;se des corpus th&eacute;oriques et analyse musicale, l&rsquo;ouvrage dirig&eacute; par N. Donin et L. Feneyrou comble le manque actuel d&rsquo;une publication collective de r&eacute;f&eacute;rence sur les th&eacute;ories compositionnelles d&rsquo;un si&egrave;cle caract&eacute;ris&eacute; par l&rsquo;abondance des &eacute;crits de cr&eacute;ateurs, des recherches sur les syst&egrave;mes de composition, et des manifestes esth&eacute;tiques d&eacute;finissant techniques et technologies musicales.</p>\r\n<p>Une soixantaine de sp&eacute;cialistes internationaux a &eacute;t&eacute; r&eacute;unie pour traiter, d&rsquo;une part, des th&eacute;ories compositionnelles sp&eacute;cifiques d&rsquo;individus (ou d&rsquo;&eacute;coles), de Schoenberg &agrave; Rihm en passant par Hindemith ou Carter ; d&rsquo;autre part, des cat&eacute;gories et probl&eacute;matiques ayant &eacute;merg&eacute; au long du si&egrave;cle, telles que : &laquo; musique algorithmique &raquo;, &laquo; live electronics &raquo;, &laquo; th&eacute;&acirc;tre musical &raquo;, &laquo; spectralisme &raquo;, etc. De nombreux corpus inconnus en langue fran&ccedil;aise, et parfois in&eacute;dits, sont pr&eacute;sents aux c&ocirc;t&eacute;s de th&eacute;matiques mieux explor&eacute;es par la musicologie au cours des quarante derni&egrave;res ann&eacute;es.</p>\r\n<p>Les contributions proposent un expos&eacute; synth&eacute;tique, &agrave; la fois technique et historique, de ces notions et/ou doctrines, en se basant &agrave; chaque fois sur l&rsquo;&eacute;tat actuel des connaissances &agrave; propos des articles, manifestes, etc., des compositeurs &eacute;tudi&eacute;s. Les participants, par leur diversit&eacute;, refl&egrave;tent les diff&eacute;rents aspects de la musicologie vingti&eacute;miste, de Philippe Alb&egrave;ra &agrave; Elena Ungeheuer, d&rsquo;Angelo Orcalli &agrave; Richard Toop. L&rsquo;ouvrage, compos&eacute; de deux tomes d&rsquo;environ 900 pages chacun, est paru aux &eacute;ditions Sym&eacute;trie fin 2013.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">Analyse des pratiques musicales</a>.</p>", "content_fr": "<p>Ce projet &eacute;ditorial commenc&eacute; en 2003 visait &agrave; publier un panorama substantiel des principales th&eacute;ories compositionnelles du XX<sup>e</sup> si&egrave;cle. Alors que certains corpus th&eacute;oriques ont &eacute;t&eacute; largement diffus&eacute;s et comment&eacute;s (Schoenberg, Xenakis, Boulez, Stockhausen...), d&rsquo;autres, tout aussi importants pour l&rsquo;histoire et l&rsquo;esth&eacute;tique musicales, restent mal connus faute d&rsquo;introductions synth&eacute;tiques disponibles. Musiciens et musicologues ne disposaient pas, &agrave; ce jour, d&rsquo;un ouvrage de r&eacute;f&eacute;rence sur la relation f&eacute;conde entre composition et th&eacute;orie au cours du si&egrave;cle pass&eacute;.</p>\r\n<p>Pourtant, la f&eacute;condit&eacute; de cette relation a &eacute;t&eacute; d&eacute;terminante dans le d&eacute;veloppement de la musique contemporaine, et notamment de l&rsquo;informatique musicale. Croisant musicologie historique, ex&eacute;g&egrave;se des corpus th&eacute;oriques et analyse musicale, l&rsquo;ouvrage dirig&eacute; par N. Donin et L. Feneyrou comble le manque actuel d&rsquo;une publication collective de r&eacute;f&eacute;rence sur les th&eacute;ories compositionnelles d&rsquo;un si&egrave;cle caract&eacute;ris&eacute; par l&rsquo;abondance des &eacute;crits de cr&eacute;ateurs, des recherches sur les syst&egrave;mes de composition, et des manifestes esth&eacute;tiques d&eacute;finissant techniques et technologies musicales.</p>\r\n<p>Une soixantaine de sp&eacute;cialistes internationaux a &eacute;t&eacute; r&eacute;unie pour traiter, d&rsquo;une part, des th&eacute;ories compositionnelles sp&eacute;cifiques d&rsquo;individus (ou d&rsquo;&eacute;coles), de Schoenberg &agrave; Rihm en passant par Hindemith ou Carter ; d&rsquo;autre part, des cat&eacute;gories et probl&eacute;matiques ayant &eacute;merg&eacute; au long du si&egrave;cle, telles que : &laquo; musique algorithmique &raquo;, &laquo; live electronics &raquo;, &laquo; th&eacute;&acirc;tre musical &raquo;, &laquo; spectralisme &raquo;, etc. De nombreux corpus inconnus en langue fran&ccedil;aise, et parfois in&eacute;dits, sont pr&eacute;sents aux c&ocirc;t&eacute;s de th&eacute;matiques mieux explor&eacute;es par la musicologie au cours des quarante derni&egrave;res ann&eacute;es.</p>\r\n<p>Les contributions proposent un expos&eacute; synth&eacute;tique, &agrave; la fois technique et historique, de ces notions et/ou doctrines, en se basant &agrave; chaque fois sur l&rsquo;&eacute;tat actuel des connaissances &agrave; propos des articles, manifestes, etc., des compositeurs &eacute;tudi&eacute;s. Les participants, par leur diversit&eacute;, refl&egrave;tent les diff&eacute;rents aspects de la musicologie vingti&eacute;miste, de Philippe Alb&egrave;ra &agrave; Elena Ungeheuer, d&rsquo;Angelo Orcalli &agrave; Richard Toop. L&rsquo;ouvrage, compos&eacute; de deux tomes d&rsquo;environ 900 pages chacun, est paru aux &eacute;ditions Sym&eacute;trie fin 2013.</p>\r\n<p>&Eacute;quipes Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">Analyse des pratiques musicales</a>.</p>", "content_en": "<p>This editorial project began in 2003 and aims to publish a substantial panorama of the main compositional theories of the 20th century. While certain theoretical corpora have been broadly published and commentated (e.g. Schoenberg, Xenakis, Boulez, Stockhausen), others, just as important <br />for history and the musical aesthetic, remain relatively unknown due to a lack of available introductory texts. Today, neither musicians nor musicologists have a comprehensive reference source on the fertile relationship between composition and theory during the last century.</p>\r\n<p>Even so, the fertility of this relationship was a determining factor in the development of contemporary music, and particularly of computer-music. Crossing historical musicology, discourse analysis and musical analysis, the book edited by N. Donin and L. Feneyrou will fill the current void with a collective reference publication on the compositional theories of past century&mdash;a century characterized by a profusion of writings by artists, aesthetic manifests defining musical techniques and technologies, and research carried out on compositional systems.</p>\r\n<p>Sixty international specialists have come together to treat, on one hand, compositional theories specific to an individual or a school&mdash;from Schoenberg to Hindemith to Carter to Rihm &mdash;and on the other hand, the categories and problems that surfaced throughout the century such as algorithmic music, musical theater, live electronics, or spectralism. Theoretical corpora unknown in French, sometimes unpublished, are presented alongside the most widely explored themes by musicologists during the past 40 years.</p>\r\n<p>The contributions offer a synthetic presentation, both technical and historical, of these notions and/ or doctrines, based on the most current knowledge about the articles, manifests, etc. on the composers studied. The level of diversity of the participants reflects different aspects of 20th century musicology, from Philippe Alb&egrave;ra to Elena Ungeheuer, from Angelo Orcalli to Richard Toop. &Eacute;ditions Sym&eacute;trie published this two 900-page volume work in 2013.</p>\r\n<p>IRCAM's Teams: <a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">Analysis of Musical Practices team.</a></p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6], "organizations": [2, 159, 1, 158], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 65, "fields": {"keywords_string": "", "site": 1, "title": "Outils de publication multim\u00e9dia pour la musicologie", "title_fr": "Outils de publication multim\u00e9dia pour la musicologie", "title_en": "Multimedia Publication Tools for Musicology", "slug": "outils-de-publication-multimedia-pour-la-musicologie", "_meta_title": "", "description": "Standardisation des formats originaux de publication multim\u00e9dia sur la musique", "description_fr": "Standardisation des formats originaux de publication multim\u00e9dia sur la musique", "description_en": "Standardize the original formats of multimedia publications on music", "gen_description": false, "created": "2016-09-09T09:51:30.477Z", "updated": "2018-06-29T10:24:59.485Z", "status": 2, "publish_date": "2016-09-09T09:51:30Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Cette recherche visait &agrave; exp&eacute;rimenter et, dans certains cas, standardiser des formats originaux de publication multim&eacute;dia sur la musique. On peut dire que n&rsquo;importe quel discours analytique sur la musique contient, en soi, un fort potentiel de &laquo; multim&eacute;dia &raquo; puisqu&rsquo;il comprend un texte (le commentaire verbal) et des pointeurs vers des donn&eacute;es musicales (citations d&rsquo;exemples musicaux, r&eacute;f&eacute;rences &agrave; des mouvements ou des passages des &oelig;uvres, etc.). Pourtant, paradoxalement, ce n&rsquo;est que r&eacute;cemment que les musicologues se sont int&eacute;ress&eacute;s aux nouvelles possibilit&eacute;s expressives de la publication multim&eacute;dia (en ligne et sur support), jusqu&rsquo;alors limit&eacute;es aux publications de CD-Rom &eacute;ducatifs et culturels.</p>\r\n<h2>Description des travaux</h2>\r\n<p>Pour contribuer &agrave; ce mouvement, nous avons proc&eacute;d&eacute; &agrave; une d&eacute;marche en deux temps.</p>\r\n<p>D&rsquo;abord, l&rsquo;exp&eacute;rimentation consistant &agrave; r&eacute;aliser diverses analyses musicologiques dans un environnement multim&eacute;dia, en sp&eacute;cifiant au fur et &agrave; mesure cet environnement en fonction des &eacute;tapes de la d&eacute;marche analytique. Cette activit&eacute; d&rsquo;exp&eacute;rimentation se concr&eacute;tise, d&rsquo;une part, par le d&eacute;veloppement d&rsquo;outils d&rsquo;analyse en collaboration avec des musicologues (par ex. &laquo; Charting the Score, outil de mise en tableau de partition &raquo;, en collaboration avec Jonathan Goldman) ; d&rsquo;autre part, par la publication de documents multim&eacute;dia, sur DvD-Rom (tels ceux joints &agrave; <em>L&rsquo;inou&iuml;</em>, revue de l&rsquo;Ircam en 2005 et 2006) et dans des revues en ligne telles que <em>DEMeter</em> (universit&eacute; de Lille-3) ou <em>Musim&eacute;diane</em> &ndash; revue audiovisuelle et multim&eacute;dia d&rsquo;analyse musicale.</p>\r\n<p>Ensuite, par un processus de comparaison et d&rsquo;abstraction, nous avons proc&eacute;d&eacute; &agrave; la formalisation des op&eacute;rations analytiques mises en jeu. Ceci a permis de standardiser des formats de publication utilisant le texte, le son et l&rsquo;image &ndash; non seulement pour les besoins sp&eacute;cifiques des musicologues <br />mais aussi pour des modalit&eacute;s voisines de publication sur la musique, propres aux projets institutionnels de l&rsquo;Ircam (refonte de la base de donn&eacute;es Brahms, constitution du R&eacute;pertoire Ircam, documentation logicielle).</p>\r\n<p>Les enjeux rel&egrave;vent du g&eacute;nie documentaire : utiliser un format bien d&eacute;fini (pour faciliter le traitement des donn&eacute;es) mais cependant pas trop contraignant pour les auteurs ; pouvoir int&eacute;grer des exemples musicaux visuels et sonores ; rendre possible plusieurs types de publication (sur le web, sous <br />forme de CD-Rom ou DvD-Rom, mais aussi en version papier). Pour ce faire, et &eacute;tant donn&eacute; la quantit&eacute; de commandes impliqu&eacute;es par ces projets, il est impossible de compter sur une mise en forme manuelle des donn&eacute;es fournies par les auteurs pour chaque publication. Il faut donc passer par un outil d&eacute;di&eacute; &agrave; ces types de publication et int&eacute;grant les contraintes pr&eacute;c&eacute;demment &eacute;num&eacute;r&eacute;es. C&rsquo;&eacute;tait l&rsquo;objet de notre participation au projet RIAM Ecoute (&laquo; Environnement auteur pour l&rsquo;&eacute;coute musicale instrument&eacute;e, la gestion des archives sonores et leur publication multisupport&nbsp; &raquo;) et au projet RNTL Scenariplatform.</p>\r\n<p>L&rsquo;ensemble de cette d&eacute;marche a d&rsquo;ores et d&eacute;j&agrave; permis d&rsquo;&eacute;tablir un format de publication pour l&rsquo;analyse musicale, exp&eacute;riment&eacute; au d&eacute;part dans une maquette de cours en ligne pour le projet europ&eacute;en MusicWeb (2003), puis dans une publication scientifique sur l&rsquo;analyse d&rsquo;interpr&eacute;tation (2005) et, enfin, formalis&eacute; lors de la conception d&rsquo;une s&eacute;rie de CD-Roms associ&eacute;e au projet Musique Lab2 (2006-2007) dans le cadre d&rsquo;un accord entre l&rsquo;Ircam et la r&eacute;gion Provence-Alpes-C&ocirc;te d&rsquo;Azur. Les CD-Roms r&eacute;alis&eacute;s, portant, l&rsquo;un sur <em>Les Variations</em> op. 27 de Webern, l&rsquo;autre sur <em>Voi(rex)</em> de P. Leroux, proposent deux niveaux de lecture de l&rsquo;&oelig;uvre :</p>\r\n<ul>\r\n<li>Le premier introduit l&rsquo;&oelig;uvre en donnant &agrave; lire la partition au fil de l&rsquo;&eacute;coute, enrichi de quelques &eacute;l&eacute;ments contextuels en cours de lecture ;</li>\r\n<li>Le second propose plusieurs points analytiques sur l&rsquo;&oelig;uvre, dont chacun pointe, au moyen de lien hyperm&eacute;dia, vers des passages clefs de la partition annot&eacute;e par l&rsquo;auteur au moyen du logiciel Musique Lab annotation. L&rsquo;int&eacute;gralit&eacute; du contenu est produite par l&rsquo;auteur lui-m&ecirc;me &agrave; l&rsquo;aide de l&rsquo;outil auteur Scenari-CHAIN et de la suite logicielle Musique Lab.</li>\r\n</ul>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">Analyse des pratiques musicales</a>.</p>", "content_fr": "<p>Cette recherche visait &agrave; exp&eacute;rimenter et, dans certains cas, standardiser des formats originaux de publication multim&eacute;dia sur la musique. On peut dire que n&rsquo;importe quel discours analytique sur la musique contient, en soi, un fort potentiel de &laquo; multim&eacute;dia &raquo; puisqu&rsquo;il comprend un texte (le commentaire verbal) et des pointeurs vers des donn&eacute;es musicales (citations d&rsquo;exemples musicaux, r&eacute;f&eacute;rences &agrave; des mouvements ou des passages des &oelig;uvres, etc.). Pourtant, paradoxalement, ce n&rsquo;est que r&eacute;cemment que les musicologues se sont int&eacute;ress&eacute;s aux nouvelles possibilit&eacute;s expressives de la publication multim&eacute;dia (en ligne et sur support), jusqu&rsquo;alors limit&eacute;es aux publications de CD-Rom &eacute;ducatifs et culturels.</p>\r\n<h2>Description des travaux</h2>\r\n<p>Pour contribuer &agrave; ce mouvement, nous avons proc&eacute;d&eacute; &agrave; une d&eacute;marche en deux temps.</p>\r\n<p>D&rsquo;abord, l&rsquo;exp&eacute;rimentation consistant &agrave; r&eacute;aliser diverses analyses musicologiques dans un environnement multim&eacute;dia, en sp&eacute;cifiant au fur et &agrave; mesure cet environnement en fonction des &eacute;tapes de la d&eacute;marche analytique. Cette activit&eacute; d&rsquo;exp&eacute;rimentation se concr&eacute;tise, d&rsquo;une part, par le d&eacute;veloppement d&rsquo;outils d&rsquo;analyse en collaboration avec des musicologues (par ex. &laquo; Charting the Score, outil de mise en tableau de partition &raquo;, en collaboration avec Jonathan Goldman) ; d&rsquo;autre part, par la publication de documents multim&eacute;dia, sur DvD-Rom (tels ceux joints &agrave; <em>L&rsquo;inou&iuml;</em>, revue de l&rsquo;Ircam en 2005 et 2006) et dans des revues en ligne telles que <em>DEMeter</em> (universit&eacute; de Lille-3) ou <em>Musim&eacute;diane</em> &ndash; revue audiovisuelle et multim&eacute;dia d&rsquo;analyse musicale.</p>\r\n<p>Ensuite, par un processus de comparaison et d&rsquo;abstraction, nous avons proc&eacute;d&eacute; &agrave; la formalisation des op&eacute;rations analytiques mises en jeu. Ceci a permis de standardiser des formats de publication utilisant le texte, le son et l&rsquo;image &ndash; non seulement pour les besoins sp&eacute;cifiques des musicologues <br />mais aussi pour des modalit&eacute;s voisines de publication sur la musique, propres aux projets institutionnels de l&rsquo;Ircam (refonte de la base de donn&eacute;es Brahms, constitution du R&eacute;pertoire Ircam, documentation logicielle).</p>\r\n<p>Les enjeux rel&egrave;vent du g&eacute;nie documentaire : utiliser un format bien d&eacute;fini (pour faciliter le traitement des donn&eacute;es) mais cependant pas trop contraignant pour les auteurs ; pouvoir int&eacute;grer des exemples musicaux visuels et sonores ; rendre possible plusieurs types de publication (sur le web, sous <br />forme de CD-Rom ou DvD-Rom, mais aussi en version papier). Pour ce faire, et &eacute;tant donn&eacute; la quantit&eacute; de commandes impliqu&eacute;es par ces projets, il est impossible de compter sur une mise en forme manuelle des donn&eacute;es fournies par les auteurs pour chaque publication. Il faut donc passer par un outil d&eacute;di&eacute; &agrave; ces types de publication et int&eacute;grant les contraintes pr&eacute;c&eacute;demment &eacute;num&eacute;r&eacute;es. C&rsquo;&eacute;tait l&rsquo;objet de notre participation au projet RIAM Ecoute (&laquo; Environnement auteur pour l&rsquo;&eacute;coute musicale instrument&eacute;e, la gestion des archives sonores et leur publication multisupport&nbsp; &raquo;) et au projet RNTL Scenariplatform.</p>\r\n<p>L&rsquo;ensemble de cette d&eacute;marche a d&rsquo;ores et d&eacute;j&agrave; permis d&rsquo;&eacute;tablir un format de publication pour l&rsquo;analyse musicale, exp&eacute;riment&eacute; au d&eacute;part dans une maquette de cours en ligne pour le projet europ&eacute;en MusicWeb (2003), puis dans une publication scientifique sur l&rsquo;analyse d&rsquo;interpr&eacute;tation (2005) et, enfin, formalis&eacute; lors de la conception d&rsquo;une s&eacute;rie de CD-Roms associ&eacute;e au projet Musique Lab2 (2006-2007) dans le cadre d&rsquo;un accord entre l&rsquo;Ircam et la r&eacute;gion Provence-Alpes-C&ocirc;te d&rsquo;Azur. Les CD-Roms r&eacute;alis&eacute;s, portant, l&rsquo;un sur <em>Les Variations</em> op. 27 de Webern, l&rsquo;autre sur <em>Voi(rex)</em> de P. Leroux, proposent deux niveaux de lecture de l&rsquo;&oelig;uvre :</p>\r\n<ul>\r\n<li>Le premier introduit l&rsquo;&oelig;uvre en donnant &agrave; lire la partition au fil de l&rsquo;&eacute;coute, enrichi de quelques &eacute;l&eacute;ments contextuels en cours de lecture ;</li>\r\n<li>Le second propose plusieurs points analytiques sur l&rsquo;&oelig;uvre, dont chacun pointe, au moyen de lien hyperm&eacute;dia, vers des passages clefs de la partition annot&eacute;e par l&rsquo;auteur au moyen du logiciel Musique Lab annotation. L&rsquo;int&eacute;gralit&eacute; du contenu est produite par l&rsquo;auteur lui-m&ecirc;me &agrave; l&rsquo;aide de l&rsquo;outil auteur Scenari-CHAIN et de la suite logicielle Musique Lab.</li>\r\n</ul>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">Analyse des pratiques musicales</a>.</p>", "content_en": "<p>This work aims to experiment with, and in some cases, standardize the original formats of multimedia publications on music. One can argue that any analytic discourse on music contains a potential &lsquo;multimedia&rsquo; aspect, as it includes a text (the oral commentary) and indicators for musical information (e.g. citations of musical examples, references to movements or passages in a work, etc.). Even so, it is not until recently that musicologists became interested in the new expressive possibilities of multimedia publication, online and on other physical supports that were limited to educational and cultural CD-ROMs until recently.</p>\r\n<h2>Project Description</h2>\r\n<p>We have begun a two-step process in order to contribute to this process.</p>\r\n<p>Firstly, the experimentation carried out consists of producing various musicological analyses in a multimedia environment, specifying as we go along the environment chosen according to the steps carried out in the analysis. This experimentation materializes itself via the development of analysis tools developed in collaboration with musicologists (e.g. Charting the Score: A Tool for \"Segmented Listening\" in collaboration with Jonathan Goldman) and also through the publication of multimedia documents, on DvD-ROM (such as those included in <em>the Inou&iuml;</em>, the IRCAM 2005 and 2006 journal) and in online magazines such as <em>DEMeter</em> (Universit&eacute; de Lille-3) or <em>Musim&eacute;diane</em>&mdash;an audiovisual and multimedia music analysis journal.</p>\r\n<p>Secondly, using a process of comparison and abstraction we will carry out a formalization of the analytic operations brought into play. This enables standardization of publication formats using text, sound, and image&mdash;not only for the specific needs of musicologists, but also for disciplines that are close to music publication found within the institutional projects carried out at IRCAM (e.g. the revamping of the Brahms database, the creation of the IRCAM repertoire, software documentation).</p>\r\n<p>The issues are those of documenting: using a well-defined format (to facilitate the processing of the information) but one that is not overly restrictive for others; joining visual and sonorous musical excerpts together; making several types of publication possible (online, a CD-ROM, a DvD-ROM, paper). In order to do this, and given the sheer number of commands involved by these projects, it is unfeasible to depend on a manual layout of the data provided by authors for each publication.&nbsp; A tool dedicated to these types of publications must be used to integrate the aforementioned constraints. This was the focus of our participation in ECOUTE (Authoring environment for instrumental music listening, sound archive management, and multi-support publication) supported by the RIAM program and the RNTL Scenariplatform project.</p>\r\n<p>The sum of these actions has already made it possible to establish a publication format for musical analysis. This format was first tested in a model of online classes for the European project MusicWeb in 2003 and in a scientific publication on the analysis of a performance in 2005. The format was finally formalized with the production of a series of CD-ROMs associated with the Musique Lab 2 project featuring <em>the variationen</em> op. 27 by Webern and <em>Voi(rex)</em> by Philippe Leroux (2006-2007) as a part of an agreement between IRCAM and the Provence Alpes C&ocirc;te-d&rsquo;Azur region. These CD-ROMs offered two different ways to address the work:</p>\r\n<ul>\r\n<li>The first introduces the work by letting the user read the score as they are listening. The score was annotated with a few contextual elements.</li>\r\n<li>The second offers several analytic points of view on the work. Each position leads, via a hypermedia link, to key passages in the score annotated by the author via the Musique Lab Annotation software program. The contents were produced entirely by the author using the Scenari-CHAIN authoring tool and the Musique Lab software package.</li>\r\n</ul>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-de-recherches/analyse-des-pratiques-musicales/\">Analysis of Musical Practices team.</a></p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 67, "fields": {"keywords_string": "", "site": 1, "title": "MuTeC", "title_fr": "MuTeC", "title_en": "MuTeC", "slug": "mutec", "_meta_title": "", "description": "Musicologie des techniques de composition contemporaines", "description_fr": "Musicologie des techniques de composition contemporaines", "description_en": "Musicology and Techniques of Contemporary Composition", "gen_description": false, "created": "2016-09-09T10:06:17.107Z", "updated": "2018-07-25T14:47:55.025Z", "status": 2, "publish_date": "2016-09-09T10:06:17Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet vise &agrave; documenter et interroger la sp&eacute;cificit&eacute; d&rsquo;un ensemble de techniques de composition caract&eacute;ristiques de la musique contemporaine, par l&rsquo;&eacute;tude approfondie et coordonn&eacute;e de plusieurs processus cr&eacute;ateurs repr&eacute;sentatifs de la musique des XX<sup>e</sup> et XXI<sup>e</sup> si&egrave;cles, document&eacute;s au moyen d&rsquo;archives de l&rsquo;activit&eacute; cr&eacute;atrice (esquisses, brouillons, etc.) et/ou d&rsquo;entretiens approfondis avec les compositeurs (pour les compositeurs en activit&eacute;). La m&eacute;thode et les r&eacute;f&eacute;rences du programme sont &agrave; la crois&eacute;e de plusieurs domaines disciplinaires compl&eacute;mentaires : musicologie, critique g&eacute;n&eacute;tique (au sens de la gen&egrave;se d&rsquo;une &oelig;uvre), sciences cognitives. Le projet d&eacute;veloppe notamment une m&eacute;thodologie innovante bas&eacute;e sur la notion de &laquo; remise en situation de composition &raquo;. Les diff&eacute;rents processus cr&eacute;ateurs s&eacute;lectionn&eacute;s s&rsquo;&eacute;chelonnent sur une p&eacute;riode d&rsquo;une soixantaine d&rsquo;ann&eacute;es, du milieu du XX<sup>e </sup>si&egrave;cle jusqu&rsquo;aux &oelig;uvres les plus r&eacute;centes : musique de film pour Cartier-Bresson par Koechlin, <em>Pli selon pli</em> de Boulez, <em>Requiem pour un jeune po&egrave;te</em> de Zimmermann, <em>Les espaces acoustiques</em> de Grisey, <em>Traiettoria</em> de Stroppa, <em>Trei II</em> de Jarrell, <em>L&rsquo;Esprit des Dunes</em> de Murail, projet de &laquo; Jardin sonore &raquo; par J.-L. Herv&eacute;, <em>Gramigna</em> de S. Gervasoni. Chacun a pris en compte une technologie sp&eacute;cifique : montage d&rsquo;enregistrements sonores, musique mixte avec sons de synth&egrave;se, installation sonore avec traitement temps r&eacute;el, etc.</p>\r\n<p>L&rsquo;&eacute;tude empirique de l&rsquo;interaction entre un projet artistique et ses outils techniques permettent : d&rsquo;&eacute;clairer sous un jour nouveau un ensemble d&rsquo;&oelig;uvres de r&eacute;f&eacute;rence de la musique contemporaine ; de mieux comprendre la relation entre dispositifs techniques et cr&eacute;ativit&eacute; ; de mettre en &eacute;vidence de fa&ccedil;on plus g&eacute;n&eacute;rale certains traits caract&eacute;ristiques de la cognition musicale &agrave; travers une analyse approfondie de l&rsquo;une de ses formes &agrave; la fois les plus expertes et les moins &eacute;tudi&eacute;es. Le programme a organis&eacute;, &agrave; l&rsquo;&eacute;chelle de ses trois ann&eacute;es de travaux, la circulation de notions et de th&egrave;mes d&rsquo;analyse transverses au travers de ses cas d&rsquo;&eacute;tude (ou &laquo; terrains &raquo;) constitutifs. Cette circulation a &eacute;t&eacute; facilit&eacute;e par a conception et l&rsquo;usage d&rsquo;une plateforme informatique partag&eacute;e (d&eacute;velopp&eacute;e dans l&rsquo;&eacute;quipe sur la base d&rsquo;un prototype pr&eacute;existant de &laquo; navigation g&eacute;n&eacute;tique &raquo; dans une &oelig;uvre musicale) permettant la num&eacute;risation des diff&eacute;rents corpus g&eacute;n&eacute;tiques et la navigation hyperm&eacute;dia au sein de ces corpus, y compris leur annotation et la variation de leurs modalit&eacute;s de repr&eacute;sentation.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-08-CREA-066-01.</p>", "content_fr": "<p>Ce projet vise &agrave; documenter et interroger la sp&eacute;cificit&eacute; d&rsquo;un ensemble de techniques de composition caract&eacute;ristiques de la musique contemporaine, par l&rsquo;&eacute;tude approfondie et coordonn&eacute;e de plusieurs processus cr&eacute;ateurs repr&eacute;sentatifs de la musique des XX<sup>e</sup> et XXI<sup>e</sup> si&egrave;cles, document&eacute;s au moyen d&rsquo;archives de l&rsquo;activit&eacute; cr&eacute;atrice (esquisses, brouillons, etc.) et/ou d&rsquo;entretiens approfondis avec les compositeurs (pour les compositeurs en activit&eacute;). La m&eacute;thode et les r&eacute;f&eacute;rences du programme sont &agrave; la crois&eacute;e de plusieurs domaines disciplinaires compl&eacute;mentaires : musicologie, critique g&eacute;n&eacute;tique (au sens de la gen&egrave;se d&rsquo;une &oelig;uvre), sciences cognitives. Le projet d&eacute;veloppe notamment une m&eacute;thodologie innovante bas&eacute;e sur la notion de &laquo; remise en situation de composition &raquo;. Les diff&eacute;rents processus cr&eacute;ateurs s&eacute;lectionn&eacute;s s&rsquo;&eacute;chelonnent sur une p&eacute;riode d&rsquo;une soixantaine d&rsquo;ann&eacute;es, du milieu du XX<sup>e </sup>si&egrave;cle jusqu&rsquo;aux &oelig;uvres les plus r&eacute;centes : musique de film pour Cartier-Bresson par Koechlin, <em>Pli selon pli</em> de Boulez, <em>Requiem pour un jeune po&egrave;te</em> de Zimmermann, <em>Les espaces acoustiques</em> de Grisey, <em>Traiettoria</em> de Stroppa, <em>Trei II</em> de Jarrell, <em>L&rsquo;Esprit des Dunes</em> de Murail, projet de &laquo; Jardin sonore &raquo; par J.-L. Herv&eacute;, <em>Gramigna</em> de S. Gervasoni. Chacun a pris en compte une technologie sp&eacute;cifique : montage d&rsquo;enregistrements sonores, musique mixte avec sons de synth&egrave;se, installation sonore avec traitement temps r&eacute;el, etc.</p>\r\n<p>L&rsquo;&eacute;tude empirique de l&rsquo;interaction entre un projet artistique et ses outils techniques permettent : d&rsquo;&eacute;clairer sous un jour nouveau un ensemble d&rsquo;&oelig;uvres de r&eacute;f&eacute;rence de la musique contemporaine ; de mieux comprendre la relation entre dispositifs techniques et cr&eacute;ativit&eacute; ; de mettre en &eacute;vidence de fa&ccedil;on plus g&eacute;n&eacute;rale certains traits caract&eacute;ristiques de la cognition musicale &agrave; travers une analyse approfondie de l&rsquo;une de ses formes &agrave; la fois les plus expertes et les moins &eacute;tudi&eacute;es. Le programme a organis&eacute;, &agrave; l&rsquo;&eacute;chelle de ses trois ann&eacute;es de travaux, la circulation de notions et de th&egrave;mes d&rsquo;analyse transverses au travers de ses cas d&rsquo;&eacute;tude (ou &laquo; terrains &raquo;) constitutifs. Cette circulation a &eacute;t&eacute; facilit&eacute;e par a conception et l&rsquo;usage d&rsquo;une plateforme informatique partag&eacute;e (d&eacute;velopp&eacute;e dans l&rsquo;&eacute;quipe sur la base d&rsquo;un prototype pr&eacute;existant de &laquo; navigation g&eacute;n&eacute;tique &raquo; dans une &oelig;uvre musicale) permettant la num&eacute;risation des diff&eacute;rents corpus g&eacute;n&eacute;tiques et la navigation hyperm&eacute;dia au sein de ces corpus, y compris leur annotation et la variation de leurs modalit&eacute;s de repr&eacute;sentation.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-08-CREA-066-01.</p>", "content_en": "<p>This project aimed to document and question the specificity of a set of modern compositional techniques, via a thorough and coordinated study of several creative processes representative of the music of 20th and 21st centuries, documented through archives of the creative process (sketches, drafts, etc.) and/or in- depth interviews with the composers (for practicing composers). The method and the references of the program have roots in a range of complementary disciplines: musicology, genetic criticism (in relation to the genesis of a work), and cognitive sciences. The project develops a pioneering methodology based on the concept of \"reenactment of the activity of composition\".nThe different creative processes selected cover a period of about 60 years, from the mid-20th century to contemporary works: music for a film for Cartier-Bresson by koechlin, <em>Pli selon pli</em> by Boulez, <em>Requiem pour un jeune po&egrave;te</em> by Zimmermann, <em>Les espaces acoustiques</em> by Grisey, <em>Traiettoria</em> by Stroppa, <em>Trei II</em> by Jarrell, <em>L&rsquo;Esprit des Dunes</em> by Murail, a recent sound garden project by J.L. Herv&eacute;, and work in progress, <em>Gramigna</em>, by Gervasoni. Each work uses a specific technology such as a montage of sound recordings, music mixed with synthesized sounds, or a sound installation with real-time treatments. The empirical study of interaction between an artistic project and its technical tools makes it possible: to understand differently a group of works that are references for contemporary music, to better understand the relationship between technical systems and creativity, to shed light on certain characteristic traits of musical cognition via an in-depth analysis of one of its forms that demands the highest level of expertise; a form that is seldom researched.</p>\r\n<p>The program organized the circulation of the notions and themes of transversal analysis through consecutive case studies. This circulation was facilitated through the design and use of a shared computer platform (developed by the team, based on a preexisting prototype of \"genetic navigation\" within a musical work) that enabled the digitization of different genetic corpora and hypermedia browsing within these corpora, including their annotation and variations in their forms of representation.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-08-CREA-066-01.</p>", "date_from": "2008-12-01", "date_to": "2011-12-31", "user": null, "type": "external", "external_id": "ANR-08-CREA-066-01", "program": 1, "program_type": 4, "call": 26, "lead_team": null, "lead_organization": 1, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6], "organizations": [164, 163, 165], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 68, "fields": {"keywords_string": "", "site": 1, "title": "Gamelan", "title_fr": "Gamelan", "title_en": "Gamelan", "slug": "gamelan", "_meta_title": "", "description": "Environnement pour la Gestion et l'Archivage de la Musique Et de L'Audio Num\u00e9riques", "description_fr": "Environnement pour la Gestion et l'Archivage de la Musique Et de L'Audio Num\u00e9riques", "description_en": "An environment for the management and archiving of music and digital audio content", "gen_description": false, "created": "2016-09-09T10:12:20.563Z", "updated": "2018-07-25T14:38:26.526Z", "status": 2, "publish_date": "2016-09-09T10:12:20Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les environnements de production sonore et musicale sont compos&eacute;s de nombreux outils destin&eacute;s au fa&ccedil;onnage et &agrave; l&rsquo;assemblage de sons. qu&rsquo;il s&rsquo;agisse de musique classique, contemporaine, &eacute;lectroacoustique, &eacute;lectronique ou vari&eacute;t&eacute;s, chaque production doit g&eacute;rer un nombre tr&egrave;s important d&rsquo;&eacute;chantillons sonores faisant intervenir une diversit&eacute; d&rsquo;outils destin&eacute;s &agrave; la cr&eacute;ation, la modification ou l&rsquo;enrichissement des sons. Il est habituel dans un contexte de production, de trouver des outils de toutes sortes : outils d&rsquo;enregistrements, outils de &laquo; nettoyage &raquo; du son, banques d&rsquo;&eacute;chantillons, outils de traitement, outils de synth&egrave;se sonore, s&eacute;quenceurs, biblioth&egrave;ques d&rsquo;effets audio, outils de synchronisation, mixage... auxquels il faut ajouter les outils sp&eacute;cifiques &agrave; la production musicale (partitions...).</p>\r\n<p>Les objectifs du projet se situaient donc sur quatre niveaux :</p>\r\n<ul>\r\n<li><strong>Environnements de production</strong><br />Garder la trace de toutes les actions, depuis le mat&eacute;riel de d&eacute;part au produit fini (par exemple : cette action sur ce fichier a produit tel autre nouveau fichier) ; organiser les &eacute;l&eacute;ments intervenant dans la production (fichiers, logiciels) dans des structures pr&eacute;d&eacute;termin&eacute;es par l&rsquo;utilisateur et les inclure comme composantes de l&rsquo;environnement. Formaliser la connaissance g&eacute;n&eacute;r&eacute;e lors du processus. L&rsquo;objectif applicatif est de travailler avec n&rsquo;importe quel logiciel de production commercial et d&rsquo;agir sur l&rsquo;environnement dans lequel ces logiciels sont utilis&eacute;s.</li>\r\n<li><strong>Strat&eacute;gies de pr&eacute;servation</strong><br />Utiliser l&rsquo;environnement de production comme une plate-forme pour la pr&eacute;servation, extraire les structures et les connaissances qui vont permettre de simplifier l&rsquo;acc&egrave;s futur &agrave; l&rsquo;environnement. Appliquer des m&eacute;thodologies de type OAIS permettant une r&eacute;utilisation de l&rsquo;environnement et ses composantes.</li>\r\n<li><strong>R&eacute;utilisation des productions</strong><br />Restructurer le mat&eacute;riel de production en fonction de nouveaux objectifs, additionner d&rsquo;autres mat&eacute;riaux et modifier les liens et la structure globale. Utiliser des sous-parties de l&rsquo;environnement pour g&eacute;n&eacute;rer de nouveaux environnements. D&eacute;construction et reconstruction de processus pour une analyse des intentions.</li>\r\n<li><strong>Gestion de droits</strong> <br />Permettre la tra&ccedil;abilit&eacute; des contenus lors d&rsquo;une production pour g&eacute;rer les droits d&rsquo;utilisation.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2009-CORD-011-01.</p>", "content_fr": "<p>Les environnements de production sonore et musicale sont compos&eacute;s de nombreux outils destin&eacute;s au fa&ccedil;onnage et &agrave; l&rsquo;assemblage de sons. qu&rsquo;il s&rsquo;agisse de musique classique, contemporaine, &eacute;lectroacoustique, &eacute;lectronique ou vari&eacute;t&eacute;s, chaque production doit g&eacute;rer un nombre tr&egrave;s important d&rsquo;&eacute;chantillons sonores faisant intervenir une diversit&eacute; d&rsquo;outils destin&eacute;s &agrave; la cr&eacute;ation, la modification ou l&rsquo;enrichissement des sons. Il est habituel dans un contexte de production, de trouver des outils de toutes sortes : outils d&rsquo;enregistrements, outils de &laquo; nettoyage &raquo; du son, banques d&rsquo;&eacute;chantillons, outils de traitement, outils de synth&egrave;se sonore, s&eacute;quenceurs, biblioth&egrave;ques d&rsquo;effets audio, outils de synchronisation, mixage... auxquels il faut ajouter les outils sp&eacute;cifiques &agrave; la production musicale (partitions...).</p>\r\n<p>Les objectifs du projet se situaient donc sur quatre niveaux :</p>\r\n<ul>\r\n<li><strong>Environnements de production</strong><br />Garder la trace de toutes les actions, depuis le mat&eacute;riel de d&eacute;part au produit fini (par exemple : cette action sur ce fichier a produit tel autre nouveau fichier) ; organiser les &eacute;l&eacute;ments intervenant dans la production (fichiers, logiciels) dans des structures pr&eacute;d&eacute;termin&eacute;es par l&rsquo;utilisateur et les inclure comme composantes de l&rsquo;environnement. Formaliser la connaissance g&eacute;n&eacute;r&eacute;e lors du processus. L&rsquo;objectif applicatif est de travailler avec n&rsquo;importe quel logiciel de production commercial et d&rsquo;agir sur l&rsquo;environnement dans lequel ces logiciels sont utilis&eacute;s.</li>\r\n<li><strong>Strat&eacute;gies de pr&eacute;servation</strong><br />Utiliser l&rsquo;environnement de production comme une plate-forme pour la pr&eacute;servation, extraire les structures et les connaissances qui vont permettre de simplifier l&rsquo;acc&egrave;s futur &agrave; l&rsquo;environnement. Appliquer des m&eacute;thodologies de type OAIS permettant une r&eacute;utilisation de l&rsquo;environnement et ses composantes.</li>\r\n<li><strong>R&eacute;utilisation des productions</strong><br />Restructurer le mat&eacute;riel de production en fonction de nouveaux objectifs, additionner d&rsquo;autres mat&eacute;riaux et modifier les liens et la structure globale. Utiliser des sous-parties de l&rsquo;environnement pour g&eacute;n&eacute;rer de nouveaux environnements. D&eacute;construction et reconstruction de processus pour une analyse des intentions.</li>\r\n<li><strong>Gestion de droits</strong> <br />Permettre la tra&ccedil;abilit&eacute; des contenus lors d&rsquo;une production pour g&eacute;rer les droits d&rsquo;utilisation.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2009-CORD-011-01.</p>", "content_en": "<p>The existing environments for sound and musical production consist of several tools designed for making and putting together sounds. Be it classical, contemporary, electroacoustic, electronic, or pop music, each production manages a large number of sound samples and uses a broad range of tools for the creation, modification, or embellishment of sounds. In a production setting, it is not unusual to find a variety of tools: recording tools, tools to &lsquo;clean&rsquo; the sound, sound banks, processing tools, tools for sound synthesis, sequencers, audio effect libraries, tools for synchronization and mixing, in addition to all the other tools that are specific to a given production such as the score.</p>\r\n<p>This project had four main objectives:</p>\r\n<ul>\r\n<li><strong>Production Environments</strong><br />Follow all your actions from the source material to the finished product (e.g. action &lsquo;x&rsquo; carried out on file &lsquo;y&rsquo; created a new file) and organize the elements that intervene in a production (files, software) in structures predetermined by the user including them in the environment&rsquo;s components. Formalize the knowledge created during the production process. The application objective is to be able to work with any production software on the market and work with the environment whenever any of these programs are used.</li>\r\n<li><strong>Preservation Strategies</strong><br />Utilize the production environment like a platform for archiving, extracting structures and knowledge that simplify future access to the environment. Apply OAIS methodologies that let future users use the environment and its components.</li>\r\n<li><strong>Reusing Productions</strong><br />Restructure production material with new objectives in mind, add other material and modify the connections found in the global structure. Use parts of the environment to generate new environments. Deconstruction and reconstruction of processes to analyze the intentions.</li>\r\n<li><strong>Copyright Management</strong><br />Enable a traceability of the contents during a production to manage the copyrights.</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference : ANR-2009-CORD-011-01.</p>", "date_from": "2009-12-01", "date_to": "2013-10-31", "user": null, "type": "external", "external_id": "ANR-2009-CORD-011-01", "program": 1, "program_type": 1, "call": 10, "lead_team": null, "lead_organization": 1, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [10, 16], "organizations": [167, 50, 166], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 69, "fields": {"keywords_string": "", "site": 1, "title": "Astree", "title_fr": "Astree", "title_en": "Astree", "slug": "astree", "_meta_title": "", "description": "Analyse et synth\u00e8se de traitements temps r\u00e9el", "description_fr": "Analyse et synth\u00e8se de traitements temps r\u00e9el", "description_en": "Analysis and Synthesis of Real-Time Sound Processing", "gen_description": false, "created": "2016-09-09T10:16:05.380Z", "updated": "2018-06-29T12:51:50.911Z", "status": 1, "publish_date": "2016-09-09T10:16:05Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Astree avait deux objectifs majeurs &agrave; long terme : une plateforme linguistique et une base de constitution de connaissances. Le projet Astree visait &agrave; d&eacute;velopper une plate-forme linguistique commune aux diff&eacute;rents syst&egrave;mes utilis&eacute;s dans la cr&eacute;ation num&eacute;rique musicale contemporaine, sans imposer aux cr&eacute;ateurs de changement de plate-forme &ndash; du moins dans l&rsquo;imm&eacute;diat.</p>\r\n<p>En effet, le projet devait cr&eacute;er une cha&icirc;ne de traitement compl&egrave;te &agrave; partir des expressions originelles &ndash; de la transformation de l&rsquo;expression originale &agrave; son analyse, sa repr&eacute;sentation en langage Faust (langage d&eacute;velopp&eacute; par le Grame depuis 2000), la g&eacute;n&eacute;ration d&rsquo;une documentation de qualit&eacute; normalis&eacute;e, et la constitution de connaissances sur ces traitements. Il n&rsquo;existait pas alors de telle plate-forme linguistique commune, malgr&eacute; des tentatives isol&eacute;es de syst&egrave;mes de transformation (de Max vers PureData ou inversement, par exemple), des tentatives de plateformes telles que celles d&eacute;velopp&eacute;es par le projet Integra.</p>", "content_fr": "<p>Le projet Astree avait deux objectifs majeurs &agrave; long terme : une plateforme linguistique et une base de constitution de connaissances. Le projet Astree visait &agrave; d&eacute;velopper une plate-forme linguistique commune aux diff&eacute;rents syst&egrave;mes utilis&eacute;s dans la cr&eacute;ation num&eacute;rique musicale contemporaine, sans imposer aux cr&eacute;ateurs de changement de plate-forme &ndash; du moins dans l&rsquo;imm&eacute;diat.</p>\r\n<p>En effet, le projet devait cr&eacute;er une cha&icirc;ne de traitement compl&egrave;te &agrave; partir des expressions originelles &ndash; de la transformation de l&rsquo;expression originale &agrave; son analyse, sa repr&eacute;sentation en langage Faust (langage d&eacute;velopp&eacute; par le Grame depuis 2000), la g&eacute;n&eacute;ration d&rsquo;une documentation de qualit&eacute; normalis&eacute;e, et la constitution de connaissances sur ces traitements. Il n&rsquo;existait pas alors de telle plate-forme linguistique commune, malgr&eacute; des tentatives isol&eacute;es de syst&egrave;mes de transformation (de Max vers PureData ou inversement, par exemple), des tentatives de plateformes telles que celles d&eacute;velopp&eacute;es par le projet Integra.</p>", "content_en": "<p>The Astree project had two long-term goals: the creation of a linguistic platform and of a knowledge base.The Astree project aspired to develop a linguistic platform that is common to various systems used in contemporary computer music creation, without forcing artists to change platforms - in the near future, at least. The project attempts to create a complete signal processing chain that includes original expressions, the transformation of the original expression, its analysis, its representation in Faust language (a language developed by GRAME since 2000), the generation of a documentation of a standardized quality, and the constitution of a knowledge base on these processes.</p>\r\n<p>Today, there is no such linguistic platform, although a few remote attempts have been made to create transformation systems (e.g. from Max/MSP to PureData, or the reverse) or platforms such as the ones developed during the Integra project.</p>", "date_from": "2008-12-01", "date_to": "2011-06-30", "user": null, "type": "external", "external_id": "ANR-2008-CORD-003-01", "program": 1, "program_type": 1, "call": null, "lead_team": null, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [10, 16], "organizations": [168, 138, 169], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 70, "fields": {"keywords_string": "", "site": 1, "title": "Cream", "title_fr": "Cream", "title_en": "Cream", "slug": "cream", "_meta_title": "", "description": "Cracking the Emotional Code of Music", "description_fr": "Cracking the Emotional Code of Music", "description_en": "Cracking the Emotional Code of Music", "gen_description": false, "created": "2016-09-09T10:20:13.738Z", "updated": "2018-06-29T09:38:59.139Z", "status": 2, "publish_date": "2016-09-09T10:20:13Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet CREAM se donne pour objectif de produire les technologies et les connaissances permettant de caract&eacute;riser pr&eacute;cis&eacute;ment quel type de signal musical est capable de d&eacute;clencher quel type de m&eacute;canisme c&eacute;r&eacute;bral d&rsquo;induction &eacute;motionnelle.</p>\r\n<p>La recherche en cognition musicale jusqu&rsquo;&agrave; pr&eacute;sent repose principalement sur des corr&eacute;lations effectu&eacute;es entre des r&eacute;actions &eacute;motionnelles relativement indistinctes et des stimuli musicaux peu contr&ocirc;l&eacute;s : on sait que la musique peut cr&eacute;er des &eacute;motions, mais on ne sait pas comment. Le projet CREAM propose de combiner les m&eacute;thodes actuelles de neurosciences avec un tr&egrave;s haut niveau de technicit&eacute; de traitement du signal, pour fabriquer, pour la premi&egrave;re fois, des stimuli musicaux capable d&rsquo;activer ou d&rsquo;inhiber s&eacute;lectivement certains des circuits corticaux impliqu&eacute;s dans le traitement &eacute;motionnel, afin de les &eacute;tudier en isolation. Par ex, nous proposons de cibler les centres d&rsquo;interpr&eacute;tation de la prosodie de la parole en construisant des sons musicaux qui &laquo; tremblent &raquo; comme une voix anxieuse ou &laquo; exultent &raquo; comme une voix joyeuse.</p>\r\n<p>Ces nouvelles techniques de contr&ocirc;le exp&eacute;rimental permettront d&rsquo;&eacute;tendre notre compr&eacute;hension actuelle des m&eacute;canismes c&eacute;r&eacute;braux d&rsquo;induction &eacute;motionnelle, mais aussi de concevoir de nombreuses applications cliniques de th&eacute;rapie ou de diagnostic dans le cadre de la d&eacute;pression ou des maladies neuro-d&eacute;g&eacute;n&eacute;ratives. En d&rsquo;autres termes, le projet CREAM fera de la musique une v&eacute;ritable technologie clinique capable de mobiliser des circuits neuronaux de fa&ccedil;on cibl&eacute;e, non-intrusive et non-pharmacologique.</p>", "content_fr": "<p>Le projet CREAM se donne pour objectif de produire les technologies et les connaissances permettant de caract&eacute;riser pr&eacute;cis&eacute;ment quel type de signal musical est capable de d&eacute;clencher quel type de m&eacute;canisme c&eacute;r&eacute;bral d&rsquo;induction &eacute;motionnelle.</p>\r\n<p>La recherche en cognition musicale jusqu&rsquo;&agrave; pr&eacute;sent repose principalement sur des corr&eacute;lations effectu&eacute;es entre des r&eacute;actions &eacute;motionnelles relativement indistinctes et des stimuli musicaux peu contr&ocirc;l&eacute;s : on sait que la musique peut cr&eacute;er des &eacute;motions, mais on ne sait pas comment. Le projet CREAM propose de combiner les m&eacute;thodes actuelles de neurosciences avec un tr&egrave;s haut niveau de technicit&eacute; de traitement du signal, pour fabriquer, pour la premi&egrave;re fois, des stimuli musicaux capable d&rsquo;activer ou d&rsquo;inhiber s&eacute;lectivement certains des circuits corticaux impliqu&eacute;s dans le traitement &eacute;motionnel, afin de les &eacute;tudier en isolation. Par ex, nous proposons de cibler les centres d&rsquo;interpr&eacute;tation de la prosodie de la parole en construisant des sons musicaux qui &laquo; tremblent &raquo; comme une voix anxieuse ou &laquo; exultent &raquo; comme une voix joyeuse.</p>\r\n<p>Ces nouvelles techniques de contr&ocirc;le exp&eacute;rimental permettront d&rsquo;&eacute;tendre notre compr&eacute;hension actuelle des m&eacute;canismes c&eacute;r&eacute;braux d&rsquo;induction &eacute;motionnelle, mais aussi de concevoir de nombreuses applications cliniques de th&eacute;rapie ou de diagnostic dans le cadre de la d&eacute;pression ou des maladies neuro-d&eacute;g&eacute;n&eacute;ratives. En d&rsquo;autres termes, le projet CREAM fera de la musique une v&eacute;ritable technologie clinique capable de mobiliser des circuits neuronaux de fa&ccedil;on cibl&eacute;e, non-intrusive et non-pharmacologique.</p>", "content_en": "<p>The CREAM project&rsquo;s objective is to produce technology and knowledge that make it possible to characterize which type of musical signal sets off which type of brain mechanism of emotional induction.</p>\r\n<p>Until now, research in musical cognition has focused on correlations between relatively indistinct emotional reactions and loosely controlled musical stimuli: we know that music creates emotions, but we do not know how. The CREAM project suggests combining current neuroscience methods with a high technical level of signal processing to create, for the first time, musical stimuli capable of selectively causing or inhibiting certain cortical circuits involved in emotional processing so they may be studied in isolation. For example, we will suggest targeting centers of interpretation of prosody and speech by constructing musical sounds that \"tremble\" like an anxious voice or that \"rejoice\" like a happy voice.</p>\r\n<p>These new experimental control techniques make it possible to expand our current understand of brain mechanisms of emotional induction, but also to conceive several clinical applications for therapy or diagnosis of depression or neurodegenerative illnesses. In other words, the CREAM project will turn music into a real clinical technology capable of stimulating specific neuronal circuits in a non-intrusive and non-pharmacological manner.</p>", "date_from": "2014-10-01", "date_to": "2019-09-30", "user": null, "type": "external", "external_id": "335536", "program": null, "program_type": 21, "call": 3, "lead_team": null, "lead_organization": 425, "website": "http://cream.ircam.fr/", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [170], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 72, "fields": {"keywords_string": "", "site": 1, "title": "MouVie", "title_fr": "MouVie", "title_en": "MouVie", "slug": "mouvie", "_meta_title": "", "description": "Mobilit\u00e9 et qualit\u00e9 de vie en milieu urbain", "description_fr": "Mobilit\u00e9 et qualit\u00e9 de vie en milieu urbain", "description_en": "Mobility and Quality of Life in Urban Areas", "gen_description": false, "created": "2016-09-09T10:43:48.364Z", "updated": "2018-06-29T10:25:16.870Z", "status": 2, "publish_date": "2016-09-09T10:43:48Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<h2>L&rsquo;interaction des pollutions atmosph&eacute;rique et acoustique sur la sant&eacute; des populations citadines</h2>\r\n<p>La chaire sur la mobilit&eacute; &amp; qualit&eacute; de vie en milieu urbain va mesurer les impacts de la pollution par les gaz, les particules et le bruit sur la qualit&eacute; de vie et la sant&eacute; des habitants d&rsquo;une ville. Confront&eacute;s &agrave; cet enjeu soci&eacute;tal, les constructeurs automobiles PSA Peugeot Citro&euml;n et Renault ont pris toute la mesure de la n&eacute;cessit&eacute; de soutenir le projet de recherche en m&eacute;c&eacute;nat que l&rsquo;UPMC m&egrave;ne avec l&rsquo;Inserm, le Laboratoire Atmosph&egrave;re, Milieux, Observations Spatiales (LATMOS), l&rsquo;OSU Ecce Terra, l&rsquo;Institut Jean-le-Rond-d&rsquo;Alembert et l&rsquo;Ircam. &laquo; En prenant en compte les multiples facteurs de la pollution chimique de l&rsquo;air mais aussi des sources de pollution non conventionnelles comme le bruit, la chaire semble pouvoir apporter &agrave; la notion d&rsquo;environnement urbain une nouvelle dimension... &raquo; commente Laurence Eymard, titulaire de la chaire.</p>\r\n<h2>Une &eacute;quipe d&rsquo;experts pluridisciplinaires engag&eacute;e dans une dynamique de recherche commune</h2>\r\n<p>&Agrave; la t&ecirc;te d&rsquo;une &eacute;quipe pluridisciplinaire d&rsquo;experts en acoustique, en qualit&eacute; de l&rsquo;air et en sant&eacute;, Laurence Eymard anime une communaut&eacute; scientifique de plus de 1 000 personnes sp&eacute;cialis&eacute;es dans les sciences du syst&egrave;me Terre et de l&rsquo;environnement, de la biodiversit&eacute; &agrave; la sant&eacute;, de la Terre profonde &agrave; la plan&eacute;tologie et au climat. R&eacute;gis Marchiano, professeur &agrave; l&rsquo;UPMC, travaille sur la propagation des ondes acoustiques lin&eacute;aires et non lin&eacute;aires en milieux complexes &agrave; l&rsquo;Institut Jean le Rond d&rsquo;Alembert UPMC/CNRS. Nicolas Misdariis est responsable-adjoint de l&rsquo;&eacute;quipe &laquo; <a href=\"/recherche/equipes-de-recherches/perception-et-design-sonores/\">Perception et design sonores</a> &raquo; de l&rsquo;Ircam. Les recherches de S&eacute;bastien Payan, professeur des universit&eacute;s &agrave; l&rsquo;UPMC et chercheur au LATMOS, IPSL/UvSq/UPMC/IPSL s&rsquo;articulent autour de plusieurs axes &agrave; l&rsquo;interface entre la physique mol&eacute;culaire et la physique de l&rsquo;atmosph&egrave;re. C&ocirc;t&eacute; sant&eacute;, Isabella Annesi Maesano, responsable de l&rsquo;&eacute;quipe Epid&eacute;miologie des maladies allergiques et respiratoires (EPAR, INSERM/UPMC), m&egrave;ne des travaux de recherche sur la compr&eacute;hension de l&rsquo;&eacute;tiologie de la rhinite, l&rsquo;asthme, la broncho-pneumopathie chronique obstructive et identifie les sujets &agrave; risque. Annick Cl&eacute;ment, professeur de p&eacute;diatrie &agrave; l&rsquo;UPMC, dirige le service de pneumologie p&eacute;diatrique de l&rsquo;h&ocirc;pital Trousseau. Elle anime au niveau europ&eacute;en un groupe de recherche sur les pathologies pulmonaires rares de l&rsquo;enfant et si&egrave;ge dans de nombreux conseils scientifiques en France et &agrave; l&rsquo;&eacute;tranger.</p>\r\n<h2>Des enjeux majeurs pour les entreprises m&eacute;c&egrave;nes de cette nouvelle chaire</h2>\r\n<p>Sylvain Allano, directeur scientifique et technologies futures de PSA Peugeot Citroen : &laquo; Le cadre d&rsquo;une chaire de m&eacute;c&eacute;nat nous a sembl&eacute; particuli&egrave;rement appropri&eacute; pour promouvoir des recherches pluridisciplinaires de haut niveau scientifique dans des domaines &agrave; forte dimension soci&eacute;tale, comme ceux de la qualit&eacute; de l&rsquo;air et des nuisances sonores. En effet, les r&eacute;sultats de ces recherches devraient contribuer &agrave; fournir des bases scientifiques solides et reconnues qui manquent souvent dans les d&eacute;bats soci&eacute;taux et environnementaux. &raquo; R&eacute;mi Bastien, directeur engineering innovation de Renault : &laquo; La soci&eacute;t&eacute; a des attentes fortes pour que la mobilit&eacute;, qui est &agrave; la fois une n&eacute;cessit&eacute; et une libert&eacute; fondamentale, puisse contribuer &agrave; une meilleure qualit&eacute; de vie, sp&eacute;cialement en milieu urbain. Les formes de mobilit&eacute;s actuelles portent en elles des nuisances de moins en moins acceptables. En tant qu&rsquo;industriels, nous faisons partie du probl&egrave;me et voulons &ecirc;tre acteurs de la solution. La meilleure fa&ccedil;on d&rsquo;y r&eacute;pondre est de coop&eacute;rer avec des scientifiques pluridisciplinaires de haut niveau et cette nouvelle chaire est pour nous une opportunit&eacute; unique de pr&eacute;parer des solutions durables et fiables appuy&eacute;es sur une expertise scientifique approfondie. &raquo; Claire Martin, directrice de la responsabilit&eacute; sociale des entreprises (RSE) et de la Fondation Renault : &laquo; Plus les impacts seront compris dans leur complexit&eacute;, plus les pouvoirs publics et les industriels seront en mesure d&rsquo;y apporter des r&eacute;ponses pertinentes. Par ailleurs, il est l&eacute;gitime et n&eacute;cessaire de toujours chercher &agrave; mieux analyser la r&eacute;alit&eacute; des ph&eacute;nom&egrave;nes dans leurs dimensions techniques, &eacute;conomiques, sociales, sanitaires... pour formuler vis-&agrave;-vis de tous les publics des messages clairs et objectifs &raquo;.</p>", "content_fr": "<h2>L&rsquo;interaction des pollutions atmosph&eacute;rique et acoustique sur la sant&eacute; des populations citadines</h2>\r\n<p>La chaire sur la mobilit&eacute; &amp; qualit&eacute; de vie en milieu urbain va mesurer les impacts de la pollution par les gaz, les particules et le bruit sur la qualit&eacute; de vie et la sant&eacute; des habitants d&rsquo;une ville. Confront&eacute;s &agrave; cet enjeu soci&eacute;tal, les constructeurs automobiles PSA Peugeot Citro&euml;n et Renault ont pris toute la mesure de la n&eacute;cessit&eacute; de soutenir le projet de recherche en m&eacute;c&eacute;nat que l&rsquo;UPMC m&egrave;ne avec l&rsquo;Inserm, le Laboratoire Atmosph&egrave;re, Milieux, Observations Spatiales (LATMOS), l&rsquo;OSU Ecce Terra, l&rsquo;Institut Jean-le-Rond-d&rsquo;Alembert et l&rsquo;Ircam. &laquo; En prenant en compte les multiples facteurs de la pollution chimique de l&rsquo;air mais aussi des sources de pollution non conventionnelles comme le bruit, la chaire semble pouvoir apporter &agrave; la notion d&rsquo;environnement urbain une nouvelle dimension... &raquo; commente Laurence Eymard, titulaire de la chaire.</p>\r\n<h2>Une &eacute;quipe d&rsquo;experts pluridisciplinaires engag&eacute;e dans une dynamique de recherche commune</h2>\r\n<p>&Agrave; la t&ecirc;te d&rsquo;une &eacute;quipe pluridisciplinaire d&rsquo;experts en acoustique, en qualit&eacute; de l&rsquo;air et en sant&eacute;, Laurence Eymard anime une communaut&eacute; scientifique de plus de 1 000 personnes sp&eacute;cialis&eacute;es dans les sciences du syst&egrave;me Terre et de l&rsquo;environnement, de la biodiversit&eacute; &agrave; la sant&eacute;, de la Terre profonde &agrave; la plan&eacute;tologie et au climat. R&eacute;gis Marchiano, professeur &agrave; l&rsquo;UPMC, travaille sur la propagation des ondes acoustiques lin&eacute;aires et non lin&eacute;aires en milieux complexes &agrave; l&rsquo;Institut Jean le Rond d&rsquo;Alembert UPMC/CNRS. Nicolas Misdariis est responsable-adjoint de l&rsquo;&eacute;quipe &laquo; <a href=\"/recherche/equipes-de-recherches/perception-et-design-sonores/\">Perception et design sonores</a> &raquo; de l&rsquo;Ircam. Les recherches de S&eacute;bastien Payan, professeur des universit&eacute;s &agrave; l&rsquo;UPMC et chercheur au LATMOS, IPSL/UvSq/UPMC/IPSL s&rsquo;articulent autour de plusieurs axes &agrave; l&rsquo;interface entre la physique mol&eacute;culaire et la physique de l&rsquo;atmosph&egrave;re. C&ocirc;t&eacute; sant&eacute;, Isabella Annesi Maesano, responsable de l&rsquo;&eacute;quipe Epid&eacute;miologie des maladies allergiques et respiratoires (EPAR, INSERM/UPMC), m&egrave;ne des travaux de recherche sur la compr&eacute;hension de l&rsquo;&eacute;tiologie de la rhinite, l&rsquo;asthme, la broncho-pneumopathie chronique obstructive et identifie les sujets &agrave; risque. Annick Cl&eacute;ment, professeur de p&eacute;diatrie &agrave; l&rsquo;UPMC, dirige le service de pneumologie p&eacute;diatrique de l&rsquo;h&ocirc;pital Trousseau. Elle anime au niveau europ&eacute;en un groupe de recherche sur les pathologies pulmonaires rares de l&rsquo;enfant et si&egrave;ge dans de nombreux conseils scientifiques en France et &agrave; l&rsquo;&eacute;tranger.</p>\r\n<h2>Des enjeux majeurs pour les entreprises m&eacute;c&egrave;nes de cette nouvelle chaire</h2>\r\n<p>Sylvain Allano, directeur scientifique et technologies futures de PSA Peugeot Citroen : &laquo; Le cadre d&rsquo;une chaire de m&eacute;c&eacute;nat nous a sembl&eacute; particuli&egrave;rement appropri&eacute; pour promouvoir des recherches pluridisciplinaires de haut niveau scientifique dans des domaines &agrave; forte dimension soci&eacute;tale, comme ceux de la qualit&eacute; de l&rsquo;air et des nuisances sonores. En effet, les r&eacute;sultats de ces recherches devraient contribuer &agrave; fournir des bases scientifiques solides et reconnues qui manquent souvent dans les d&eacute;bats soci&eacute;taux et environnementaux. &raquo; R&eacute;mi Bastien, directeur engineering innovation de Renault : &laquo; La soci&eacute;t&eacute; a des attentes fortes pour que la mobilit&eacute;, qui est &agrave; la fois une n&eacute;cessit&eacute; et une libert&eacute; fondamentale, puisse contribuer &agrave; une meilleure qualit&eacute; de vie, sp&eacute;cialement en milieu urbain. Les formes de mobilit&eacute;s actuelles portent en elles des nuisances de moins en moins acceptables. En tant qu&rsquo;industriels, nous faisons partie du probl&egrave;me et voulons &ecirc;tre acteurs de la solution. La meilleure fa&ccedil;on d&rsquo;y r&eacute;pondre est de coop&eacute;rer avec des scientifiques pluridisciplinaires de haut niveau et cette nouvelle chaire est pour nous une opportunit&eacute; unique de pr&eacute;parer des solutions durables et fiables appuy&eacute;es sur une expertise scientifique approfondie. &raquo; Claire Martin, directrice de la responsabilit&eacute; sociale des entreprises (RSE) et de la Fondation Renault : &laquo; Plus les impacts seront compris dans leur complexit&eacute;, plus les pouvoirs publics et les industriels seront en mesure d&rsquo;y apporter des r&eacute;ponses pertinentes. Par ailleurs, il est l&eacute;gitime et n&eacute;cessaire de toujours chercher &agrave; mieux analyser la r&eacute;alit&eacute; des ph&eacute;nom&egrave;nes dans leurs dimensions techniques, &eacute;conomiques, sociales, sanitaires... pour formuler vis-&agrave;-vis de tous les publics des messages clairs et objectifs &raquo;.</p>", "content_en": "<h2>The Impact of Atmospheric and noise Pollution on the Health of Urban Populations</h2>\r\n<p>The chair in mobility and quality of life in urban areas will measure the impacts of pollution by gases, particles and noise on the quality of life and health of the residents of a city. In response to this societal issue, the car manufacturers PSA Peugeot Citro&euml;n and Renault have realized the importance <br />of supporting the sponsored research project that UPMC is running together with France&rsquo;s Institute of Health and Medical Research (INSERM), Atmosphere, Media and Spatial Observation Laboratory (LATMOS), Ecce Terra, the Jean le Rond d&rsquo;Alembert Institute and the Institute for Acoustics and Music Research and Coordination (IRCAM). \"By taking the many factors involved in chemical air pollution into account, as well as unconventional sources of pollution such as noise, the chair can bring a new dimension to the concept of the urban environment, which may be promising for the future,\" commented Laurence Eymard, Chair.</p>\r\n<h2>An Inter-disciplinary Research Team of Experts</h2>\r\n<p>A chair headed by Laurence Eymard, coordinating an inter-disciplinary team of experts in acoustics, air quality and health. Laurence Eymard will coordinate a scientific community of more than 1,000 people specialized in earth system and environmental sciences, ranging from biodiversity to health, and from deep-earth science to planetary science, via climatology. R&eacute;gis Marchiano, a professor at UPMC, works on linear and non-linear acoustic wave propagation in complex media at the UPMC/CNRS Jean le Rond d&rsquo;Alembert Institute. Nicolas Misdariis is joint head of the <a href=\"/recherche/equipes-de-recherches/perception-et-design-sonores/\">Sound Perception and Design team</a> at the Institute for Acoustics and Music Research and Coordination (IRCAM). S&eacute;bastien Payan, professor at UPMC and a research fellow at LATMOS, researches various issues on the boundary between molecular physics and atmospheric physics. In health, Isabella Annesi-Maesano, head of the INSERM/UPMC Epidemiology of Allergic and Respiratory Diseases team, runs research projects to understand the etiology of rhinitis, asthma, chronic obstructive broncho-pneumopathy, and identify subjects at risk. Annick Cl&eacute;ment, professor of pediatric pneumology at UPMC, runs the pediatric pneumology ward at Trousseau Hospital. She also coordinates a European research group on rare lung diseases in children and sits on numerous scientific boards in France and around the world.</p>\r\n<h2>Major Issues for Private-Sector Sponsors of the new Chair</h2>\r\n<p>Sylvain Allano, Scientific and Future Technology Director at PSA Peugeot Citroen: \"We thought a sponsored chair was an appropriate way to support high-quality inter-disciplinary research in areas with a strong societal dimension, such as air quality and noise pollution. The research results should provide the kind of solid, recognized scientific basis that often is missing from societal and environmental debates.\" R&eacute;mi Bastien, Head of Innovation Engineering at Renault: \"Society expects mobility, which is both a necessity and a fundamental freedom, to contribute to a higher quality of life, especially in urban areas. Current forms of mobility have increasingly unacceptable impacts. As manufacturers, we are part of the problem, so we want to be part of the solution. The best way is to cooperate with high-level inter-disciplinary scientists. The new chair offers us a unique opportunity to <br />pave the way for sustainable, reliable solutions backed by in-depth scientific expertise.\" Claire Martin, vice President of CSR at Renault and Managing Director of the Renault Foundation: \"The better we understand impacts in their complexity, the more able the government and industry will be to develop appropriate responses. It is also legitimate and necessary to analyze the technical, economic, social, health and other aspects of phenomena in order to send clear, objective messages to all audiences.\"</p>", "date_from": "2014-04-01", "date_to": "2019-04-30", "user": null, "type": "external", "external_id": "", "program": 13, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [175, 8, 174, 173], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 73, "fields": {"keywords_string": "", "site": 1, "title": "Loudnat", "title_fr": "Loudnat", "title_en": "Loudnat", "slug": "loudnat", "_meta_title": "", "description": "Extension la validit\u00e9 de mod\u00e8les de sonie \u00e0 des sons de l\u2019environnement", "description_fr": "Extension la validit\u00e9 de mod\u00e8les de sonie \u00e0 des sons de l\u2019environnement", "description_en": "Expand the validity of loudness models to environmental sounds", "gen_description": false, "created": "2016-09-09T10:47:17.616Z", "updated": "2018-07-25T14:46:18.168Z", "status": 2, "publish_date": "2016-09-09T10:47:17Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La sonie (sensation de force sonore &ndash; loudness en anglais) est un caract&egrave;re fondamental de perception d&rsquo;un son. Des mod&egrave;les existent pour pr&eacute;dire cette sensation &agrave; partir de mesures effectu&eacute;es sur le signal sonore, mais ils sont limit&eacute;s &agrave; des cas particuliers de sons qui s&rsquo;&eacute;loignent des sons environnementaux (naturels).</p>\r\n<p>Ces restrictions limitent donc fortement l&rsquo;utilisation de ces mod&egrave;les pour mesurer la sonie des sons de l&rsquo;environnement dont les caract&eacute;ristiques acoustiques varient au cours du temps (par exemple, bruit de passage d&rsquo;un v&eacute;hicule).</p>\r\n<p>L&rsquo;impression globale de sonie d&rsquo;un auditeur d&eacute;pend alors du type de variation des caract&eacute;ristiques du son dont il faut tenir compte dans un mod&egrave;le pr&eacute;dictif. D&rsquo;autre part, la localisation de la source ainsi que l&rsquo;obstacle constitu&eacute; par le corps de l&rsquo;auditeur dans un contexte environnemental quotidien induisent des modifications du son et des diff&eacute;rences interaurales dont d&eacute;pend la sonie jug&eacute;e par un auditeur. Ces modifications sont aussi &agrave; prendre en compte dans un mod&egrave;le pr&eacute;dictif adapt&eacute; aux sons de l&rsquo;environnement.</p>\r\n<p>L&rsquo;objet de ce projet est donc d&rsquo;&eacute;tendre la validit&eacute; de mod&egrave;les de sonie &agrave; des sons de l&rsquo;environnement. L&rsquo;&eacute;tude consistera en des exp&eacute;riences psychoacoustiques visant &agrave; tester plusieurs hypoth&egrave;ses concernant des m&eacute;canismes perceptifs et cognitifs &agrave; prendre en compte pour modifier et adapter les mod&egrave;les de sonie existants.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR\u201011\u2010BS09\u2010016\u201003.</p>", "content_fr": "<p>La sonie (sensation de force sonore &ndash; loudness en anglais) est un caract&egrave;re fondamental de perception d&rsquo;un son. Des mod&egrave;les existent pour pr&eacute;dire cette sensation &agrave; partir de mesures effectu&eacute;es sur le signal sonore, mais ils sont limit&eacute;s &agrave; des cas particuliers de sons qui s&rsquo;&eacute;loignent des sons environnementaux (naturels).</p>\r\n<p>Ces restrictions limitent donc fortement l&rsquo;utilisation de ces mod&egrave;les pour mesurer la sonie des sons de l&rsquo;environnement dont les caract&eacute;ristiques acoustiques varient au cours du temps (par exemple, bruit de passage d&rsquo;un v&eacute;hicule).</p>\r\n<p>L&rsquo;impression globale de sonie d&rsquo;un auditeur d&eacute;pend alors du type de variation des caract&eacute;ristiques du son dont il faut tenir compte dans un mod&egrave;le pr&eacute;dictif. D&rsquo;autre part, la localisation de la source ainsi que l&rsquo;obstacle constitu&eacute; par le corps de l&rsquo;auditeur dans un contexte environnemental quotidien induisent des modifications du son et des diff&eacute;rences interaurales dont d&eacute;pend la sonie jug&eacute;e par un auditeur. Ces modifications sont aussi &agrave; prendre en compte dans un mod&egrave;le pr&eacute;dictif adapt&eacute; aux sons de l&rsquo;environnement.</p>\r\n<p>L&rsquo;objet de ce projet est donc d&rsquo;&eacute;tendre la validit&eacute; de mod&egrave;les de sonie &agrave; des sons de l&rsquo;environnement. L&rsquo;&eacute;tude consistera en des exp&eacute;riences psychoacoustiques visant &agrave; tester plusieurs hypoth&egrave;ses concernant des m&eacute;canismes perceptifs et cognitifs &agrave; prendre en compte pour modifier et adapter les mod&egrave;les de sonie existants.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR\u201011\u2010BS09\u2010016\u201003.</p>", "content_en": "<p>Loudness is a basic dimension of sound perception related to sound intensity. Models exist to predict this feeling based on measurements carried out on the sound signal, but they are limited to specific cases of sounds that are unrelated to natural environmental sounds.</p>\r\n<p>These restrictions consequently limit the use of these models to measure the loudness of environmental sounds that vary in time such as a passing car.</p>\r\n<p>The general impression of loudness for a listener therefore depends on the type of variation of the sound&rsquo;s characteristics that must be taken into account in a predictive model. Moreover, the localization of a sound source as well as the obstacle created by the listener&rsquo;s very body in an everyday situation lead to modifications of a sound and inter-aural differences which affect how loudness is judged by a listener. These modifications must also be taken into account in a predictive model adapted for environmental sounds.</p>\r\n<p>This project&rsquo;s goal is to expand the validity of loudness models to environmental sounds; the study consists of psychoacoustic experiments that will test several hypotheses concerning perceptive and cognitive mechanisms that must be taken into account to modify and adapt existing loudness models.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR\u201011\u2010BS09\u2010016\u201003.</p>", "date_from": "2011-11-01", "date_to": "2015-10-31", "user": null, "type": "external", "external_id": "ANR\u201011\u2010BS09\u2010016\u201003", "program": 1, "program_type": 2, "call": 16, "lead_team": null, "lead_organization": 320, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [6, 176], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 74, "fields": {"keywords_string": "", "site": 1, "title": "RoadSense", "title_fr": "RoadSense", "title_en": "RoadSense", "slug": "roadsense", "_meta_title": "", "description": "Projet de recherche industrielle qui vise \u00e0 concevoir une aide \u00e0 la conduite destin\u00e9e aux usagers motoris\u00e9s", "description_fr": "Projet de recherche industrielle qui vise \u00e0 concevoir une aide \u00e0 la conduite destin\u00e9e aux usagers motoris\u00e9s", "description_en": "Industrial research project that aims to design via experiments a system of assistance for drivers", "gen_description": false, "created": "2016-09-09T10:50:35.937Z", "updated": "2018-07-25T14:50:23.687Z", "status": 2, "publish_date": "2016-09-09T10:50:35Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>RoadSense est un projet de recherche industrielle qui vise &agrave; concevoir, &agrave; mettre en &oelig;uvre et &agrave; valider exp&eacute;rimentalement une aide &agrave; la conduite destin&eacute;e aux usagers motoris&eacute;s. Cette aide est fournie par une d&eacute;lin&eacute;ation par l&rsquo;infrastructure, produisant une alerte sonore et vibratoire au passage des roues. Cette aide est destin&eacute;e &agrave; alerter les conducteurs ayant une trajectoire al&eacute;atoire ou aberrante par rapport aux voies de circulation en rase campagne.</p>\r\n<p>Pour atteindre cet objectif le projet de recherche RoadSense vise &agrave;&nbsp; :</p>\r\n<ul>\r\n<li>Proposer un cadre d&rsquo;analyse fonctionnelle de la s&ucirc;ret&eacute; des voies de circulation &agrave; partir de l&rsquo;&eacute;tat de l&rsquo;art des connaissances et de l&rsquo;identification des enjeux et des m&eacute;canismes d&rsquo;accidents de la route en rase campagne ;</li>\r\n<li>Concevoir sur simulateur num&eacute;rique des signaux sonores pertinents, les impl&eacute;menter sur simulateur de conduite et sur banc physique, et exp&eacute;rimenter l&rsquo;efficacit&eacute; et l&rsquo;acceptabilit&eacute; d&rsquo;une &laquo;bande d&rsquo;&eacute;veil de vigilance &raquo; par d&eacute;limitation sonore de la voie de circulation ;</li>\r\n<li>R&eacute;aliser et exp&eacute;rimenter un nouveau syst&egrave;me d&rsquo;aide &agrave; la conduite &agrave; bas co&ucirc;t, rapidement g&eacute;n&eacute;ralisable et efficace pour l&rsquo;ensemble du parc des v&eacute;hicules existants sur routes d&eacute;partementales, nationales ou autoroutes par une validation graduelle in situ (sur piste puis sur route).</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2010-VPTT-010-02.</p>", "content_fr": "<p>RoadSense est un projet de recherche industrielle qui vise &agrave; concevoir, &agrave; mettre en &oelig;uvre et &agrave; valider exp&eacute;rimentalement une aide &agrave; la conduite destin&eacute;e aux usagers motoris&eacute;s. Cette aide est fournie par une d&eacute;lin&eacute;ation par l&rsquo;infrastructure, produisant une alerte sonore et vibratoire au passage des roues. Cette aide est destin&eacute;e &agrave; alerter les conducteurs ayant une trajectoire al&eacute;atoire ou aberrante par rapport aux voies de circulation en rase campagne.</p>\r\n<p>Pour atteindre cet objectif le projet de recherche RoadSense vise &agrave;&nbsp; :</p>\r\n<ul>\r\n<li>Proposer un cadre d&rsquo;analyse fonctionnelle de la s&ucirc;ret&eacute; des voies de circulation &agrave; partir de l&rsquo;&eacute;tat de l&rsquo;art des connaissances et de l&rsquo;identification des enjeux et des m&eacute;canismes d&rsquo;accidents de la route en rase campagne ;</li>\r\n<li>Concevoir sur simulateur num&eacute;rique des signaux sonores pertinents, les impl&eacute;menter sur simulateur de conduite et sur banc physique, et exp&eacute;rimenter l&rsquo;efficacit&eacute; et l&rsquo;acceptabilit&eacute; d&rsquo;une &laquo;bande d&rsquo;&eacute;veil de vigilance &raquo; par d&eacute;limitation sonore de la voie de circulation ;</li>\r\n<li>R&eacute;aliser et exp&eacute;rimenter un nouveau syst&egrave;me d&rsquo;aide &agrave; la conduite &agrave; bas co&ucirc;t, rapidement g&eacute;n&eacute;ralisable et efficace pour l&rsquo;ensemble du parc des v&eacute;hicules existants sur routes d&eacute;partementales, nationales ou autoroutes par une validation graduelle in situ (sur piste puis sur route).</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-2010-VPTT-010-02.</p>", "content_en": "<p>RoadSense is an industrial research project that aims to design, implement, and validate via experiments a system of assistance for drivers. This system consists of a delineation (rumble strips) that creates an alarm&mdash;a sound and vibrations&mdash; that is set off when the wheels pass a specific limit. This system is designed to alert drivers whose trajectory does not correspond with that of the road in the countryside.</p>\r\n<p>To reach this goal, the RoadSense project aims to:</p>\r\n<ul>\r\n<li>Propose a framework for the functional analysis of the security of roads using current knowledge, the identification of specific problems, and the circumstances surrounding accidents on rural roads.</li>\r\n<li>Design a digital simulator for relevant sound signals, implement them using a driving simulator and via physical tests, and test their effectiveness and acceptability of a \"vigilance rumble strip\" that uses sound delimitation of the roadway.</li>\r\n<li>Carry out and test a new, low-cost system of assistance for drivers. This system will be able to be applied quickly and will work with all existing vehicles on roads, from small country roads to highways, via a gradual validation process in situ (on closed tracks and then on roads).</li>\r\n</ul>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-2010-VPTT-010-02.</p>", "date_from": "2010-12-01", "date_to": "2013-11-30", "user": null, "type": "external", "external_id": "ANR-2010-VPTT-010-02", "program": 1, "program_type": 23, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [180, 177, 179, 178], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 75, "fields": {"keywords_string": "", "site": 1, "title": "Closed", "title_fr": "Closed", "title_en": "Closed", "slug": "closed", "_meta_title": "", "description": "Closing the Loop Of Sound Evaluation and Design", "description_fr": "Closing the Loop Of Sound Evaluation and Design", "description_en": "Closing the Loop Of Sound Evaluation and Design", "gen_description": false, "created": "2016-09-09T10:54:54.232Z", "updated": "2018-06-29T09:57:32.668Z", "status": 2, "publish_date": "2016-09-09T10:54:54Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet CLOSED a pour vocation de proposer une nouvelle approche du design sonore en termes d&rsquo;outils de cr&eacute;ation, de mesure et d&rsquo;&eacute;valuation des productions sonores dans le domaine du design des objets du quotidien. Elle s&rsquo;inscrit dans une d&eacute;marche plus large emprunt&eacute;e au domaine du design industriel et peut se repr&eacute;senter sch&eacute;matiquement de la mani&egrave;re suivante :</p>\r\n<p><img alt=\"\" src=\"/media/uploads/recherche/projets/illustration_projet_closed.jpg\" width=\"800\" height=\"360\" /></p>\r\n<p>De cette mani&egrave;re, le processus de design sonore est vu comme une boucle it&eacute;rative : une premi&egrave;re phase d&rsquo;analyse permet de d&eacute;gager des sp&eacute;cifications vis-&agrave;-vis des qualit&eacute;s/propri&eacute;t&eacute;s du son &agrave; r&eacute;aliser, la phase de cr&eacute;ation sonore s&rsquo;op&egrave;re &agrave; partir de ces connaissances pr&eacute;alables puis est valid&eacute;e sur la base des sp&eacute;cifications initiales ; le cas &eacute;ch&eacute;ant, la production est affin&eacute;e en repassant dans la boucle cr&eacute;ation/validation. &Agrave; l&rsquo;int&eacute;rieur de ce cadre, le projet est centr&eacute; sur l&rsquo;&eacute;laboration d&rsquo;outils de mesure reli&eacute;s aux aspects fonctionnels, esth&eacute;tiques et &eacute;motionnels du son, et ayant pour <br />vocation d&rsquo;&ecirc;tre utilis&eacute;s par les designers dans leurs processus de cr&eacute;ation.</p>\r\n<p>&Agrave; travers ces outils, le designer peut &agrave; la fois fa&ccedil;onner les sons d&rsquo;objets du quotidien et, dans le m&ecirc;me temps, &eacute;valuer le r&eacute;sultat de sa cr&eacute;ation. L&rsquo;outil d&rsquo;&eacute;valuation est compos&eacute; d&rsquo;un ensemble d&rsquo;indicateurs facilement interpr&eacute;tables en termes de fonctionnalit&eacute;, d&rsquo;esth&eacute;tique et de r&eacute;actions &eacute;motionnelles, qui sont associ&eacute;s &agrave; un contexte donn&eacute; d&rsquo;utilisation du produit. Ce projet a f&eacute;d&eacute;r&eacute; quatre laboratoires europ&eacute;ens qui ont articul&eacute; son contenu suivant quatre diff&eacute;rents axes :</p>\r\n<ul>\r\n<li>Synth&egrave;se sonore bas&eacute;e sur la mod&eacute;lisation d&rsquo;&eacute;v&eacute;nements physiques (solide, liquide...), le contr&ocirc;le de la synth&egrave;se par param&egrave;tres physiques et perceptifs orient&eacute;s vers le design interactif ;</li>\r\n<li>L&rsquo;&eacute;tude de la perception des sons environnementaux et de leur organisation perceptive et cognitive. Int&eacute;gration des aspects esth&eacute;tique et fonctionnel per&ccedil;us du son dans le processus de design, et &eacute;valuation de leur impact &eacute;motionnel ;</li>\r\n<li>&Eacute;tude des nouveaux usages du design sonore. &Eacute;laboration de principes d&rsquo;interaction sonore avec un objet en relation avec la perception et la cognition. &Eacute;laboration de sc&eacute;narios par la cr&eacute;ation de prototypes sonores favorisant les interactions entre un usager et un objet ;</li>\r\n<li>Techniques d&rsquo;apprentissage et de classification automatique des sons bas&eacute;es sur des mod&egrave;les physiologiques pour une &eacute;valuation automatique de l&rsquo;esth&eacute;tique, de la fonction et des aspects &eacute;motionnels du son int&eacute;gr&eacute;s dans le processus global du design sonore.</li>\r\n</ul>", "content_fr": "<p>Le projet CLOSED a pour vocation de proposer une nouvelle approche du design sonore en termes d&rsquo;outils de cr&eacute;ation, de mesure et d&rsquo;&eacute;valuation des productions sonores dans le domaine du design des objets du quotidien. Elle s&rsquo;inscrit dans une d&eacute;marche plus large emprunt&eacute;e au domaine du design industriel et peut se repr&eacute;senter sch&eacute;matiquement de la mani&egrave;re suivante :</p>\r\n<p><img alt=\"\" src=\"/media/uploads/recherche/projets/illustration_projet_closed.jpg\" width=\"800\" height=\"360\" /></p>\r\n<p>De cette mani&egrave;re, le processus de design sonore est vu comme une boucle it&eacute;rative : une premi&egrave;re phase d&rsquo;analyse permet de d&eacute;gager des sp&eacute;cifications vis-&agrave;-vis des qualit&eacute;s/propri&eacute;t&eacute;s du son &agrave; r&eacute;aliser, la phase de cr&eacute;ation sonore s&rsquo;op&egrave;re &agrave; partir de ces connaissances pr&eacute;alables puis est valid&eacute;e sur la base des sp&eacute;cifications initiales ; le cas &eacute;ch&eacute;ant, la production est affin&eacute;e en repassant dans la boucle cr&eacute;ation/validation. &Agrave; l&rsquo;int&eacute;rieur de ce cadre, le projet est centr&eacute; sur l&rsquo;&eacute;laboration d&rsquo;outils de mesure reli&eacute;s aux aspects fonctionnels, esth&eacute;tiques et &eacute;motionnels du son, et ayant pour <br />vocation d&rsquo;&ecirc;tre utilis&eacute;s par les designers dans leurs processus de cr&eacute;ation.</p>\r\n<p>&Agrave; travers ces outils, le designer peut &agrave; la fois fa&ccedil;onner les sons d&rsquo;objets du quotidien et, dans le m&ecirc;me temps, &eacute;valuer le r&eacute;sultat de sa cr&eacute;ation. L&rsquo;outil d&rsquo;&eacute;valuation est compos&eacute; d&rsquo;un ensemble d&rsquo;indicateurs facilement interpr&eacute;tables en termes de fonctionnalit&eacute;, d&rsquo;esth&eacute;tique et de r&eacute;actions &eacute;motionnelles, qui sont associ&eacute;s &agrave; un contexte donn&eacute; d&rsquo;utilisation du produit. Ce projet a f&eacute;d&eacute;r&eacute; quatre laboratoires europ&eacute;ens qui ont articul&eacute; son contenu suivant quatre diff&eacute;rents axes :</p>\r\n<ul>\r\n<li>Synth&egrave;se sonore bas&eacute;e sur la mod&eacute;lisation d&rsquo;&eacute;v&eacute;nements physiques (solide, liquide...), le contr&ocirc;le de la synth&egrave;se par param&egrave;tres physiques et perceptifs orient&eacute;s vers le design interactif ;</li>\r\n<li>L&rsquo;&eacute;tude de la perception des sons environnementaux et de leur organisation perceptive et cognitive. Int&eacute;gration des aspects esth&eacute;tique et fonctionnel per&ccedil;us du son dans le processus de design, et &eacute;valuation de leur impact &eacute;motionnel ;</li>\r\n<li>&Eacute;tude des nouveaux usages du design sonore. &Eacute;laboration de principes d&rsquo;interaction sonore avec un objet en relation avec la perception et la cognition. &Eacute;laboration de sc&eacute;narios par la cr&eacute;ation de prototypes sonores favorisant les interactions entre un usager et un objet ;</li>\r\n<li>Techniques d&rsquo;apprentissage et de classification automatique des sons bas&eacute;es sur des mod&egrave;les physiologiques pour une &eacute;valuation automatique de l&rsquo;esth&eacute;tique, de la fonction et des aspects &eacute;motionnels du son int&eacute;gr&eacute;s dans le processus global du design sonore.</li>\r\n</ul>", "content_en": "<p>The vocation of the Closed project is to offer a new approach to sound design for tools&mdash; for artistic, measurement, and assessment purposes&mdash;for the design of everyday objects. This project is part of the larger domain of industrial design and can be represented graphically as seen here:</p>\r\n<p><img alt=\"\" src=\"http://cri-dev01.ircam.fr:8020/media/uploads/recherche/projets/illustration_projet_closed.jpg\" width=\"800\" height=\"360\" /><br />The design process is seen as an iterative loop. The initial phase of analysis leads to the creation of specifications of the qualities of the sound to be produced. The creation phase uses these specifications that are then validated based on the initial specifications. If need be, the production is refined and passes again through the creation-evaluation loop. Closed focuses on the creation of tools for measurement destined to be used by designers in their creative processes.</p>\r\n<p>These tools are associated with functional, aesthetic, and emotional aspects of sound; the designer can shape the sounds of daily objects while assessing the results of their creation. The evaluation tool will be made up of a group of easily understood indicators measuring functional,&nbsp; aesthetic, and emotional responses that will be connected to a specific usage for the product. This project brings together four European laboratories and is structured around four principal domains:</p>\r\n<ul>\r\n<li>Sound synthesis based on a physical modeling approach (solid, liquid, etc.). Synthesis is controlled via physical and perceptive parameters oriented toward interactive design.</li>\r\n<li>Study of the perception of environmental sounds and their perceptive and cognitive organization. Integration of the aesthetic and functional aspects perceived in sound in the design process and assessment of their emotional impact.</li>\r\n<li>Study of new uses for sound design. Creation of principles of sound interaction of an object in relation to perception and cognition. Elaboration of scenarios via sound prototypes that promote user/object interaction.</li>\r\n<li>Techniques for learning and automatic classification of sounds based on physiological models for an automatic aesthetic, functionality, and emotional evaluation of the sound included in the sound design process.</li>\r\n</ul>", "date_from": "2006-07-01", "date_to": "2009-06-30", "user": null, "type": "external", "external_id": "FP6-NEST-029085", "program": 8, "program_type": 24, "call": null, "lead_team": null, "lead_organization": 1, "website": "http://closed.ircam.fr/", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [182, 183, 185], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 76, "fields": {"keywords_string": "", "site": 1, "title": "Minet", "title_fr": "Minet", "title_en": "Minet", "slug": "minet", "_meta_title": "", "description": "Measuring the Impossible NETwork", "description_fr": "Measuring the Impossible NETwork", "description_en": "Measuring the Impossible NETwork", "gen_description": false, "created": "2016-09-09T10:56:58.525Z", "updated": "2018-06-29T09:55:12.335Z", "status": 2, "publish_date": "2016-09-09T10:56:58Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet MINET avait pour objectif de regrouper tous les projets europ&eacute;ens du programme &laquo;Measuring the Impossible&raquo; (MTI), auquel le projet CLOSED appartient, ainsi que des sp&eacute;cialistes de m&eacute;trologie. En effet, le point commun de tous ces projets est qu&rsquo;ils cherchent &agrave; mesurer l&rsquo;impossible, c&rsquo;est-&agrave;-dire des ph&eacute;nom&egrave;nes li&eacute;s &agrave; l&rsquo;&ecirc;tre humain, traditionnellement r&eacute;put&eacute;s non mesurables, tels que les &eacute;motions ou la perception.</p>\r\n<p>L&rsquo;objectif global de MINET a donc &eacute;t&eacute; de r&eacute;fl&eacute;chir &agrave; ce concept de mesure appliqu&eacute; &agrave; l&rsquo;humain. &Agrave; travers l&rsquo;organisation d&rsquo;&eacute;changes, de groupes de r&eacute;flexions, de s&eacute;minaires, de visites d&rsquo;&eacute;tudes ou d&rsquo;&eacute;coles d&rsquo;&eacute;t&eacute; entre les diff&eacute;rents projets partenaires de MINET, cet objectif s&rsquo;est subdivis&eacute; en plusieurs points : augmenter la productivit&eacute; des diff&eacute;rents projets partenaires de MINET, structurer et &eacute;largir la communaut&eacute; scientifique europ&eacute;enne s&rsquo;int&eacute;ressant &agrave; la mesure de quantit&eacute;s li&eacute;es &agrave; l&rsquo;humain, d&eacute;velopper et standardiser les concepts m&eacute;trologiques propres &agrave; la mesure de l&rsquo;humain.</p>", "content_fr": "<p>Le projet MINET avait pour objectif de regrouper tous les projets europ&eacute;ens du programme &laquo;Measuring the Impossible&raquo; (MTI), auquel le projet CLOSED appartient, ainsi que des sp&eacute;cialistes de m&eacute;trologie. En effet, le point commun de tous ces projets est qu&rsquo;ils cherchent &agrave; mesurer l&rsquo;impossible, c&rsquo;est-&agrave;-dire des ph&eacute;nom&egrave;nes li&eacute;s &agrave; l&rsquo;&ecirc;tre humain, traditionnellement r&eacute;put&eacute;s non mesurables, tels que les &eacute;motions ou la perception.</p>\r\n<p>L&rsquo;objectif global de MINET a donc &eacute;t&eacute; de r&eacute;fl&eacute;chir &agrave; ce concept de mesure appliqu&eacute; &agrave; l&rsquo;humain. &Agrave; travers l&rsquo;organisation d&rsquo;&eacute;changes, de groupes de r&eacute;flexions, de s&eacute;minaires, de visites d&rsquo;&eacute;tudes ou d&rsquo;&eacute;coles d&rsquo;&eacute;t&eacute; entre les diff&eacute;rents projets partenaires de MINET, cet objectif s&rsquo;est subdivis&eacute; en plusieurs points : augmenter la productivit&eacute; des diff&eacute;rents projets partenaires de MINET, structurer et &eacute;largir la communaut&eacute; scientifique europ&eacute;enne s&rsquo;int&eacute;ressant &agrave; la mesure de quantit&eacute;s li&eacute;es &agrave; l&rsquo;humain, d&eacute;velopper et standardiser les concepts m&eacute;trologiques propres &agrave; la mesure de l&rsquo;humain.</p>", "content_en": "<p>The MINET project coordinated activities for all European projects that are a part of the &lsquo;Measuring the Impossible&rsquo; (MTI) program; the CLOSED project was a part of this program, as are specialists in metrology. The common point of these projects is their search to measure the impossible, meaning phenomena connected to being human, conventionally thought of as being immeasurable such as emotions or perceptions.</p>\r\n<p>The global objective of MINET was therefore to reflect on this idea of measurement applied to humans. Via an organization that facilitated exchanges, brainstorming groups, seminars, study groups, or summer schools among MINET project partners, this objective was divided into several points: improve the productivity of MINET project partners, structure and broaden the European scientific community interested in measuring quantities connected with the human being, developing and standardizing the metrology concepts used to measure humans.</p>", "date_from": "2007-02-01", "date_to": "2010-03-31", "user": null, "type": "external", "external_id": "043297-6th-FPR-2006", "program": 8, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [181], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 77, "fields": {"keywords_string": "", "site": 1, "title": "Sid", "title_fr": "Sid", "title_en": "Sid", "slug": "sid", "_meta_title": "", "description": "Sonic Interaction Design", "description_fr": "Sonic Interaction Design", "description_en": "Sonic Interaction Design", "gen_description": false, "created": "2016-09-09T10:57:33.344Z", "updated": "2018-06-29T11:15:08.104Z", "status": 2, "publish_date": "2016-09-09T10:57:33Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le design interactif sonore (SID) consiste &agrave; exploiter la modalit&eacute; sonore pour transmettre une information, combin&eacute;e &agrave; une composante esth&eacute;tique/&eacute;motionnelle, utile dans des contextes d&rsquo;usage interactif. En d&rsquo;autres termes, il s&rsquo;agit de favoriser les interactions par le biais du sonore.</p>\r\n<p>L&rsquo;objectif de la COST action SID est de contribuer &agrave; la cr&eacute;ation et &agrave; la consolidation d&rsquo;une th&eacute;orie, d&rsquo;outils et de domaines d&rsquo;application du design sonore afin d&rsquo;am&eacute;liorer ou d&rsquo;introduire la composante sonore dans la conception d&rsquo;objets et de syst&egrave;mes interactifs.</p>\r\n<p>Un des enjeux &agrave; long terme est de coordonner les travaux dans ce domaine au niveau europ&eacute;en, et de d&eacute;gager des nouvelles perspectives dans les programmes europ&eacute;ens (7<sup>th</sup> framework programme...). Les efforts ont &eacute;t&eacute; port&eacute;s par quatre groupes de travail, chacun &eacute;tant associ&eacute; &agrave; un axe de recherche ou d&rsquo;application r&eacute;v&eacute;l&eacute; pertinent pour le domaine&nbsp; :</p>\r\n<ul>\r\n<li>Approches perceptive, cognitive et &eacute;motionnelle dans les interactions sonores ;</li>\r\n<li>Design sonore produit ;</li>\r\n<li>Interactions musicales et artistiques ;</li>\r\n<li>Sonification.</li>\r\n</ul>", "content_fr": "<p>Le design interactif sonore (SID) consiste &agrave; exploiter la modalit&eacute; sonore pour transmettre une information, combin&eacute;e &agrave; une composante esth&eacute;tique/&eacute;motionnelle, utile dans des contextes d&rsquo;usage interactif. En d&rsquo;autres termes, il s&rsquo;agit de favoriser les interactions par le biais du sonore.</p>\r\n<p>L&rsquo;objectif de la COST action SID est de contribuer &agrave; la cr&eacute;ation et &agrave; la consolidation d&rsquo;une th&eacute;orie, d&rsquo;outils et de domaines d&rsquo;application du design sonore afin d&rsquo;am&eacute;liorer ou d&rsquo;introduire la composante sonore dans la conception d&rsquo;objets et de syst&egrave;mes interactifs.</p>\r\n<p>Un des enjeux &agrave; long terme est de coordonner les travaux dans ce domaine au niveau europ&eacute;en, et de d&eacute;gager des nouvelles perspectives dans les programmes europ&eacute;ens (7<sup>th</sup> framework programme...). Les efforts ont &eacute;t&eacute; port&eacute;s par quatre groupes de travail, chacun &eacute;tant associ&eacute; &agrave; un axe de recherche ou d&rsquo;application r&eacute;v&eacute;l&eacute; pertinent pour le domaine&nbsp; :</p>\r\n<ul>\r\n<li>Approches perceptive, cognitive et &eacute;motionnelle dans les interactions sonores ;</li>\r\n<li>Design sonore produit ;</li>\r\n<li>Interactions musicales et artistiques ;</li>\r\n<li>Sonification.</li>\r\n</ul>", "content_en": "<p>Sonic Interaction Design is the exploitation of sound as one of the principal channels conveying information, meaning, and aesthetic/emotional qualities in interactive contexts.</p>\r\n<p>The Action pro&ndash;actively contributes to the creation and consolidation of new design theories, tools, and practices in this innovative and interdisciplinary domain.</p>\r\n<p>While being advanced through a few sparse projects, this field relies on the COST &ndash; SID Action to strengthen the links between scientists, artists, and designers in the European Research Area. The COST &ndash; SID platform stands on four legs:</p>\r\n<ul>\r\n<li>Perceptive, cognitive, and emotional approaches in sound interactions</li>\r\n<li>Design of the sound produced</li>\r\n<li>Musical and artistic interactions</li>\r\n<li>Sonification</li>\r\n</ul>", "date_from": "2007-07-01", "date_to": "2010-08-01", "user": null, "type": "external", "external_id": "FP6-NEST-MTL-IC-060", "program": 8, "program_type": 25, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 28, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [171], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 82, "fields": {"keywords_string": "", "site": 1, "title": "ChaNTeR", "title_fr": "ChaNTeR", "title_en": "ChaNTeR", "slug": "chanter", "_meta_title": "", "description": "Syst\u00e8me de synth\u00e8se du chant", "description_fr": "Syst\u00e8me de synth\u00e8se du chant", "description_en": "Real-time controlled digital singing", "gen_description": false, "created": "2016-11-07T14:30:19.695Z", "updated": "2018-11-26T15:13:20.159Z", "status": 2, "publish_date": "2016-11-07T14:30:19Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le but du projet est de r&eacute;aliser un syst&egrave;me de synth&egrave;se de chant de haute qualit&eacute;, qui puisse &ecirc;tre utilis&eacute; par le grand public musicien. Le syst&egrave;me doit non seulement chanter sur des voyelles, mais aussi prononcer les paroles d&rsquo;une chanson. Un tel syst&egrave;me n&rsquo;existe pas pour la langue fran&ccedil;aise. Le synth&eacute;tiseur pr&eacute;vu fonctionnera sur deux modes : le mode &laquo; chant &agrave; partir du texte &raquo; dans lequel l&rsquo;utilisateur doit saisir le texte &agrave; chanter et les notes de la partition (dur&eacute;es et hauteurs) que la machine transforme en son et le mode &laquo; chanteur virtuel &raquo; dans lequel l&rsquo;utilisateur utilise des interfaces de contr&ocirc;le temps r&eacute;el pour contr&ocirc;ler le synth&eacute;tiseur de chant comme un instrument.</p>\r\n<p>Pour r&eacute;aliser ces outils, nous proposons une combinaison de technologies avanc&eacute;es de transformation de voix, avec le savoir faire sur la s&eacute;lection des unit&eacute;s et les syst&egrave;mes de r&egrave;gles du chant, et des interfaces de contr&ocirc;le gestuel innovantes. Le projet porte une attention particuli&egrave;re &agrave; capturer et reproduire la vari&eacute;t&eacute; des styles vocaux (lyrique/classique, populaire/chanson). Outre les tests de qualit&eacute; utilis&eacute;s d&rsquo;ordinaire pour la synth&egrave;se vocale, l&rsquo;utilisabilit&eacute; des syst&egrave;mes sera test&eacute;e et d&eacute;montr&eacute;e en pr&ecirc;tant une attention d&egrave;s le d&eacute;part aux aspects de cr&eacute;ation qu&rsquo;ils permettent (&eacute;valuation sous forme de mini-concerts et mini-projets compositionnels utilisant les nouveaux gestes de contr&ocirc;le, un ch&oelig;ur virtuel et/ou un soliste virtuel). Le prototype de synth&egrave;se de chant qui sera d&eacute;velopp&eacute; dans le projet sera utilis&eacute; par les partenaires pour proposer des produits de synth&egrave;se de voix chant&eacute;e et d&rsquo;instrument chanteur qui font actuellement d&eacute;faut ou am&eacute;liorer les fonctionnalit&eacute;s de produits existants. Ainsi, le projet permettra d&rsquo;offrir &agrave; des musiciens interpr&egrave;tes, &agrave; des compositeurs et &agrave; un large public une approche artistique nouvelle du chant de synth&egrave;se, de nouveaux moyens de cr&eacute;ation permettant des exp&eacute;riences interactives utilisant la voix chant&eacute;e.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-13-CORD-011-02.</p>", "content_fr": "<p>Le but du projet est de r&eacute;aliser un syst&egrave;me de synth&egrave;se de chant de haute qualit&eacute;, qui puisse &ecirc;tre utilis&eacute; par le grand public musicien. Le syst&egrave;me doit non seulement chanter sur des voyelles, mais aussi prononcer les paroles d&rsquo;une chanson. Un tel syst&egrave;me n&rsquo;existe pas pour la langue fran&ccedil;aise. Le synth&eacute;tiseur pr&eacute;vu fonctionnera sur deux modes : le mode &laquo; chant &agrave; partir du texte &raquo; dans lequel l&rsquo;utilisateur doit saisir le texte &agrave; chanter et les notes de la partition (dur&eacute;es et hauteurs) que la machine transforme en son et le mode &laquo; chanteur virtuel &raquo; dans lequel l&rsquo;utilisateur utilise des interfaces de contr&ocirc;le temps r&eacute;el pour contr&ocirc;ler le synth&eacute;tiseur de chant comme un instrument.</p>\r\n<p>Pour r&eacute;aliser ces outils, nous proposons une combinaison de technologies avanc&eacute;es de transformation de voix, avec le savoir faire sur la s&eacute;lection des unit&eacute;s et les syst&egrave;mes de r&egrave;gles du chant, et des interfaces de contr&ocirc;le gestuel innovantes. Le projet porte une attention particuli&egrave;re &agrave; capturer et reproduire la vari&eacute;t&eacute; des styles vocaux (lyrique/classique, populaire/chanson). Outre les tests de qualit&eacute; utilis&eacute;s d&rsquo;ordinaire pour la synth&egrave;se vocale, l&rsquo;utilisabilit&eacute; des syst&egrave;mes sera test&eacute;e et d&eacute;montr&eacute;e en pr&ecirc;tant une attention d&egrave;s le d&eacute;part aux aspects de cr&eacute;ation qu&rsquo;ils permettent (&eacute;valuation sous forme de mini-concerts et mini-projets compositionnels utilisant les nouveaux gestes de contr&ocirc;le, un ch&oelig;ur virtuel et/ou un soliste virtuel). Le prototype de synth&egrave;se de chant qui sera d&eacute;velopp&eacute; dans le projet sera utilis&eacute; par les partenaires pour proposer des produits de synth&egrave;se de voix chant&eacute;e et d&rsquo;instrument chanteur qui font actuellement d&eacute;faut ou am&eacute;liorer les fonctionnalit&eacute;s de produits existants. Ainsi, le projet permettra d&rsquo;offrir &agrave; des musiciens interpr&egrave;tes, &agrave; des compositeurs et &agrave; un large public une approche artistique nouvelle du chant de synth&egrave;se, de nouveaux moyens de cr&eacute;ation permettant des exp&eacute;riences interactives utilisant la voix chant&eacute;e.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-13-CORD-011-02.</p>", "content_en": "<p>The goal of this project is to create a high quality system for synthesizing song that can be used by the general public. The system must not only sing vowels, but must also say the words of a song. This type of system does not currently exist for the French language. The synthesizer imagined will work in two modes. The first is \"song from text\" mode where the user can enter a text to be sung along with a score (times and pitches), and the machine will transform it into sound. The second is the \"virtual singer\" mode in which the user controls the song synthesizer in real-time via specific interfaces; just like playing an instrument.</p>\r\n<p>To create these tools, we suggest a combination of advanced voice transformation technologies, based on our expertise in synthesis by selection of units and in synthesis of singing by rules, and innovative interfaces for gestural control. The project focuses on capturing and reproducing a variety of vocal styles (e.g. lyrical/classical, popular/song). Beyond the quality tests ordinarily used for vocal synthesis the usability of the systems will be tested from the outset, paying particular attention to the creative aspects they allow (assessment through mini-concerts and mini composition projects that use the new control gestures, a virtual chorus, and/or a virtual soloist). Project partners will use the prototype of song synthesis that will be developed during the project to offer synthesized singing voice and singing instrument products that are currently lacking, or to improve the functions of currently existing products. The project will offer musicians and performers a new artistic approach to synthesized song, new means of creation that make interactive experiences with a sung voice possible.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-13-CORD-011-02.</p>", "date_from": "2014-01-01", "date_to": "2017-12-31", "user": null, "type": "external", "external_id": "ANR-13-CORD-011-02", "program": 1, "program_type": 2, "call": 10, "lead_team": null, "lead_organization": 599, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [25, 26, 1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 93, "fields": {"keywords_string": "", "site": 1, "title": "Orchestration", "title_fr": "Orchestration", "title_en": "Orchestration", "slug": "orchestration", "_meta_title": "", "description": "Confrontation de l\u2019\u00e9tat de l\u2019art en musicologie, en psychologie de la perception et en informatique musicale pour la cr\u00e9ation de nouveaux outils", "description_fr": "Confrontation de l\u2019\u00e9tat de l\u2019art en musicologie, en psychologie de la perception et en informatique musicale pour la cr\u00e9ation de nouveaux outils", "description_en": "Comparison of the state of the art in musicology, in psychology of perception, and in computer music to create new tools", "gen_description": false, "created": "2016-11-07T14:30:22.312Z", "updated": "2018-06-29T10:25:39.770Z", "status": 2, "publish_date": "2016-11-07T14:30:22Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;un des aspects les plus complexes et myst&eacute;rieux de la composition musicale, encore relativement peu abord&eacute; syst&eacute;matiquement dans le champ scientifique, concerne l&rsquo;&eacute;criture du timbre, en particulier par les techniques d&rsquo;orchestration. Le projet se fonde sur une confrontation de l&rsquo;&eacute;tat de l&rsquo;art en musicologie, en psychologie de la perception et en informatique musicale pour la cr&eacute;ation de nouveaux outils permettant d&rsquo;aborder les probl&eacute;matiques li&eacute;es &agrave; l&rsquo;orchestration, sa perception et sa p&eacute;dagogie.</p>\r\n<p>L&rsquo;objectif est de d&eacute;velopper des mod&egrave;les g&eacute;n&eacute;ralisables qui facilitent l&rsquo;apprentissage et la pratique de l&rsquo;orchestration, assist&eacute;s par les nouvelles technologies. L&rsquo;enjeu &agrave; long terme est de constituer un trait&eacute; d&rsquo;orchestration interactif int&eacute;grant les connaissances sur les pratiques de l&rsquo;orchestration, la perception des effets orchestraux, ainsi que des outils num&eacute;riques pour aider &agrave; r&eacute;soudre des probl&egrave;mes d&rsquo;orchestration, y compris pour l&rsquo;&eacute;criture de parties &eacute;lectroniques d&rsquo;oeuvres mixtes. Le projet s&rsquo;appuie &agrave; cet effet sur un important volet d&rsquo;annotations de corpus de musique classique selon un ensemble de cat&eacute;gories pertinentes, destin&eacute;es &agrave; alimenter &agrave; la fois des exp&eacute;riences perceptives, des supports p&eacute;dagogiques et &agrave; constituer des donn&eacute;es d&rsquo;entra&icirc;nement pour des algorithmes d&rsquo;apprentissage automatique.</p>\r\n<p>Le r&ocirc;le de l&rsquo;Ircam dans le projet porte sur les applications de&nbsp; l&rsquo;informatique musicale et de l&rsquo;intelligence artificielle aux outils d&rsquo;aide &agrave; l&rsquo;orchestration, sur la base du logiciel Orchids et de nouvelles recherches faisant appel &agrave; des techniques d&rsquo;apprentissage profond.</p>", "content_fr": "<p>L&rsquo;un des aspects les plus complexes et myst&eacute;rieux de la composition musicale, encore relativement peu abord&eacute; syst&eacute;matiquement dans le champ scientifique, concerne l&rsquo;&eacute;criture du timbre, en particulier par les techniques d&rsquo;orchestration. Le projet se fonde sur une confrontation de l&rsquo;&eacute;tat de l&rsquo;art en musicologie, en psychologie de la perception et en informatique musicale pour la cr&eacute;ation de nouveaux outils permettant d&rsquo;aborder les probl&eacute;matiques li&eacute;es &agrave; l&rsquo;orchestration, sa perception et sa p&eacute;dagogie.</p>\r\n<p>L&rsquo;objectif est de d&eacute;velopper des mod&egrave;les g&eacute;n&eacute;ralisables qui facilitent l&rsquo;apprentissage et la pratique de l&rsquo;orchestration, assist&eacute;s par les nouvelles technologies. L&rsquo;enjeu &agrave; long terme est de constituer un trait&eacute; d&rsquo;orchestration interactif int&eacute;grant les connaissances sur les pratiques de l&rsquo;orchestration, la perception des effets orchestraux, ainsi que des outils num&eacute;riques pour aider &agrave; r&eacute;soudre des probl&egrave;mes d&rsquo;orchestration, y compris pour l&rsquo;&eacute;criture de parties &eacute;lectroniques d&rsquo;oeuvres mixtes. Le projet s&rsquo;appuie &agrave; cet effet sur un important volet d&rsquo;annotations de corpus de musique classique selon un ensemble de cat&eacute;gories pertinentes, destin&eacute;es &agrave; alimenter &agrave; la fois des exp&eacute;riences perceptives, des supports p&eacute;dagogiques et &agrave; constituer des donn&eacute;es d&rsquo;entra&icirc;nement pour des algorithmes d&rsquo;apprentissage automatique.</p>\r\n<p>Le r&ocirc;le de l&rsquo;Ircam dans le projet porte sur les applications de&nbsp; l&rsquo;informatique musicale et de l&rsquo;intelligence artificielle aux outils d&rsquo;aide &agrave; l&rsquo;orchestration, sur la base du logiciel Orchids et de nouvelles recherches faisant appel &agrave; des techniques d&rsquo;apprentissage profond.</p>", "content_en": "<p>One of the most complex and mysterious aspects of musical composition, still scarcely studied in the scientific domain, concerns writing timbre, in particular orchestration techniques. The project is based on a comparison of the state of the art in musicology, in psychology of perception, and in computer music to create new tools to address problems connected to orchestration, its perception, and its instruction.</p>\r\n<p>The objective is to develop models that can be generalized, that facilitate the instruction and practice of orchestration, assisted by new technologies. The long-term goal is to create an interactive treaty on orchestration comprising knowledge on orchestration practices, the perception of orchestral effects, and digital tools to help resolve orchestration problems including writing electronic sections of mixed-music works. The project relies on a large quantity of annotations made on the corpus of classical music using a range of pertinent categories, intended to supply both perceptive experiences and educational materials as well as to establish practice data for automatic learning algorithms.</p>\r\n<p>IRCAM&rsquo;s role in this project focuses on computer music applications and artificial intelligence for computer-assisted orchestration tools based on the software program Orchids and new research on deep learning techniques.</p>", "date_from": "2015-04-01", "date_to": "2018-03-31", "user": null, "type": "external", "external_id": "890-2014-0008-241043", "program": 14, "program_type": null, "call": 8, "lead_team": null, "lead_organization": 131, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [163, 1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 104, "fields": {"keywords_string": "", "site": 1, "title": "UMG", "title_fr": "UMG", "title_en": null, "slug": "umg", "_meta_title": null, "description": "UMG", "description_fr": "UMG", "description_en": null, "gen_description": true, "created": "2016-11-07T14:30:26.097Z", "updated": "2016-11-07T14:30:26.097Z", "status": 1, "publish_date": "2016-11-07T14:30:26.095Z", "expiry_date": null, "short_url": null, "in_sitemap": true, "content": "", "content_fr": "", "content_en": null, "date_from": null, "date_to": null, "user": null, "type": "", "external_id": null, "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 145, "fields": {"keywords_string": "", "site": 1, "title": "Wasabi", "title_fr": "Wasabi", "title_en": "Wasabi", "slug": "wasabi", "_meta_title": "", "description": "Web Audio Semantic Aggregated in the Browser for Indexation", "description_fr": "Web Audio Semantic Aggregated in the Browser for Indexation", "description_en": "Web Audio Semantic Aggregated in the Browser for Indexation", "gen_description": false, "created": "2017-01-06T09:16:20.472Z", "updated": "2018-12-28T15:08:16.399Z", "status": 2, "publish_date": "2017-01-06T09:16:20Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet propose de d&eacute;finir une m&eacute;thodologie d&rsquo;optimisation de l&rsquo;indexation musicale dans un contexte Web et pour de tr&egrave;s grands corpus de donn&eacute;es par l&rsquo;utilisation conjointe de m&eacute;tadonn&eacute;es issues de l&rsquo;analyse audio, du Web s&eacute;mantique, de l&rsquo;analyse en langage naturel des paroles de chansons, puis de confronter cette m&eacute;thodologie &agrave; des cas d&rsquo;usages en d&eacute;veloppant des services et des applications originales exploitant les technologies Web audio.</p>\r\n<p>Il s&rsquo;agit donc d&rsquo;utiliser conjointement les algorithmes d&rsquo;extraction d&rsquo;information musicale et le Web s&eacute;mantique afin de produire des bases de connaissances musicales plus consistantes pour les services de streaming et les bases de donn&eacute;es musicales. Les services de donn&eacute;es du Web s&eacute;mantique (LastFM, MusicBrainz, DBPedia, etc.) favoriseront l&rsquo;extraction de donn&eacute;es structur&eacute;es, liant les oeuvres &agrave; des m&eacute;tadonn&eacute;es telles que le producteur, le studio d&rsquo;enregistrement, le compositeur, l&rsquo;ann&eacute;e de diffusion, les th&egrave;mes qui y sont abord&eacute;s, par exemple. Les donn&eacute;es en texte libre comme les paroles seront aussi analys&eacute;es pour d&eacute;terminer le contexte musical de l&rsquo;&oelig;uvre. Les technologies Web audio permettront enfin d&rsquo;explorer ces espaces musicaux enrichis par des analyses de type indexation musicale de haut niveau : d&eacute;tection d&rsquo;&eacute;motion, d&eacute;tection de plagiat, d&eacute;tection et caract&eacute;risation de voix chant&eacute;e, d&eacute;tection de structure et s&eacute;paration de sources.</p>\r\n<p>Il sera propos&eacute; une suite de briques logicielles open source et de services en ligne de type &laquo; open data &raquo; pour :</p>\r\n<ul>\r\n<li>la visualisation de m&eacute;tadonn&eacute;es audio et l&rsquo;&eacute;coute de pistes d&eacute;mix&eacute;es dans le navigateur en exploitant les derni&egrave;res technologies issues de la Web Audio API (mixage temps r&eacute;el, effets audio) ;</li>\r\n<li>le traitement automatique de textes de chansons, reconnaissance<br />et liage d&rsquo;entit&eacute; nomm&eacute;es, d&rsquo;annotation et correction<br />collaborative ;</li>\r\n<li>l&rsquo;acc&egrave;s &agrave; un service Web dot&eacute; d&rsquo;une API proposant un environnement d&rsquo;&eacute;tude de similarit&eacute;s musicales issu des analyses audio et s&eacute;mantiques.</li>\r\n</ul>\r\n<p>Ces briques logicielles serviront au d&eacute;veloppement des d&eacute;monstrateurs formalis&eacute;s avec nos partenaires et collaborateurs (journalistes et compositeurs), utilisant le nouveau standard Web Audio API et permettant ainsi le d&eacute;veloppement d&rsquo;applications musicales accessibles au grand public depuis un navigateur Web.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-16-CE23-0017-02.</p>", "content_fr": "<p>Le projet propose de d&eacute;finir une m&eacute;thodologie d&rsquo;optimisation de l&rsquo;indexation musicale dans un contexte Web et pour de tr&egrave;s grands corpus de donn&eacute;es par l&rsquo;utilisation conjointe de m&eacute;tadonn&eacute;es issues de l&rsquo;analyse audio, du Web s&eacute;mantique, de l&rsquo;analyse en langage naturel des paroles de chansons, puis de confronter cette m&eacute;thodologie &agrave; des cas d&rsquo;usages en d&eacute;veloppant des services et des applications originales exploitant les technologies Web audio.</p>\r\n<p>Il s&rsquo;agit donc d&rsquo;utiliser conjointement les algorithmes d&rsquo;extraction d&rsquo;information musicale et le Web s&eacute;mantique afin de produire des bases de connaissances musicales plus consistantes pour les services de streaming et les bases de donn&eacute;es musicales. Les services de donn&eacute;es du Web s&eacute;mantique (LastFM, MusicBrainz, DBPedia, etc.) favoriseront l&rsquo;extraction de donn&eacute;es structur&eacute;es, liant les oeuvres &agrave; des m&eacute;tadonn&eacute;es telles que le producteur, le studio d&rsquo;enregistrement, le compositeur, l&rsquo;ann&eacute;e de diffusion, les th&egrave;mes qui y sont abord&eacute;s, par exemple. Les donn&eacute;es en texte libre comme les paroles seront aussi analys&eacute;es pour d&eacute;terminer le contexte musical de l&rsquo;&oelig;uvre. Les technologies Web audio permettront enfin d&rsquo;explorer ces espaces musicaux enrichis par des analyses de type indexation musicale de haut niveau : d&eacute;tection d&rsquo;&eacute;motion, d&eacute;tection de plagiat, d&eacute;tection et caract&eacute;risation de voix chant&eacute;e, d&eacute;tection de structure et s&eacute;paration de sources.</p>\r\n<p>Il sera propos&eacute; une suite de briques logicielles open source et de services en ligne de type &laquo; open data &raquo; pour :</p>\r\n<ul>\r\n<li>la visualisation de m&eacute;tadonn&eacute;es audio et l&rsquo;&eacute;coute de pistes d&eacute;mix&eacute;es dans le navigateur en exploitant les derni&egrave;res technologies issues de la Web Audio API (mixage temps r&eacute;el, effets audio) ;</li>\r\n<li>le traitement automatique de textes de chansons, reconnaissance<br />et liage d&rsquo;entit&eacute; nomm&eacute;es, d&rsquo;annotation et correction<br />collaborative ;</li>\r\n<li>l&rsquo;acc&egrave;s &agrave; un service Web dot&eacute; d&rsquo;une API proposant un environnement d&rsquo;&eacute;tude de similarit&eacute;s musicales issu des analyses audio et s&eacute;mantiques.</li>\r\n</ul>\r\n<p>Ces briques logicielles serviront au d&eacute;veloppement des d&eacute;monstrateurs formalis&eacute;s avec nos partenaires et collaborateurs (journalistes et compositeurs), utilisant le nouveau standard Web Audio API et permettant ainsi le d&eacute;veloppement d&rsquo;applications musicales accessibles au grand public depuis un navigateur Web.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-16-CE23-0017-02.</p>", "content_en": "<p>The goal of the WASABI project is to define an optimized methodology for indexing music for the Web for large databases by linking metadata from audio analysis, Semantic Web techniques, and the analysis of textual data such as song lyrics using natural language analysis and to compare this methodology with case scenarios to develop unique services and applications using Web Audio technologies.</p>\r\n<p>The project entails using algorithms to extract musical information and Semantic Web techniques to produce more consistent musical knowledge bases for streaming services and music databases. Services using Web Semantic data like LastFM, MusicBrainz, or DBPedia use the extraction of structural data, connecting works to metadata such as the producer, the recording studio name, the composer, the release year, or the subjects in the lyrics for example. The data in free text like the lyrics are also analyzed to determine the musical context of the piece. Web Audio technologies make it possible to explore these musical spaces improved with analyses such as high-level musical indexation: detecting emotion and plagiarism, detecting and characterizing the singing voice, detecting the structure and separating the different sources.</p>\r\n<p>Open source software bricks and &ldquo;open data&rdquo; online services will be proposed at the end of the project for:</p>\r\n<ul>\r\n<li>The visualization of audio metadata and listening to un-mixed tracks in a browser as well as using the latest Web Audio API technologies (mixing in real-time, audio effects)</li>\r\n<li>Automatic processing of lyrics, recognition and merging named entities, collaborative annotation and correction</li>\r\n<li>Access to a Web service with an API offering an environment in which to study musical similarities from audio and semantic analyses</li>\r\n</ul>\r\n<p>These software bricks will be used in the development of formalized demonstrators with our partners and collaborators (journalists and composers), using the new Web Audio API standard making it possible to develop musical applications accessible to the general public via a Web browser.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-16-CE23-0017-02.</p>", "date_from": "2016-10-01", "date_to": "2020-03-31", "user": null, "type": "external", "external_id": "ANR-16-CE23-0017-02", "program": 1, "program_type": 17, "call": 1, "lead_team": null, "lead_organization": 595, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6, 13, 44], "organizations": [618, 106, 1, 617, 99], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 146, "fields": {"keywords_string": "", "site": 1, "title": "Vertigo", "title_fr": "Vertigo", "title_en": "Vertigo", "slug": "vertigo", "_meta_title": "", "description": "Promouvoir la collaboration d\u2019artistes \u00e0 des projets de R&D dans le champ ICT \u00e0 des fins d\u2019innovation", "description_fr": "Promouvoir la collaboration d\u2019artistes \u00e0 des projets de R&D dans le champ ICT \u00e0 des fins d\u2019innovation", "description_en": "Encourages synergies between artists and R&D projects in the field of ICT supporting innovation", "gen_description": false, "created": "2017-01-06T09:17:30.275Z", "updated": "2018-06-29T09:44:17.664Z", "status": 2, "publish_date": "2017-01-06T09:17:30Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Vertigo a &eacute;t&eacute; con&ccedil;u et s&eacute;lectionn&eacute; en r&eacute;ponse au premier appel de la <a href=\"http://ec.europa.eu/index_fr.htm\" target=\"_blank\">Commission europ&eacute;enne</a> dans le cadre du programme H2020 ICT (technologies de l&rsquo;information et de la communication) li&eacute; &agrave; l&rsquo;<a href=\"https://ec.europa.eu/digital-single-market/en/ict-art-starts-platform\" target=\"_blank\">initiative STARTS</a> (Science, Technology and the Arts). L&rsquo;enjeu g&eacute;n&eacute;ral de STARTS est de promouvoir la collaboration d&rsquo;artistes &agrave; des projets de R&amp;D dans le champ ICT &agrave; des fins d&rsquo;innovation et Vertigo s&rsquo;attache &agrave; coordonner les diff&eacute;rentes actions men&eacute;es dans ce sens au niveau europ&eacute;en selon trois volets compl&eacute;mentaires :</p>\r\n<ul>\r\n<li>L&rsquo;organisation de r&eacute;sidences d&rsquo;artistes en lien avec des projets de R&amp;D, dans le cadre d&rsquo;appels &agrave; propositions annuels &eacute;valu&eacute;s par un comit&eacute; de s&eacute;lection international et interdisciplinaire. Un budget de 900 k&euro; est consacr&eacute; au soutien en 3 cycles annuels d&rsquo;un total de 45 projets de r&eacute;sidences artistiques visant notamment &agrave; constituer, par la production d&rsquo;oeuvres artistiques originales, des prototypes de cas d&rsquo;usages innovants des technologies d&eacute;velopp&eacute;es ;</li>\r\n<li>La pr&eacute;sentation publique des diff&eacute;rentes actions men&eacute;es dans le cadre du nouvel &eacute;v&eacute;nement annuel au Centre Pompidou, &laquo; Mutations Cr&eacute;ations &raquo;, associant expositions, symposiums et &eacute;v&eacute;nements artistiques et visant &agrave; exposer et d&eacute;battre des &eacute;volutions des pratiques artistiques dans l&rsquo;&eacute;cosyst&egrave;me scientifique et technologique contemporain. L&rsquo;&eacute;dition inaugurale de mars 2017, li&eacute;e aux expositions &laquo; Imprimer le monde &raquo; et &laquo; Ross Lovegrove &raquo;, est plac&eacute;e sous le th&egrave;me &laquo; L&rsquo;espace simul&eacute; ou les formes du digital &raquo;.</li>\r\n</ul>\r\n<p>Le d&eacute;veloppement d&rsquo;une plateforme Web communautaire f&eacute;d&eacute;rant et mettant en contact les diff&eacute;rents acteurs concern&eacute;s (chercheurs, artistes, industriels, incubateurs, investisseurs) et offrant un support &agrave; leurs actions (communication, organisation de programmes particuliers de r&eacute;sidences artistiques, etc.). En sus du consortium de ses partenaires, le projet pilote un r&eacute;seau international de 20 correspondants dans le champ culturel, comprenant notamment le Zentrum fu\u0308r Kunst und Media de Karslruhe, le Victoria and Albert Museum de Londres, la Biennale de Venise, le festival Ars Electronica de Linz, etc.</p>", "content_fr": "<p>Le projet Vertigo a &eacute;t&eacute; con&ccedil;u et s&eacute;lectionn&eacute; en r&eacute;ponse au premier appel de la <a href=\"http://ec.europa.eu/index_fr.htm\" target=\"_blank\">Commission europ&eacute;enne</a> dans le cadre du programme H2020 ICT (technologies de l&rsquo;information et de la communication) li&eacute; &agrave; l&rsquo;<a href=\"https://ec.europa.eu/digital-single-market/en/ict-art-starts-platform\" target=\"_blank\">initiative STARTS</a> (Science, Technology and the Arts). L&rsquo;enjeu g&eacute;n&eacute;ral de STARTS est de promouvoir la collaboration d&rsquo;artistes &agrave; des projets de R&amp;D dans le champ ICT &agrave; des fins d&rsquo;innovation et Vertigo s&rsquo;attache &agrave; coordonner les diff&eacute;rentes actions men&eacute;es dans ce sens au niveau europ&eacute;en selon trois volets compl&eacute;mentaires :</p>\r\n<ul>\r\n<li>L&rsquo;organisation de r&eacute;sidences d&rsquo;artistes en lien avec des projets de R&amp;D, dans le cadre d&rsquo;appels &agrave; propositions annuels &eacute;valu&eacute;s par un comit&eacute; de s&eacute;lection international et interdisciplinaire. Un budget de 900 k&euro; est consacr&eacute; au soutien en 3 cycles annuels d&rsquo;un total de 45 projets de r&eacute;sidences artistiques visant notamment &agrave; constituer, par la production d&rsquo;oeuvres artistiques originales, des prototypes de cas d&rsquo;usages innovants des technologies d&eacute;velopp&eacute;es ;</li>\r\n<li>La pr&eacute;sentation publique des diff&eacute;rentes actions men&eacute;es dans le cadre du nouvel &eacute;v&eacute;nement annuel au Centre Pompidou, &laquo; Mutations Cr&eacute;ations &raquo;, associant expositions, symposiums et &eacute;v&eacute;nements artistiques et visant &agrave; exposer et d&eacute;battre des &eacute;volutions des pratiques artistiques dans l&rsquo;&eacute;cosyst&egrave;me scientifique et technologique contemporain. L&rsquo;&eacute;dition inaugurale de mars 2017, li&eacute;e aux expositions &laquo; Imprimer le monde &raquo; et &laquo; Ross Lovegrove &raquo;, est plac&eacute;e sous le th&egrave;me &laquo; L&rsquo;espace simul&eacute; ou les formes du digital &raquo;.</li>\r\n</ul>\r\n<p>Le d&eacute;veloppement d&rsquo;une plateforme Web communautaire f&eacute;d&eacute;rant et mettant en contact les diff&eacute;rents acteurs concern&eacute;s (chercheurs, artistes, industriels, incubateurs, investisseurs) et offrant un support &agrave; leurs actions (communication, organisation de programmes particuliers de r&eacute;sidences artistiques, etc.). En sus du consortium de ses partenaires, le projet pilote un r&eacute;seau international de 20 correspondants dans le champ culturel, comprenant notamment le Zentrum fu\u0308r Kunst und Media de Karslruhe, le Victoria and Albert Museum de Londres, la Biennale de Venise, le festival Ars Electronica de Linz, etc.</p>", "content_en": "<p>The Vertigo project was written and selected in response to the first call during the European Commission&rsquo;s H2020 ICT program (Information and Communication Technologies) connected to the STARTS initiative (Science, Technology and the Arts). STARTS encourages synergies between artists and R&amp;D projects in the field of ICT supporting innovation and Vertigo is committed to coordinate a range of actions carried out in this regard throughout Europe focusing on three areas:</p>\r\n<ul>\r\n<li>The organization of artistic residencies assessed by an international and multidisciplinary jury. A budget of 900 K&euro; is dedicated to supporting 3 annual cycles for a total of 45 artistic residency projects that focus on creating, via the production of unique artistic works, prototypes for innovative products using the technologies developed.</li>\r\n<li>The public presentation of different actions carried out during the new, annual event at the Centre Pompidou: Mutations/Cr&eacute;ations. This event features exhibitions, symposia, and artistic events and aims to expose and debate evolutions in artistic practices within the contemporary scientific and technological ecosystem. The theme of the inaugural edition in March 2017, presented in connection with the exhibitions &ldquo;Imprimer le monde (Printing the World)&rdquo; and &ldquo;Ross Lovegrove&rdquo;, is &ldquo;Simulated Space or Digital Forms&rdquo;.</li>\r\n</ul>\r\n<p>The development of a communal online platform enabling different parties (scientists, artists, manufacturers, business incubators, investors) to contact each other and offer support for their actions (communication, organization of specific artistic residency programs, etc.). In addition to the consortium partners, the project oversees an international network of 20 correspondents in the cultural field, including Zentrum f&uuml;r Kunst und Media de Karslruhe, The Victoria and Albert Museum in London, the Venice Biennale, the festival Ars Electronica in Linz, etc.</p>", "date_from": "2016-12-01", "date_to": "2020-05-30", "user": null, "type": "external", "external_id": "732112", "program": 4, "program_type": 26, "call": 2, "lead_team": null, "lead_organization": 1, "website": "http://vertigo.starts.eu/", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [13, 12], "organizations": [619, 622, 623, 620, 621, 624], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 147, "fields": {"keywords_string": "", "site": 1, "title": "iMuSciCA", "title_fr": "iMuSciCA", "title_en": "", "slug": "imuscica", "_meta_title": "", "description": "Projet p\u00e9dagogique qui vise \u00e0 am\u00e9liorer l\u2019acquisition des comp\u00e9tences scientifiques dans l\u2019enseignement secondaire", "description_fr": "Projet p\u00e9dagogique qui vise \u00e0 am\u00e9liorer l\u2019acquisition des comp\u00e9tences scientifiques dans l\u2019enseignement secondaire", "description_en": "Educational project that intends to improve the acquisition of scientific skills in secondary-level education", "gen_description": false, "created": "2017-01-06T09:19:49.435Z", "updated": "2018-07-06T17:01:51.271Z", "status": 2, "publish_date": "2017-01-06T09:19:49Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>iMuSciCA est un projet p&eacute;dagogique qui vise &agrave; am&eacute;liorer l&rsquo;acquisition des comp&eacute;tences scientifiques dans l&rsquo;enseignement secondaire. iMuSciCA apporte de nouvelles m&eacute;thodologies d&rsquo;apprentissage et s&rsquo;appuie sur des technologies innovantes, sur un mode personnalis&eacute; et collaboratif de &laquo; d&eacute;couverte &raquo; afin de rendre de certains enseignements scientifiques &ndash; en particulier les maths et la physique &ndash; plus motivants. Via Modalys, l&rsquo;Ircam apporte ses comp&eacute;tences de lutherie musicale virtuelle afin de donner vie &agrave; des instruments 3D &eacute;labor&eacute;s par l&rsquo;&eacute;l&egrave;ve et dont certains param&egrave;tres (g&eacute;om&eacute;trie, mat&eacute;riau etc) sont modifiables et testables en temps r&eacute;el.</p>\r\n<p>L&rsquo;environnement iMuSciCA, impl&eacute;ment&eacute; gr&acirc;ce &agrave; une collaboration &eacute;troite entre diff&eacute;rents acteurs industriels et acad&eacute;miques, sera test&eacute; et &eacute;valu&eacute; dans un programme pilote, avec un nombre substantiel d&rsquo;&eacute;l&egrave;ves et d&rsquo;enseignants, dans trois pays europ&eacute;ens : Belgique, France et Gr&egrave;ce.</p>", "content_fr": "<p>iMuSciCA est un projet p&eacute;dagogique qui vise &agrave; am&eacute;liorer l&rsquo;acquisition des comp&eacute;tences scientifiques dans l&rsquo;enseignement secondaire. iMuSciCA apporte de nouvelles m&eacute;thodologies d&rsquo;apprentissage et s&rsquo;appuie sur des technologies innovantes, sur un mode personnalis&eacute; et collaboratif de &laquo; d&eacute;couverte &raquo; afin de rendre de certains enseignements scientifiques &ndash; en particulier les maths et la physique &ndash; plus motivants. Via Modalys, l&rsquo;Ircam apporte ses comp&eacute;tences de lutherie musicale virtuelle afin de donner vie &agrave; des instruments 3D &eacute;labor&eacute;s par l&rsquo;&eacute;l&egrave;ve et dont certains param&egrave;tres (g&eacute;om&eacute;trie, mat&eacute;riau etc) sont modifiables et testables en temps r&eacute;el.</p>\r\n<p>L&rsquo;environnement iMuSciCA, impl&eacute;ment&eacute; gr&acirc;ce &agrave; une collaboration &eacute;troite entre diff&eacute;rents acteurs industriels et acad&eacute;miques, sera test&eacute; et &eacute;valu&eacute; dans un programme pilote, avec un nombre substantiel d&rsquo;&eacute;l&egrave;ves et d&rsquo;enseignants, dans trois pays europ&eacute;ens : Belgique, France et Gr&egrave;ce.</p>", "content_en": "<p>iMuSciCA is an educational project that intends to improve the acquisition of scientific skills in secondary-level education. iMuSciCA offers new learning methods using innovative \"discovery\" technologies&mdash;both personalized and collaborative&mdash;in order to make certain scientific subjects, in particular math and physics, more appealing. IRCAM brings its skills in virtual instrument making via Modalys, giving life to 3D instruments created by students. Some of these instruments feature parameters that can be tested and modified (geometry, material, etc.) in real-time.</p>\r\n<p>The iMuSciCA environment, implemented through a collaboration among different industrial and educational partners, will be tested and assessed during a pilot program with a large number of students and teachers in three European countries: Belgium, France, and Greece.</p>", "date_from": "2017-01-01", "date_to": "2019-06-30", "user": null, "type": "external", "external_id": "731861", "program": 4, "program_type": 12, "call": 4, "lead_team": null, "lead_organization": 596, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [613, 616, 612, 1, 614, 611, 615], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 149, "fields": {"keywords_string": "", "site": 1, "title": "ORPHEUS", "title_fr": "ORPHEUS", "title_en": "ORPHEUS", "slug": "orpheus-1", "_meta_title": "", "description": "Object Based Broadcasting", "description_fr": "Object Based Broadcasting", "description_en": "Object Based Broadcasting", "gen_description": false, "created": "2017-01-16T13:49:53.704Z", "updated": "2018-06-29T10:36:16.592Z", "status": 2, "publish_date": "2017-01-16T13:49:53Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les media orient&eacute;s &laquo; objets &raquo; constituent une approche prometteuse pour la cr&eacute;ation et le d&eacute;ploiement de contenus immersifs, interactifs et personnalisables. Ils consistent &agrave; repr&eacute;senter le contenu sous forme d&rsquo;un ensemble de flux de signaux individuels (vid&eacute;o et/ou audio) associ&eacute;s &agrave; des m&eacute;tadonn&eacute;es d&eacute;crivant leurs relations temporelles et spatiales. Cette approche permet non seulement l&rsquo;adaptation du contenu &agrave; diff&eacute;rents dispositifs de restitution mais peut aussi enrichir consid&eacute;rablement l&rsquo;exp&eacute;rience de l&rsquo;utilisateur en offrant notamment diff&eacute;rents degr&eacute;s d&rsquo;interactivit&eacute; : d&eacute;cours non lin&eacute;aire du contenu, navigation spatiale, adaptation au contexte d&rsquo;&eacute;coute (rehaussement des dialogues, mobilit&eacute;...).</p>\r\n<p>Le <a href=\"https://orpheus-audio.eu\" target=\"_blank\">projet ORPHEUS</a> vise &agrave; d&eacute;velopper et valider une cha&icirc;ne de production audio compl&egrave;te bas&eacute;e sur l&rsquo;approche &laquo; objet &raquo;. Dans le projet ORPHEUS l&rsquo;Ircam s&rsquo;occupera plus sp&eacute;cifiquement des aspects li&eacute;s &agrave; la caract&eacute;risation, &agrave; la synth&egrave;se et &agrave; la transmission des effets de r&eacute;verb&eacute;ration.</p>", "content_fr": "<p>Les media orient&eacute;s &laquo; objets &raquo; constituent une approche prometteuse pour la cr&eacute;ation et le d&eacute;ploiement de contenus immersifs, interactifs et personnalisables. Ils consistent &agrave; repr&eacute;senter le contenu sous forme d&rsquo;un ensemble de flux de signaux individuels (vid&eacute;o et/ou audio) associ&eacute;s &agrave; des m&eacute;tadonn&eacute;es d&eacute;crivant leurs relations temporelles et spatiales. Cette approche permet non seulement l&rsquo;adaptation du contenu &agrave; diff&eacute;rents dispositifs de restitution mais peut aussi enrichir consid&eacute;rablement l&rsquo;exp&eacute;rience de l&rsquo;utilisateur en offrant notamment diff&eacute;rents degr&eacute;s d&rsquo;interactivit&eacute; : d&eacute;cours non lin&eacute;aire du contenu, navigation spatiale, adaptation au contexte d&rsquo;&eacute;coute (rehaussement des dialogues, mobilit&eacute;...).</p>\r\n<p>Le <a href=\"https://orpheus-audio.eu\" target=\"_blank\">projet ORPHEUS</a> vise &agrave; d&eacute;velopper et valider une cha&icirc;ne de production audio compl&egrave;te bas&eacute;e sur l&rsquo;approche &laquo; objet &raquo;. Dans le projet ORPHEUS l&rsquo;Ircam s&rsquo;occupera plus sp&eacute;cifiquement des aspects li&eacute;s &agrave; la caract&eacute;risation, &agrave; la synth&egrave;se et &agrave; la transmission des effets de r&eacute;verb&eacute;ration.</p>", "content_en": "<p>Object-based media is a promising approach for creating and deploying interactive, personalized, scalable and immersive content, by representing it as a set of individual assets (video and/or audio) together with metadata describing their temporal and spatial relationships and associations. This allows media objects to be assembled in groundbreaking ways to create new user experiences, offering various levels of interaction: innovative ways for playing contents, spatial navigation, adaptation to listening contexts (enhancement of dialogues, mobility, etc.).</p>\r\n<p>The <a href=\"https://orpheus-audio.eu\" target=\"_blank\">ORPHEUS project</a> aims to develop and validate an object based audio production chain. IRCAM&rsquo;s role in this project focuses on aspects of characterization as well as the synthesis and transmission of reverberation effects.</p>", "date_from": "2015-12-01", "date_to": "2018-05-31", "user": null, "type": "external", "external_id": "687645", "program": 4, "program_type": 7, "call": 6, "lead_team": null, "lead_organization": 88, "website": "https://orpheus-audio.eu/", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [90, 89, 92, 95, 96, 1, 93, 94], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 162, "fields": {"keywords_string": "", "site": 1, "title": "ECOUTE", "title_fr": "ECOUTE", "title_en": null, "slug": "ecoute-1", "_meta_title": null, "description": "ECOUTE", "description_fr": "ECOUTE", "description_en": null, "gen_description": true, "created": "2017-01-18T13:57:34.788Z", "updated": "2017-01-18T13:57:34.796Z", "status": 2, "publish_date": "2017-01-18T13:57:34.786Z", "expiry_date": null, "short_url": null, "in_sitemap": true, "content": "", "content_fr": "", "content_en": null, "date_from": "2005-01-01", "date_to": "2008-03-30", "user": null, "type": "", "external_id": "RIAM-ANR", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 166, "fields": {"keywords_string": "", "site": 1, "title": "EFFICAC(e)", "title_fr": "EFFICAC(e)", "title_en": "EFFICAC(e)", "slug": "efficace", "_meta_title": "", "description": "Environnements r\u00e9actifs pour la compositon musicale assist\u00e9e par ordinateur", "description_fr": "Environnements r\u00e9actifs pour la compositon musicale assist\u00e9e par ordinateur", "description_en": "Extended Frameworks For 'In-Time' Computer-Aided Composition", "gen_description": false, "created": "2017-01-18T13:59:07.871Z", "updated": "2018-07-25T14:37:40.859Z", "status": 2, "publish_date": "2017-01-18T13:59:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet EFFICAC(e) initie une dynamique nouvelle pour le d&eacute;veloppement d&rsquo;outils de composition assist&eacute;e par ordinateur (CAO), explorant de nouveaux rapports entre calcul, temps et interactions articul&eacute;s autour de l&rsquo;environnement OpenMusic et d&rsquo;autres technologies d&eacute;velopp&eacute;es &agrave; l&rsquo;Ircam et au CNMAT. Ce projet vise &agrave; d&eacute;cloisonner les processus de CAO du domaine strictement &laquo; hors temps &raquo; afin de les int&eacute;grer dans une interaction structur&eacute;e avec leur contexte, au niveau de la performance, de l&rsquo;ex&eacute;cution, ou au niveau compositionnel (dans les processus qui conduisent &agrave; la cr&eacute;ation de mat&eacute;riau musical).</p>\r\n<p>Cette d&eacute;marche se concentre dans un certain nombre de directions sp&eacute;cifiques, notamment :</p>\r\n<ul>\r\n<li>Processus r&eacute;actifs en CAO : communication et propagation d&rsquo;&eacute;v&egrave;nements au sein de processus compositionnels ;</li>\r\n<li>Gestion des flux temporels : &eacute;criture, ordonnancement dynamique, relations entre le temps d&eacute;roul&eacute; d&rsquo;ex&eacute;cutions &laquo; musicales &raquo; et les processus de calcul &laquo; hors temps &raquo; ; repr&eacute;sentation des constructions temporelles ;</li>\r\n<li>Contr&ocirc;le, visualisation, ex&eacute;cution de processus des synth&egrave;se et spatialisation sonore ;</li>\r\n<li>Interactions gestuelles dans les processus compositionnels.</li>\r\n</ul>\r\n<p>Diff&eacute;rents aspects critiques dans le domaine de l&rsquo;informatique musicale sont ainsi abord&eacute;s (approches signal vs. symbolique,&nbsp; hors temps vs. temps r&eacute;el), liant la CAO &agrave; des cadres techniques et paradigmatiques divers tels que le traitement, la spatialisation sonore ou l&rsquo;int&eacute;gration gestuelle et ins&eacute;rant contr&ocirc;le et interactions musicales dans des syst&egrave;mes compositionnels abstraits et expressifs.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-13-JS02-0004-01.</p>", "content_fr": "<p>Le projet EFFICAC(e) initie une dynamique nouvelle pour le d&eacute;veloppement d&rsquo;outils de composition assist&eacute;e par ordinateur (CAO), explorant de nouveaux rapports entre calcul, temps et interactions articul&eacute;s autour de l&rsquo;environnement OpenMusic et d&rsquo;autres technologies d&eacute;velopp&eacute;es &agrave; l&rsquo;Ircam et au CNMAT. Ce projet vise &agrave; d&eacute;cloisonner les processus de CAO du domaine strictement &laquo; hors temps &raquo; afin de les int&eacute;grer dans une interaction structur&eacute;e avec leur contexte, au niveau de la performance, de l&rsquo;ex&eacute;cution, ou au niveau compositionnel (dans les processus qui conduisent &agrave; la cr&eacute;ation de mat&eacute;riau musical).</p>\r\n<p>Cette d&eacute;marche se concentre dans un certain nombre de directions sp&eacute;cifiques, notamment :</p>\r\n<ul>\r\n<li>Processus r&eacute;actifs en CAO : communication et propagation d&rsquo;&eacute;v&egrave;nements au sein de processus compositionnels ;</li>\r\n<li>Gestion des flux temporels : &eacute;criture, ordonnancement dynamique, relations entre le temps d&eacute;roul&eacute; d&rsquo;ex&eacute;cutions &laquo; musicales &raquo; et les processus de calcul &laquo; hors temps &raquo; ; repr&eacute;sentation des constructions temporelles ;</li>\r\n<li>Contr&ocirc;le, visualisation, ex&eacute;cution de processus des synth&egrave;se et spatialisation sonore ;</li>\r\n<li>Interactions gestuelles dans les processus compositionnels.</li>\r\n</ul>\r\n<p>Diff&eacute;rents aspects critiques dans le domaine de l&rsquo;informatique musicale sont ainsi abord&eacute;s (approches signal vs. symbolique,&nbsp; hors temps vs. temps r&eacute;el), liant la CAO &agrave; des cadres techniques et paradigmatiques divers tels que le traitement, la spatialisation sonore ou l&rsquo;int&eacute;gration gestuelle et ins&eacute;rant contr&ocirc;le et interactions musicales dans des syst&egrave;mes compositionnels abstraits et expressifs.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-13-JS02-0004-01.</p>", "content_en": "<p>The objective of this project is the development of tools for computer-assisted composition (CAC) exploring new relations between computation, time, and interactions in the OpenMusic environment and in other technologies developed at IRCAM and CNMAT. This project endeavors to take CAC processes beyond the traditional \"offline\" domain to include them in a structured interaction in their context be it performance, execution, or composition (in the processes that lead to the creation of musical material).</p>\r\n<p>During this project, we will focus on a number of specific directions, such as:</p>\r\n<ul>\r\n<li>Reactive processes for computer-aided composition: communication and propagation of events and changes in compositional processes</li>\r\n<li>Management of temporal flows: Writing, dynamic scheduling, relations between musical execution time and offline computation processes; representation of temporal constructs</li>\r\n<li>Control, visualization and execution of sound synthesis and spatialization processes</li>\r\n<li>Gestural interactions in compositional processes</li>\r\n</ul>\r\n<p>Several critical antagonisms in the domain of computer music are addressed in this project (signal versus symbolic approaches, offline versus real-time). By bridging high-level computer-aided composition systems with other disciplines and frameworks such as sound processing, spatialization and gestural integration, it includes control and interactions in abstract and expressive compositional models.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference : ANR-13-JS02-0004-01.</p>", "date_from": "2013-10-01", "date_to": "2017-03-31", "user": null, "type": "external", "external_id": "ANR-13-JS02-0004-01", "program": 1, "program_type": 15, "call": null, "lead_team": null, "lead_organization": null, "website": "http://repmus.ircam.fr/efficace/home", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2, 7, 5], "organizations": [137], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 167, "fields": {"keywords_string": "", "site": 1, "title": "DYCI2", "title_fr": "DYCI2", "title_en": "DYCI2", "slug": "dyci2-1", "_meta_title": "", "description": "Dynamiques cr\u00e9atives de l'interaction improvis\u00e9e", "description_fr": "Dynamiques cr\u00e9atives de l'interaction improvis\u00e9e", "description_en": "Creative Dynamics for Improvised Interaction", "gen_description": false, "created": "2017-01-18T13:59:07.882Z", "updated": "2018-07-25T14:36:56.863Z", "status": 2, "publish_date": "2017-01-18T13:59:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet Dynamiques cr&eacute;atives de l&rsquo;interaction improvis&eacute;e porte sur la constitution, l&rsquo;adaptation et la mise en &oelig;uvre effective de mod&egrave;les performants d&rsquo;&eacute;coute artificielle, d&rsquo;apprentissage, d&rsquo;interaction et de cr&eacute;ation automatique de contenus musicaux pour permettre la constitution d&rsquo;avatars musicaux num&eacute;riques, autonomes, cr&eacute;atifs, capables de s&rsquo;int&eacute;grer de fa&ccedil;on interactive et artistiquement cr&eacute;dible dans des dispositifs humains vari&eacute;s tels que la sc&egrave;ne vivante, la (post-) production, la p&eacute;dagogie, ou de contribuer &agrave; terme aux comp&eacute;tences perceptives et communicatives de syst&egrave;mes cyber-physiques.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le projet met en avant l&rsquo;interaction improvis&eacute;e, &agrave; la fois comme mod&egrave;le anthropologique et cognitif de l&rsquo;action et de la d&eacute;cision, comme sch&eacute;ma de d&eacute;couverte et d&rsquo;apprentissage non supervis&eacute;, et comme outil discursif pour l&rsquo;&eacute;change humain &ndash; artefact num&eacute;rique, dans une perspective de mod&eacute;lisation du style et de l&rsquo;interaction.</p>\r\n<p>L&rsquo;objectif est de constituer des agents cr&eacute;atifs autonomes par apprentissage direct r&eacute;sultant d&rsquo;une exposition au jeu vivant (live) de musiciens humains improvisant, en cr&eacute;ant une boucle de r&eacute;troaction stylistique par l&rsquo;exposition simultan&eacute;e de l&rsquo;humain aux productions improvis&eacute;es des artefacts num&eacute;riques eux-m&ecirc;mes, donc &agrave; partir d&rsquo;une situation de communication humain-artefact &eacute;voluant dans une dynamique complexe. Un apprentissage hors-ligne sur des archives peut aussi &ecirc;tre anticip&eacute; pour &laquo; colorer &raquo; stylistiquement l&rsquo;individualit&eacute; num&eacute;rique des agents ou situer l&rsquo;exp&eacute;rience dans un genre (jazz, classique, pop etc.). La situation de jeu &laquo; live &raquo; peut-&ecirc;tre &eacute;tendue &agrave; des applications in&eacute;dites comme l&rsquo;interaction d&rsquo;utilisateurs de comp&eacute;tences vari&eacute;es avec des archives audiovisuelles ressuscit&eacute;es dynamiquement dans sc&eacute;narios cr&eacute;atifs ou p&eacute;dagogiques de co-improvisation, ainsi que dans le cadre g&eacute;n&eacute;ral des nouvelles formes narratives &agrave; l&rsquo;&oelig;uvre dans les m&eacute;dias num&eacute;riques interactifs/g&eacute;n&eacute;ratifs et la r&eacute;alit&eacute; virtuelle.</p>\r\n<p>Le but est aussi bien de constituer une connaissance proc&eacute;durale de la musique par cette interaction que de susciter une riche exp&eacute;rience instantan&eacute;e communicative humain-num&eacute;rique, susceptible de renvoyer une satisfaction esth&eacute;tique &agrave; l&rsquo;utilisateur, d&rsquo;enrichir sa production sonore et musicale, de &laquo; dialoguer &raquo; avec lui, de l&rsquo;imiter ou le contredire, et, en g&eacute;n&eacute;ral, de stimuler et dynamiser l&rsquo;exp&eacute;rience de jeu collectif. Cette interaction humain-artefact sera &eacute;tendue &agrave; une interaction artefact-artefact dans des configurations riches (plusieurs humains, plusieurs artefacts num&eacute;riques en r&eacute;seau). Au fur et &agrave; mesure de l&rsquo;exp&eacute;rience, se formera une individualit&eacute; musicale num&eacute;rique autonome capable d&rsquo;intervenir de mani&egrave;re cr&eacute;dible dans des situations d&rsquo;interaction collective.</p>\r\n<p>Une entit&eacute; cr&eacute;ative dans un contexte audio-musical subsume ainsi une collection d&rsquo;agents concurrents, contributifs et comp&eacute;titifs, capables d&rsquo;apprentissage interactif, qui prennent en charge des t&acirc;ches d&rsquo;&eacute;coute artificielle, de d&eacute;couverte de structures temporelles &agrave; court et long terme, de mod&eacute;lisation du style, de g&eacute;n&eacute;ration de s&eacute;quences symboliques, de rendu audio temps r&eacute;el, mais aussi de visualisation et d&rsquo;IHM.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-14-CE24-0002-01.</p>", "content_fr": "<p>Le projet Dynamiques cr&eacute;atives de l&rsquo;interaction improvis&eacute;e porte sur la constitution, l&rsquo;adaptation et la mise en &oelig;uvre effective de mod&egrave;les performants d&rsquo;&eacute;coute artificielle, d&rsquo;apprentissage, d&rsquo;interaction et de cr&eacute;ation automatique de contenus musicaux pour permettre la constitution d&rsquo;avatars musicaux num&eacute;riques, autonomes, cr&eacute;atifs, capables de s&rsquo;int&eacute;grer de fa&ccedil;on interactive et artistiquement cr&eacute;dible dans des dispositifs humains vari&eacute;s tels que la sc&egrave;ne vivante, la (post-) production, la p&eacute;dagogie, ou de contribuer &agrave; terme aux comp&eacute;tences perceptives et communicatives de syst&egrave;mes cyber-physiques.</p>\r\n<h2>Description des travaux/Objectifs</h2>\r\n<p>Le projet met en avant l&rsquo;interaction improvis&eacute;e, &agrave; la fois comme mod&egrave;le anthropologique et cognitif de l&rsquo;action et de la d&eacute;cision, comme sch&eacute;ma de d&eacute;couverte et d&rsquo;apprentissage non supervis&eacute;, et comme outil discursif pour l&rsquo;&eacute;change humain &ndash; artefact num&eacute;rique, dans une perspective de mod&eacute;lisation du style et de l&rsquo;interaction.</p>\r\n<p>L&rsquo;objectif est de constituer des agents cr&eacute;atifs autonomes par apprentissage direct r&eacute;sultant d&rsquo;une exposition au jeu vivant (live) de musiciens humains improvisant, en cr&eacute;ant une boucle de r&eacute;troaction stylistique par l&rsquo;exposition simultan&eacute;e de l&rsquo;humain aux productions improvis&eacute;es des artefacts num&eacute;riques eux-m&ecirc;mes, donc &agrave; partir d&rsquo;une situation de communication humain-artefact &eacute;voluant dans une dynamique complexe. Un apprentissage hors-ligne sur des archives peut aussi &ecirc;tre anticip&eacute; pour &laquo; colorer &raquo; stylistiquement l&rsquo;individualit&eacute; num&eacute;rique des agents ou situer l&rsquo;exp&eacute;rience dans un genre (jazz, classique, pop etc.). La situation de jeu &laquo; live &raquo; peut-&ecirc;tre &eacute;tendue &agrave; des applications in&eacute;dites comme l&rsquo;interaction d&rsquo;utilisateurs de comp&eacute;tences vari&eacute;es avec des archives audiovisuelles ressuscit&eacute;es dynamiquement dans sc&eacute;narios cr&eacute;atifs ou p&eacute;dagogiques de co-improvisation, ainsi que dans le cadre g&eacute;n&eacute;ral des nouvelles formes narratives &agrave; l&rsquo;&oelig;uvre dans les m&eacute;dias num&eacute;riques interactifs/g&eacute;n&eacute;ratifs et la r&eacute;alit&eacute; virtuelle.</p>\r\n<p>Le but est aussi bien de constituer une connaissance proc&eacute;durale de la musique par cette interaction que de susciter une riche exp&eacute;rience instantan&eacute;e communicative humain-num&eacute;rique, susceptible de renvoyer une satisfaction esth&eacute;tique &agrave; l&rsquo;utilisateur, d&rsquo;enrichir sa production sonore et musicale, de &laquo; dialoguer &raquo; avec lui, de l&rsquo;imiter ou le contredire, et, en g&eacute;n&eacute;ral, de stimuler et dynamiser l&rsquo;exp&eacute;rience de jeu collectif. Cette interaction humain-artefact sera &eacute;tendue &agrave; une interaction artefact-artefact dans des configurations riches (plusieurs humains, plusieurs artefacts num&eacute;riques en r&eacute;seau). Au fur et &agrave; mesure de l&rsquo;exp&eacute;rience, se formera une individualit&eacute; musicale num&eacute;rique autonome capable d&rsquo;intervenir de mani&egrave;re cr&eacute;dible dans des situations d&rsquo;interaction collective.</p>\r\n<p>Une entit&eacute; cr&eacute;ative dans un contexte audio-musical subsume ainsi une collection d&rsquo;agents concurrents, contributifs et comp&eacute;titifs, capables d&rsquo;apprentissage interactif, qui prennent en charge des t&acirc;ches d&rsquo;&eacute;coute artificielle, de d&eacute;couverte de structures temporelles &agrave; court et long terme, de mod&eacute;lisation du style, de g&eacute;n&eacute;ration de s&eacute;quences symboliques, de rendu audio temps r&eacute;el, mais aussi de visualisation et d&rsquo;IHM.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-14-CE24-0002-01.</p>", "content_en": "<p>The project on creative dynamics for improvised interaction focuses on the creation, adaptation, and implementation of effective models for artificial listening, learning, and interaction as well as the automatic generation of musical contents enabling the creation of digital musical avatars that are creative and either capable of being incorporated in an interactive and artistically convincing manner within a range of human systems such as live performances, (post) production, or education or to contribute perceptive and communicative skills to cyber-physical systems.</p>\r\n<h2 id=\"section-0\">Project Description &amp; Goals</h2>\r\n<p>The project highlights improvised interaction, both as an anthropological and cognitive model of action and decision, as a schema of discovery and unsupervised learning and as<br />a discursive tool for human&mdash; digital artifact interaction with the aim of modeling style and interaction.</p>\r\n<p>The objective is to produce creative agents that become autonomous through direct learning resulting from contact with live performances by human improvising musicians, creating a loop of stylistic retroaction via the simultaneous exposition of humans to the productions of digital artifacts that improvised themselves. This creates a situation of human-artifact communication that evolves in a complex dynamic. Off-line learning with archives can also be anticipated to systematically \"color\" the digital individuality of the agents or to situate the experience within different genres (jazz, classic, pop, etc.). The live performance situation could be extended to novel applications such as interaction with users that have a range of skills, with audio-visual archives dynamically resuscitated in artistic or educations scenarios of co-improvisation, as well as in the general situation of new narrative forms of the work in interactive/generative digital media and virtual reality.</p>\r\n<p>The goal is also to constitute procedural knowledge of music through this interaction and to produce a rich instantaneous human-digital experience, likely to provide aesthetic satisfaction for the user, to enrich his sound and musical production, to implement a dialog with him, to imitate or contradict him, and in general, to stimulate and revitalize the experience of collective performance. This human-artifact interaction will be extended to artifactartifact interaction in diverse configurations (several humans, a network of several digital artifacts). During the experiment, an autonomous musical individuality will form an individuality capable of intervening in a plausible fashion in situations of collective interaction.</p>\r\n<p>A creative entity in an audio-musical context thus subsumes a collection of concurrent, contributing, and competitive agents capable of interactive learning, of taking charge of artificial learning tasks, of discovering short and longterm temporal structures, of modeling style, of generating symbolic sequences, of real-time audio rendering, but also of visualization and human-machine interfaces.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference : ANR-14-CE24-0002-01.</p>", "date_from": "2014-10-01", "date_to": "2018-09-30", "user": null, "type": "external", "external_id": "ANR-14-CE24-0002-01", "program": 1, "program_type": 17, "call": null, "lead_team": null, "lead_organization": null, "website": "http://repmus.ircam.fr/dyci2/", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [148, 1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 168, "fields": {"keywords_string": "", "site": 1, "title": "Skat-VG", "title_fr": "Skat-VG", "title_en": "Skat-VG", "slug": "skat-vg", "_meta_title": "", "description": "Sketching Audio Technologies using Vocalizations and Gestures", "description_fr": "Sketching Audio Technologies using Vocalizations and Gestures", "description_en": "Sketching Audio Technologies using Vocalizations and Gestures", "gen_description": false, "created": "2017-01-18T13:59:08.138Z", "updated": "2019-01-02T10:31:06.772Z", "status": 2, "publish_date": "2017-01-18T13:59:08Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;esquisse est une &eacute;tape fondamentale des activit&eacute;s de design. Dans le design visuel, le syst&egrave;me &laquo; papier + crayon &raquo; est toujours le principal outil utilis&eacute; pour produire, en peu de temps, une grande vari&eacute;t&eacute; de concepts et d&rsquo;id&eacute;es. Cela &eacute;tant, dans le design produit et le design media, le comportement sonore des objets consid&eacute;r&eacute;s rev&ecirc;t un caract&egrave;re essentiel, dans la mesure o&ugrave; le son peut v&eacute;hiculer des propri&eacute;t&eacute;s d&rsquo;esth&eacute;tique et d&rsquo;homog&eacute;n&eacute;it&eacute; dans un contexte d&rsquo;usage interactif. La question qui se pose est alors de savoir comment esquisser la dimension sonore d&rsquo;un objet, dans les phases pr&eacute;liminaires de sa conception. Les sons non verbaux &ndash; mieux que la parole &ndash; sont naturellement et spontan&eacute;ment utilis&eacute;s dans la vie de tous les jours pour d&eacute;crire et imiter des &eacute;v&eacute;nements sonores ; ils sont, en outre, souvent associ&eacute;s &agrave; des gestes manuels expressifs afin de les qualifier, de les compl&eacute;ter ou bien de les mettre en valeur. Le projet SkAT-vG a pour but de permettre aux designers d&rsquo;utiliser directement leur voix et leurs mains pour esquisser les caract&eacute;ristiques sonores d&rsquo;un objet, facilitant ainsi l&rsquo;exploitation des possibilit&eacute;s fonctionnelles et esth&eacute;tiques du son. Le c&oelig;ur de ce syst&egrave;me r&eacute;side dans un dispositif capable d&rsquo;interpr&eacute;ter les intentions des utilisateurs exprim&eacute;es au moyen d&rsquo;imitations vocales et de gestes, de s&eacute;lectionner des modules de synth&egrave;ses sonores appropri&eacute;s, et de rendre ainsi possible le partage et le raffinement des id&eacute;es de mani&egrave;re it&eacute;rative. Pour atteindre ces objectifs, le projet SkAT-vG s&rsquo;appuie sur un consortium pluridisciplinaire de partenaires poss&eacute;dant des expertises compl&eacute;mentaires : analyse des m&eacute;canismes articulatoires de la voix, perception et cognition sonores, apprentissage automatique, design interactif, et d&eacute;veloppement d&rsquo;applications audio. Les principales t&acirc;ches du projet comprennent des &eacute;tudes de cas pour comprendre comment les imitations vocales et les gestes sont naturellement utilis&eacute;s dans la communication sur le son, l&rsquo;analyse de pratiques expertes aupr&egrave;s de designers sonores professionnels, des &eacute;tudes exp&eacute;rimentales et fondamentales portant sur l&rsquo;identification des sons via la production d&rsquo;imitations vocales ou de gestes, l&rsquo;analyse des gestes, l&rsquo;apprentissage automatique et le d&eacute;veloppement d&rsquo;outils d&rsquo;esquisses sonores.</p>\r\n<p>Le projet vise plusieurs objectifs scientifiques :</p>\r\n<ul>\r\n<li>&eacute;tendre les connaissances existantes dans le domaine de la perception et la production d&rsquo;imitations vocales et de gestes expressifs ;</li>\r\n<li>d&eacute;velopper des algorithmes de classification automatique d&rsquo;imitations vocales et gestuelles, fond&eacute;s sur l&rsquo;imitation elle-m&ecirc;me, en combinant l&rsquo;analyse du signal sonore avec des m&eacute;canismes physiologiques de la production vocale ;</li>\r\n<li>explorer l&rsquo;efficacit&eacute; des esquisses sonores et gestuelles dans le domaine du design sonore interactif, en exploitant la classification automatique &agrave; des fins de s&eacute;lection et param&eacute;trisation de mod&egrave;les de synth&egrave;se sonore ;</li>\r\n<li>d&eacute;velopper des applications de cr&eacute;ation et de traitement sonores intuitives, utilisant la voix et les gestes.</li>\r\n</ul>", "content_fr": "<p>L&rsquo;esquisse est une &eacute;tape fondamentale des activit&eacute;s de design. Dans le design visuel, le syst&egrave;me &laquo; papier + crayon &raquo; est toujours le principal outil utilis&eacute; pour produire, en peu de temps, une grande vari&eacute;t&eacute; de concepts et d&rsquo;id&eacute;es. Cela &eacute;tant, dans le design produit et le design media, le comportement sonore des objets consid&eacute;r&eacute;s rev&ecirc;t un caract&egrave;re essentiel, dans la mesure o&ugrave; le son peut v&eacute;hiculer des propri&eacute;t&eacute;s d&rsquo;esth&eacute;tique et d&rsquo;homog&eacute;n&eacute;it&eacute; dans un contexte d&rsquo;usage interactif. La question qui se pose est alors de savoir comment esquisser la dimension sonore d&rsquo;un objet, dans les phases pr&eacute;liminaires de sa conception. Les sons non verbaux &ndash; mieux que la parole &ndash; sont naturellement et spontan&eacute;ment utilis&eacute;s dans la vie de tous les jours pour d&eacute;crire et imiter des &eacute;v&eacute;nements sonores ; ils sont, en outre, souvent associ&eacute;s &agrave; des gestes manuels expressifs afin de les qualifier, de les compl&eacute;ter ou bien de les mettre en valeur. Le projet SkAT-vG a pour but de permettre aux designers d&rsquo;utiliser directement leur voix et leurs mains pour esquisser les caract&eacute;ristiques sonores d&rsquo;un objet, facilitant ainsi l&rsquo;exploitation des possibilit&eacute;s fonctionnelles et esth&eacute;tiques du son. Le c&oelig;ur de ce syst&egrave;me r&eacute;side dans un dispositif capable d&rsquo;interpr&eacute;ter les intentions des utilisateurs exprim&eacute;es au moyen d&rsquo;imitations vocales et de gestes, de s&eacute;lectionner des modules de synth&egrave;ses sonores appropri&eacute;s, et de rendre ainsi possible le partage et le raffinement des id&eacute;es de mani&egrave;re it&eacute;rative. Pour atteindre ces objectifs, le projet SkAT-vG s&rsquo;appuie sur un consortium pluridisciplinaire de partenaires poss&eacute;dant des expertises compl&eacute;mentaires : analyse des m&eacute;canismes articulatoires de la voix, perception et cognition sonores, apprentissage automatique, design interactif, et d&eacute;veloppement d&rsquo;applications audio. Les principales t&acirc;ches du projet comprennent des &eacute;tudes de cas pour comprendre comment les imitations vocales et les gestes sont naturellement utilis&eacute;s dans la communication sur le son, l&rsquo;analyse de pratiques expertes aupr&egrave;s de designers sonores professionnels, des &eacute;tudes exp&eacute;rimentales et fondamentales portant sur l&rsquo;identification des sons via la production d&rsquo;imitations vocales ou de gestes, l&rsquo;analyse des gestes, l&rsquo;apprentissage automatique et le d&eacute;veloppement d&rsquo;outils d&rsquo;esquisses sonores.</p>\r\n<p>Le projet vise plusieurs objectifs scientifiques :</p>\r\n<ul>\r\n<li>&eacute;tendre les connaissances existantes dans le domaine de la perception et la production d&rsquo;imitations vocales et de gestes expressifs ;</li>\r\n<li>d&eacute;velopper des algorithmes de classification automatique d&rsquo;imitations vocales et gestuelles, fond&eacute;s sur l&rsquo;imitation elle-m&ecirc;me, en combinant l&rsquo;analyse du signal sonore avec des m&eacute;canismes physiologiques de la production vocale ;</li>\r\n<li>explorer l&rsquo;efficacit&eacute; des esquisses sonores et gestuelles dans le domaine du design sonore interactif, en exploitant la classification automatique &agrave; des fins de s&eacute;lection et param&eacute;trisation de mod&egrave;les de synth&egrave;se sonore ;</li>\r\n<li>d&eacute;velopper des applications de cr&eacute;ation et de traitement sonores intuitives, utilisant la voix et les gestes.</li>\r\n</ul>", "content_en": "<p>Sketching is at the root of any design activity. In visual design, hand and pencil are still the primary tools used to produce a large variety of initial concepts in a very short time. However, in product and media design the sonic behavior of objects is also of primary importance, as sounds may afford seamless and aesthetically pleasing interactions. But how might one sketch the auditory aspects and sonic behavior of objects, in the early stages of the design process? Non-verbal sounds, more than speech, are naturally and spontaneously used in everyday life to describe and imitate sonic events, often accompanied by manual expressive gestures that complement, qualify, or emphasize them. The SkAT-vG project aims at enabling designers to use their voice and hands, directly, to sketch the auditory aspects of an object, thereby making it easier to exploit the functional and aesthetic possibilities of sound. The core of this framework is a system able to interpret users&rsquo; intentions through gestures and vocalizations, to select appropriate sound synthesis modules, and to enable iterative refinement and sharing, as it is commonly done with drawn sketches in the early stages of the design process. To reach its goal, the SkAT-vG project is based on an original mixture of complementary expertise: voice production, gesture analysis, cognitive psychology, machine learning, interaction design, and audio application development. The project tasks include case studies of how people naturally use vocalizations and gestures to communicate sounds, evaluation of current practices of sound designers, basic studies of sound identification trough vocalizations and gestural production, gesture analysis and machine learning, and development of the sketching tools.</p>\r\n<p>The project has several scientific goals:</p>\r\n<ul>\r\n<li>Expand existing knowledge in the domain of perception and production of vocal imitations and expressive gestures</li>\r\n<li>Develop algorithms for automatic classification of vocal and gestural imitations, based on imitation itself, combining the analysis of a sound signal with the physiological mechanisms of vocal production</li>\r\n<li>Explore the effectiveness of sound and gestural sketches in the domain of interactive sound design, by taking advantage of automatic classification for selection and parameters of sound synthesis models</li>\r\n<li>Develop applications for intuitive sound creation and processing using voice and gesture</li>\r\n</ul>", "date_from": "2014-01-01", "date_to": "2017-01-31", "user": null, "type": "external", "external_id": "618067", "program": 8, "program_type": 22, "call": null, "lead_team": 3, "lead_organization": 600, "website": "http://skatvg.iuav.it/", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [4, 7, 3], "organizations": [172, 135, 171], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 169, "fields": {"keywords_string": "", "site": 1, "title": "Wave", "title_fr": "Wave", "title_en": "Wave", "slug": "wave", "_meta_title": "", "description": "Web audio : \u00e9dition/visualisation", "description_fr": "Web audio : \u00e9dition/visualisation", "description_en": "Web Audio: Editing/Visualization", "gen_description": false, "created": "2017-01-18T13:59:09.262Z", "updated": "2018-07-25T14:51:59.150Z", "status": 2, "publish_date": "2017-01-18T13:59:09Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet WAvE vise &agrave; formaliser de nouveaux moyens d&rsquo;&eacute;dition, de visualisation et d&rsquo;interaction avec des objets temporels audiovisuels diffus&eacute;s sur le web.</p>\r\n<p>Il donnera lieu &agrave; la conception et au d&eacute;veloppement de briques logicielles concernant les interfaces et interactions utilisateurs, les interfaces audionum&eacute;riques, les interfaces clients/serveurs, et leurs &eacute;changes de donn&eacute;es. Ces diff&eacute;rentes briques logicielles seront issues de l&rsquo;analyse de pratiques musicales expertes confront&eacute;es &agrave; des usages ordinaires d&rsquo;applications et standards du web, dans le but de proposer des cas d&rsquo;usages innovants.</p>\r\n<p>Le projet a pour objectif d&rsquo;int&eacute;grer ces briques logicielles pour d&eacute;velopper de nouveaux services et enrichir ceux existant. Moyens nouveaux de consommer et partager des documents musicaux et audiovisuels en ligne, ces services seront mis en place dans le cadre du projet et mis &agrave; disposition des utilisateurs par les partenaires du projet dans le cadre de d&eacute;veloppements de leurs produits et/ou nouvelles offres commerciales.</p>\r\n<p>Le projet utilisera d&rsquo;une part les standards du W3C (particuli&egrave;rement HTML5 et la nouvelle plateforme web), en les compl&eacute;tant si besoin, et d&rsquo;autre part, les possibilit&eacute;s d&rsquo;interaction offertes par les nouveaux terminaux, afin de proposer des interfaces coh&eacute;rentes, accessibles et innovantes et des nouvelles exp&eacute;riences utilisateurs adapt&eacute;es &agrave; la consultation, &agrave; l&rsquo;interaction, &agrave; l&rsquo;annotation, &agrave; la transformation et au partage d&rsquo;objets temporels. Dans un contexte technologique web prot&eacute;iforme, la formalisation et l&rsquo;instanciation de ces multiples interfaces dans diff&eacute;rentes technologies et prenant appui sur des standards et recommandations du W3C contribueront &agrave; l&rsquo;&eacute;mergence d&rsquo;un web v&eacute;ritablement hyperm&eacute;dia et interactif.</p>\r\n<p>Dans un contexte de crise des industries culturelles, et particuli&egrave;rement celles ayant attrait &agrave; la musique, les entreprises partenaires et les partenaires institutionnels pourront mettre &agrave; profit ces cas d&rsquo;usage et exploiter de nouveaux march&eacute;s &agrave; travers des dispositifs innovants d&rsquo;&eacute;coute et de consultation interactives et enrichies de flux temporels sur le web. Le projet s&rsquo;est notamment traduit par l&rsquo;organisation &agrave; l&rsquo;Ircam, les 26, 27 et 28 janvier 2015, de la premi&egrave;re Web Audio Conference (WAC) en collaboration avec Mozilla, Google, et le W3C.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-12-CORD-027-01.</p>", "content_fr": "<p>Le projet WAvE vise &agrave; formaliser de nouveaux moyens d&rsquo;&eacute;dition, de visualisation et d&rsquo;interaction avec des objets temporels audiovisuels diffus&eacute;s sur le web.</p>\r\n<p>Il donnera lieu &agrave; la conception et au d&eacute;veloppement de briques logicielles concernant les interfaces et interactions utilisateurs, les interfaces audionum&eacute;riques, les interfaces clients/serveurs, et leurs &eacute;changes de donn&eacute;es. Ces diff&eacute;rentes briques logicielles seront issues de l&rsquo;analyse de pratiques musicales expertes confront&eacute;es &agrave; des usages ordinaires d&rsquo;applications et standards du web, dans le but de proposer des cas d&rsquo;usages innovants.</p>\r\n<p>Le projet a pour objectif d&rsquo;int&eacute;grer ces briques logicielles pour d&eacute;velopper de nouveaux services et enrichir ceux existant. Moyens nouveaux de consommer et partager des documents musicaux et audiovisuels en ligne, ces services seront mis en place dans le cadre du projet et mis &agrave; disposition des utilisateurs par les partenaires du projet dans le cadre de d&eacute;veloppements de leurs produits et/ou nouvelles offres commerciales.</p>\r\n<p>Le projet utilisera d&rsquo;une part les standards du W3C (particuli&egrave;rement HTML5 et la nouvelle plateforme web), en les compl&eacute;tant si besoin, et d&rsquo;autre part, les possibilit&eacute;s d&rsquo;interaction offertes par les nouveaux terminaux, afin de proposer des interfaces coh&eacute;rentes, accessibles et innovantes et des nouvelles exp&eacute;riences utilisateurs adapt&eacute;es &agrave; la consultation, &agrave; l&rsquo;interaction, &agrave; l&rsquo;annotation, &agrave; la transformation et au partage d&rsquo;objets temporels. Dans un contexte technologique web prot&eacute;iforme, la formalisation et l&rsquo;instanciation de ces multiples interfaces dans diff&eacute;rentes technologies et prenant appui sur des standards et recommandations du W3C contribueront &agrave; l&rsquo;&eacute;mergence d&rsquo;un web v&eacute;ritablement hyperm&eacute;dia et interactif.</p>\r\n<p>Dans un contexte de crise des industries culturelles, et particuli&egrave;rement celles ayant attrait &agrave; la musique, les entreprises partenaires et les partenaires institutionnels pourront mettre &agrave; profit ces cas d&rsquo;usage et exploiter de nouveaux march&eacute;s &agrave; travers des dispositifs innovants d&rsquo;&eacute;coute et de consultation interactives et enrichies de flux temporels sur le web. Le projet s&rsquo;est notamment traduit par l&rsquo;organisation &agrave; l&rsquo;Ircam, les 26, 27 et 28 janvier 2015, de la premi&egrave;re Web Audio Conference (WAC) en collaboration avec Mozilla, Google, et le W3C.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-12-CORD-027-01.</p>", "content_en": "<p>The WAvE project aims to formalize new means of editing, visualization, and interaction with temporal audiovisual objects online.</p>\r\n<p>This project will lead to the design and development of software bricks concerning user interfaces and interactions, digital audio interfaces, client/server interfaces, and their data exchanges. These software bricks will come from the results of the analysis of expert musical practices compared to their ordinary use in web applications and standards, with the goal of offering innovative uses for them.</p>\r\n<p>The project&rsquo;s objective is to integrate these software bricks in existing software to develop new services and improve existing ones. New means of purchasing and sharing musical and audiovisual documents online, these services will be put in place during the project and made available to users by project partners using the W3C standards (particularly HTML5 and the new Web platform), completing them if necessary, and also proposing interaction via new terminals in order to offer coherent interfaces, accessible and innovative, and new user experiences adapted for consultation, interaction, annotation, transformation, and sharing of temporal objects. In a fluctuating web technology situation, the formalization and instanciation of these multiple interfaces in different technologies supported by WC3 standards and recommendations will contribute to the surfacing of a truly hypermedia and interactive Internet.</p>\r\n<p>In the context of the cultural industry&rsquo;s crisis, and particularly those connected to music, companies and institutions can make use of these cases and explore new markets via innovative systems for listening and consultation that are interactive and enhanced with temporal streaming from the Internet. This project led to the organization of the first Web Audio Conference (WAC) in collaboration with Mozilla, Google, and the W3C at IRCAM on January 26, 27, and 28, 2015.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-12-CORD-027-01.</p>", "date_from": "2012-11-01", "date_to": "2015-10-31", "user": null, "type": "external", "external_id": "ANR-12-CORD-027-01", "program": 1, "program_type": 1, "call": null, "lead_team": null, "lead_organization": 1, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6, 7], "organizations": [160, 161, 162], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 172, "fields": {"keywords_string": "", "site": 1, "title": "\u00c9criture du temps synchrone", "title_fr": "\u00c9criture du temps synchrone", "title_en": "Writing Timed Interactions and Musical Synchronizations", "slug": "ecriture-du-temps-synchrone", "_meta_title": "", "description": "\u00c9criture du temps et interaction de la partition pour la partie \u00e9lectronique", "description_fr": "\u00c9criture du temps et interaction de la partition pour la partie \u00e9lectronique", "description_en": "Definition of complex interactions between performers and live electronics", "gen_description": false, "created": "2017-02-10T11:31:31.306Z", "updated": "2018-06-29T10:27:12.598Z", "status": 2, "publish_date": "2017-02-10T11:31:31Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Dans le contexte de l&rsquo;ex&eacute;cution d&rsquo;&oelig;uvres contemporaines associant parties instrumentales et informatiques, le suivi de partition est une technique souvent employ&eacute;e pour la synchronisation de l&rsquo;accompagnement &eacute;lectronique avec un instrument soliste. La partition est enregistr&eacute;e dans l&rsquo;ordinateur dans un format sp&eacute;cifique contenant &agrave; la fois les &eacute;l&eacute;ments essentiels de la partition instrumentale et une &eacute;criture de la partie informatique avec un langage musical synchrone. Lors de l&rsquo;ex&eacute;cution, l&rsquo;analyse en temps r&eacute;el du son et/ou du geste capt&eacute; aupr&egrave;s de l&rsquo;interpr&egrave;te est mise en comparaison avec la partition enregistr&eacute;e. L&rsquo;algorithme de suivi d&eacute;termine &agrave; chaque instant de l&rsquo;interpr&eacute;tation la position correspondante dans la partition et synchronise les processus programm&eacute;s dans la partie &eacute;lectronique de l&rsquo;&oelig;uvre.</p>\r\n<p>Le suiveur de partition (Antescofo) int&egrave;gre d&eacute;sormais &eacute;galement un langage synchrone temps r&eacute;el, permettant une &eacute;criture du temps et une interaction pour la partie &eacute;lectronique. L&rsquo;utilisation de cette technologie permet une &eacute;criture coh&eacute;rente entre les parties &eacute;lectroniques et instrumentales au temps de la composition, et une ex&eacute;cution synchrone et polyphonique des modules &eacute;lectroniques avec les musiciens en temps r&eacute;el. Son d&eacute;veloppement est pr&eacute;vu pour une adaptation aux diff&eacute;rentes familles d&rsquo;instruments et &agrave; la reconnaissance de formes musicales, ainsi qu&rsquo;une augmentation des paradigmes d&rsquo;&eacute;criture synchrone pour la partie &eacute;lectronique.</p>\r\n<p>Ce dispositif int&egrave;gre donc deux probl&eacute;matiques importantes en informatique musicale : la reconnaissance et l&rsquo;extraction des donn&eacute;es musicales en temps r&eacute;el (&eacute;coute artificielle) depuis un signal audio, et la programmation synchrone r&eacute;active pour l&rsquo;&eacute;criture du temps et de l&rsquo;interaction.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>Dans le contexte de l&rsquo;ex&eacute;cution d&rsquo;&oelig;uvres contemporaines associant parties instrumentales et informatiques, le suivi de partition est une technique souvent employ&eacute;e pour la synchronisation de l&rsquo;accompagnement &eacute;lectronique avec un instrument soliste. La partition est enregistr&eacute;e dans l&rsquo;ordinateur dans un format sp&eacute;cifique contenant &agrave; la fois les &eacute;l&eacute;ments essentiels de la partition instrumentale et une &eacute;criture de la partie informatique avec un langage musical synchrone. Lors de l&rsquo;ex&eacute;cution, l&rsquo;analyse en temps r&eacute;el du son et/ou du geste capt&eacute; aupr&egrave;s de l&rsquo;interpr&egrave;te est mise en comparaison avec la partition enregistr&eacute;e. L&rsquo;algorithme de suivi d&eacute;termine &agrave; chaque instant de l&rsquo;interpr&eacute;tation la position correspondante dans la partition et synchronise les processus programm&eacute;s dans la partie &eacute;lectronique de l&rsquo;&oelig;uvre.</p>\r\n<p>Le suiveur de partition (Antescofo) int&egrave;gre d&eacute;sormais &eacute;galement un langage synchrone temps r&eacute;el, permettant une &eacute;criture du temps et une interaction pour la partie &eacute;lectronique. L&rsquo;utilisation de cette technologie permet une &eacute;criture coh&eacute;rente entre les parties &eacute;lectroniques et instrumentales au temps de la composition, et une ex&eacute;cution synchrone et polyphonique des modules &eacute;lectroniques avec les musiciens en temps r&eacute;el. Son d&eacute;veloppement est pr&eacute;vu pour une adaptation aux diff&eacute;rentes familles d&rsquo;instruments et &agrave; la reconnaissance de formes musicales, ainsi qu&rsquo;une augmentation des paradigmes d&rsquo;&eacute;criture synchrone pour la partie &eacute;lectronique.</p>\r\n<p>Ce dispositif int&egrave;gre donc deux probl&eacute;matiques importantes en informatique musicale : la reconnaissance et l&rsquo;extraction des donn&eacute;es musicales en temps r&eacute;el (&eacute;coute artificielle) depuis un signal audio, et la programmation synchrone r&eacute;active pour l&rsquo;&eacute;criture du temps et de l&rsquo;interaction.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>In a context of the performance of contemporary works with instrumental and computer parts, score following is a technique often used for the synchronization of the electronic accompaniment with a solo performer. An augmented score is recorded in the computer using a specific format that contains both the essential elements of the instrumental score a specification for the computer part written in a dedicated musical language. During the performance, the analysis in real-time of the performer&rsquo;s sound and/or of the captured movement is aligned with the symbolic score. At every instant throughout the performance, the score follower&rsquo;s algorithm determines the location in the score and synchronizes the processes programmed in the electronic part of the work.&nbsp;</p>\r\n<p>The score follower (Antescofo) now includes a real-time reactive, synchronous and timed programming language, enabling the definition of complex interactions between performers and live electronics. The use of this technology makes it possible to ensure coherent writing between the electronic and instrumental parts of the composition, and a synchronous and polyphonic performance of electronic modules with musicians in real-time. Its development will include an adaptation for different families of musical instruments and recognition of musical forms as well as the extension of dedicated expressive structures to address various paradigms for the electronic parts.</p>\r\n<p>This system includes two important issues in computer music: the recognition and extraction of musical data in real-time (artificial listening) from an audio signal and reactive synchronous programming for writing time and interaction.</p>\r\n<p>IRCAM's team:&nbsp;<a href=\"/recherche/equipes-recherche/repmus/\">Musical Representations</a> .</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 173, "fields": {"keywords_string": "", "site": 1, "title": "Composition assist\u00e9e par ordinateur (OpenMusic)", "title_fr": "Composition assist\u00e9e par ordinateur (OpenMusic)", "title_en": "Computer-Assisted Composition (OpenMusic)", "slug": "composition-assistee-par-ordinateur-openmusic", "_meta_title": "", "description": "Concevoir des mod\u00e8les informatiques adapt\u00e9s aux processus de cr\u00e9ation, int\u00e9grant paradigmes de calcul, interactions et repr\u00e9sentations musicales", "description_fr": "Concevoir des mod\u00e8les informatiques adapt\u00e9s aux processus de cr\u00e9ation, int\u00e9grant paradigmes de calcul, interactions et repr\u00e9sentations musicales", "description_en": "Design models  techniques adapted to the creative process, incorporating paradigms for calculations as well as musical interactions and representations", "gen_description": false, "created": "2017-02-10T11:59:35.813Z", "updated": "2018-06-29T09:46:02.689Z", "status": 2, "publish_date": "2017-02-10T11:59:35Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La recherche en composition assist&eacute;e par ordinateur (CAO) a pour but d&rsquo;&eacute;tudier et concevoir des mod&egrave;les et techniques informatiques adapt&eacute;s aux processus de cr&eacute;ation, int&eacute;grant paradigmes de calcul, interactions et repr&eacute;sentations musicales. Cette d&eacute;marche met en avant une orientation symbolique s&rsquo;appuyant sur les langages de programmation pour la cr&eacute;ation et le traitement des donn&eacute;es harmoniques, temporelles, rythmiques ou des autres aspects entrant en jeu dans les processus compositionnels. Nos travaux dans ce domaine s&rsquo;articulent principalement autour de l&rsquo;environnement OpenMusic, un langage de programmation visuelle bas&eacute; sur Common Lisp et d&eacute;di&eacute; &agrave; la composition musicale. Cet environnement utilis&eacute; par les compositeurs de musique contemporaine depuis une quinzaine d&rsquo;ann&eacute;es, est aujourd&rsquo;hui consid&eacute;r&eacute; comme l&rsquo;une des principales r&eacute;f&eacute;rences dans le domaine de la composition assist&eacute;e par ordinateur et il a fait l&rsquo;objet de plusieurs dizaines de milliers de t&eacute;l&eacute;chargements par des utilisateurs de tous les pays.</p>\r\n<p><a href=\"http://forumnet.ircam.fr/fr/produit/openmusic/\" target=\"_blank\">OpenMusic</a> (OM) est un environnement de programmation visuelle pour la composition ou l&rsquo;analyse musicale assist&eacute;es par ordinateur. OM offre &agrave; l&rsquo;utilisateur de nombreux modules associ&eacute;s &agrave; des fonctions, connect&eacute;s les uns aux autres pour constituer un programme (ou patch) permettant de g&eacute;n&eacute;rer ou transformer des structures et donn&eacute;es musicales. OM propose &eacute;galement de nombreux &eacute;diteurs permettant de manipuler ces donn&eacute;es, ainsi que des biblioth&egrave;ques sp&eacute;cialis&eacute;es dans des domaines tels que l'analyse et la synth&egrave;se sonore, les mod&egrave;les math&eacute;matiques, la r&eacute;solution des probl&egrave;mes de contraintes, etc. Des interfaces originales comme l'&eacute;diteur de maquettes permettent de construire des structures int&eacute;grant relations fonctionnelles et temporelles entre les objets musicaux. OpenMusic est utilis&eacute; par un grand nombre de compositeurs et de musicologues, et est enseign&eacute; dans les principaux centres d&rsquo;informatique musicale ainsi que dans plusieurs universit&eacute;s en Europe et dans le monde.</p>\r\n<p>R&eacute;cemment, Un nouveau paradigme de calcul et de programmation a &eacute;t&eacute; propos&eacute; au sein de l'environnement OpenMusic, combinant l&rsquo;approche existante bas&eacute;e sur le style fonctionnel/ demand-driven &agrave; une approche r&eacute;active inspir&eacute;e des syst&egrave;mes interactifs temps r&eacute;el (event-driven). L&rsquo;activation de cha&icirc;nes r&eacute;actives dans les programmes visuels accro&icirc;t les possibilit&eacute;s d&rsquo;interaction dans l&rsquo;environnement de CAO : un changement ou une action de l'utilisateur (&eacute;v&eacute;nement) dans un programme ou dans les donn&eacute;es qui le composent, produit une s&eacute;rie de r&eacute;actions conduisant &agrave; sa mise &agrave; jour (r&eacute;&eacute;valuation). Un &eacute;v&eacute;nement peut &eacute;galement provenir d'une source ext&eacute;rieure (typiquement, un port MIDI ou UDP ouvert et attach&eacute; &agrave; un &eacute;l&eacute;ment du programme visuel) ; ainsi, une communication bidirectionnelle peut &ecirc;tre &eacute;tablie entre les programmes visuels et des applications ou dispositifs externes.</p>\r\n<p>L'environnement de CAO se trouve alors ins&eacute;r&eacute; dans la temporalit&eacute; d'un syst&egrave;me plus large, et potentiellement r&eacute;gi par les &eacute;v&egrave;nements et interactions produits par ou dans ce syst&egrave;me. Cette temporalit&eacute; peut &ecirc;tre celle du processus de composition, ou celle de la performance. La richesse expressive des environnements de CAO tient en grande partie aux croisements qu'elle permet de r&eacute;aliser entre relations temporelles et fonctionnelles au sein des structures musicales. Si dans un cadre classique &laquo; temps diff&eacute;r&eacute; &raquo; les processus de calcul et d&rsquo;ex&eacute;cution des structures musicales ont lieu dans des phases et temporalit&eacute;s distinctes, nous nous int&eacute;ressons ici &agrave; des situations interactives o&ugrave; l&rsquo;ordonnancement des &eacute;v&egrave;nements musicaux est susceptible de d&eacute;pendre, ou d&rsquo;interagir avec les processus g&eacute;n&eacute;ratifs mis en &oelig;uvre dans un contexte compositionnel ou performatif donn&eacute;.</p>\r\n<p>Une nouvelle architecture a &eacute;t&eacute; d&eacute;finie dans cet objectif, liant les structures musicales produites dans l'environnement de CAO &agrave; la structure d'ordonnancement. Cette architecture repose sur une repr&eacute;sentation hi&eacute;rarchique des objets musicaux agissant directement sur leur conversion en s&eacute;quences d'actions. Sur cette architecture, diff&eacute;rents prototypes de noyaux d&rsquo;ordonnancement ont &eacute;t&eacute; &eacute;labor&eacute;s, permettant d&rsquo;int&eacute;grer &agrave; l&rsquo;environnement OpenMusic l&rsquo;id&eacute;e d&rsquo;un &laquo; s&eacute;quenceur dynamique &raquo;, qui permettrait la modification ou la g&eacute;n&eacute;ration &laquo; &agrave; la vol&eacute;e &raquo; de donn&eacute;es musicales pendant le rendu d&rsquo;une partition. Les diff&eacute;rents mod&egrave;les et optimisations, sp&eacute;cifiques &agrave; chacun de ces prototypes, les rendent plus ou moins adapt&eacute;s &agrave; diff&eacute;rents cas de figure et situations musicales : partitions statiques, mat&eacute;riau statique &agrave; ordonnancement dynamique, et mat&eacute;riau enti&egrave;rement dynamique&hellip; La conception d&rsquo;un mod&egrave;le unifiant fait partie des objectifs &agrave; moyen terme de ce projet.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>.</p>", "content_fr": "<p>La recherche en composition assist&eacute;e par ordinateur (CAO) a pour but d&rsquo;&eacute;tudier et concevoir des mod&egrave;les et techniques informatiques adapt&eacute;s aux processus de cr&eacute;ation, int&eacute;grant paradigmes de calcul, interactions et repr&eacute;sentations musicales. Cette d&eacute;marche met en avant une orientation symbolique s&rsquo;appuyant sur les langages de programmation pour la cr&eacute;ation et le traitement des donn&eacute;es harmoniques, temporelles, rythmiques ou des autres aspects entrant en jeu dans les processus compositionnels. Nos travaux dans ce domaine s&rsquo;articulent principalement autour de l&rsquo;environnement OpenMusic, un langage de programmation visuelle bas&eacute; sur Common Lisp et d&eacute;di&eacute; &agrave; la composition musicale. Cet environnement utilis&eacute; par les compositeurs de musique contemporaine depuis une quinzaine d&rsquo;ann&eacute;es, est aujourd&rsquo;hui consid&eacute;r&eacute; comme l&rsquo;une des principales r&eacute;f&eacute;rences dans le domaine de la composition assist&eacute;e par ordinateur et il a fait l&rsquo;objet de plusieurs dizaines de milliers de t&eacute;l&eacute;chargements par des utilisateurs de tous les pays.</p>\r\n<p><a href=\"http://forumnet.ircam.fr/fr/produit/openmusic/\" target=\"_blank\">OpenMusic</a> (OM) est un environnement de programmation visuelle pour la composition ou l&rsquo;analyse musicale assist&eacute;es par ordinateur. OM offre &agrave; l&rsquo;utilisateur de nombreux modules associ&eacute;s &agrave; des fonctions, connect&eacute;s les uns aux autres pour constituer un programme (ou patch) permettant de g&eacute;n&eacute;rer ou transformer des structures et donn&eacute;es musicales. OM propose &eacute;galement de nombreux &eacute;diteurs permettant de manipuler ces donn&eacute;es, ainsi que des biblioth&egrave;ques sp&eacute;cialis&eacute;es dans des domaines tels que l'analyse et la synth&egrave;se sonore, les mod&egrave;les math&eacute;matiques, la r&eacute;solution des probl&egrave;mes de contraintes, etc. Des interfaces originales comme l'&eacute;diteur de maquettes permettent de construire des structures int&eacute;grant relations fonctionnelles et temporelles entre les objets musicaux. OpenMusic est utilis&eacute; par un grand nombre de compositeurs et de musicologues, et est enseign&eacute; dans les principaux centres d&rsquo;informatique musicale ainsi que dans plusieurs universit&eacute;s en Europe et dans le monde.</p>\r\n<p>R&eacute;cemment, Un nouveau paradigme de calcul et de programmation a &eacute;t&eacute; propos&eacute; au sein de l'environnement OpenMusic, combinant l&rsquo;approche existante bas&eacute;e sur le style fonctionnel/ demand-driven &agrave; une approche r&eacute;active inspir&eacute;e des syst&egrave;mes interactifs temps r&eacute;el (event-driven). L&rsquo;activation de cha&icirc;nes r&eacute;actives dans les programmes visuels accro&icirc;t les possibilit&eacute;s d&rsquo;interaction dans l&rsquo;environnement de CAO : un changement ou une action de l'utilisateur (&eacute;v&eacute;nement) dans un programme ou dans les donn&eacute;es qui le composent, produit une s&eacute;rie de r&eacute;actions conduisant &agrave; sa mise &agrave; jour (r&eacute;&eacute;valuation). Un &eacute;v&eacute;nement peut &eacute;galement provenir d'une source ext&eacute;rieure (typiquement, un port MIDI ou UDP ouvert et attach&eacute; &agrave; un &eacute;l&eacute;ment du programme visuel) ; ainsi, une communication bidirectionnelle peut &ecirc;tre &eacute;tablie entre les programmes visuels et des applications ou dispositifs externes.</p>\r\n<p>L'environnement de CAO se trouve alors ins&eacute;r&eacute; dans la temporalit&eacute; d'un syst&egrave;me plus large, et potentiellement r&eacute;gi par les &eacute;v&egrave;nements et interactions produits par ou dans ce syst&egrave;me. Cette temporalit&eacute; peut &ecirc;tre celle du processus de composition, ou celle de la performance. La richesse expressive des environnements de CAO tient en grande partie aux croisements qu'elle permet de r&eacute;aliser entre relations temporelles et fonctionnelles au sein des structures musicales. Si dans un cadre classique &laquo; temps diff&eacute;r&eacute; &raquo; les processus de calcul et d&rsquo;ex&eacute;cution des structures musicales ont lieu dans des phases et temporalit&eacute;s distinctes, nous nous int&eacute;ressons ici &agrave; des situations interactives o&ugrave; l&rsquo;ordonnancement des &eacute;v&egrave;nements musicaux est susceptible de d&eacute;pendre, ou d&rsquo;interagir avec les processus g&eacute;n&eacute;ratifs mis en &oelig;uvre dans un contexte compositionnel ou performatif donn&eacute;.</p>\r\n<p>Une nouvelle architecture a &eacute;t&eacute; d&eacute;finie dans cet objectif, liant les structures musicales produites dans l'environnement de CAO &agrave; la structure d'ordonnancement. Cette architecture repose sur une repr&eacute;sentation hi&eacute;rarchique des objets musicaux agissant directement sur leur conversion en s&eacute;quences d'actions. Sur cette architecture, diff&eacute;rents prototypes de noyaux d&rsquo;ordonnancement ont &eacute;t&eacute; &eacute;labor&eacute;s, permettant d&rsquo;int&eacute;grer &agrave; l&rsquo;environnement OpenMusic l&rsquo;id&eacute;e d&rsquo;un &laquo; s&eacute;quenceur dynamique &raquo;, qui permettrait la modification ou la g&eacute;n&eacute;ration &laquo; &agrave; la vol&eacute;e &raquo; de donn&eacute;es musicales pendant le rendu d&rsquo;une partition. Les diff&eacute;rents mod&egrave;les et optimisations, sp&eacute;cifiques &agrave; chacun de ces prototypes, les rendent plus ou moins adapt&eacute;s &agrave; diff&eacute;rents cas de figure et situations musicales : partitions statiques, mat&eacute;riau statique &agrave; ordonnancement dynamique, et mat&eacute;riau enti&egrave;rement dynamique&hellip; La conception d&rsquo;un mod&egrave;le unifiant fait partie des objectifs &agrave; moyen terme de ce projet.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicales</a>.</p>", "content_en": "<p>The purpose of research in computer-assisted composition (CAC) is to study and design models and computer techniques adapted to the creative process, incorporating paradigms for calculations as well as musical interactions and representations. This approach favors symbolic orientation using programming languages for artistic creation and processing harmonic, temporal, and rhythmic data in addition to other aspects that come into play in the compositional process. Our work in this domain is articulated primarily around the OpenMusic environment, a visual programming language based on Common Lisp and dedicated to musical composition. Contemporary music composers have used this environment for the past 15 years. Today, is regarded as one of the principle references in computer-assisted composition and has been downloaded by several thousand users from around the globe.</p>\r\n<p><a href=\"http://forumnet.ircam.fr/product/openmusic-en/\" target=\"_blank\">OpenMusic</a> (OM) is a visual programming environment for composition or musical analysis assisted by computer. OM offers users a range of interconnected modules associated with specific functions, making up patches that enable the creation or transformation of musical data structures. OM also offers several editors to manipulate these data in addition to libraries in specialized sound analysis and synthesis, mathematical models, the resolution of constraint problems, etc. Unique interfaces like the maquette editor let users construct structures that include functional and temporal relationships among musical objects. OpenMusic is used by a large number of composers and musicologists; it is taught in all major computer-music centers and several universities worldwide.</p>\r\n<p>Recently, a new calculation and programming paradigm was suggested for the OpenMusic environment, combining the existing demand-driven approach with a reactive approach inspired by event-driven, interactive real-time systems. The activation of reactive channels in visual programs increases the possibilities for interaction in a CAC environment: an event&mdash;a change or an action made by a user&mdash;made in a program or in the data it is made from, produce a series of reactions leading to an update (reevaluation). An event can also come from an outside source (typically, a MIDI port or an open UDP and attached to an element of the visual program). Two-way communication can be established between the visual programs and exterior applications or systems. The CAC environment finds itself inserted in the temporality of a larger system, potentially governed by events and interactions produced by or in this system. This temporality could be that of the compositional process, or that of the performance. The expressive wealth of CAC environments is largely found in the combinations it enables between temporal and functional relationships within musical structures. In traditional &ldquo;off line&rdquo; work, the processes of calculating and the execution of musical structures take place in distinct phases and temporalities. Here, we study interactive situations where the sequencing of musical events may depend on, or interact with generative processes put in place in a specific compositional or performance situation.&nbsp; A new architecture was defined with this objective in mind, connecting musical structures produced in a CAC environment with the sequencing structure. This architecture employs a hierarchical representation of musical objects that interact with their conversion by sequencing events.</p>\r\n<p>Different prototypes for the sequence kernel were created for this architecture. These prototypes made it possible to integrate the idea of a dynamic sequencer in the OpenMusic environment, as well as the modification and generation of musical data \"on the fly\" during the performance of a score. The different models and optimizations, specified for each prototype make them more or less adapted for different cases and musical situations: static scores, static material with dynamic sequencing, and entirely dynamic material&hellip;. The creation of a unifying model is one of the medium-term goals in this project.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-recherche/repmus/\">Musical Representations</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 174, "fields": {"keywords_string": "", "site": 1, "title": "Orchestration assist\u00e9e par ordinateur (Orchids)", "title_fr": "Orchestration assist\u00e9e par ordinateur (Orchids)", "title_en": "Computer-Assisted Composition (Orchids)", "slug": "orchestration-assistee-par-ordinateur-orchids", "_meta_title": "", "description": "Orchestration par la recherche automatique d\u2019instrumentations et de superpositions d\u2019instruments approchant une cible d\u00e9finie par le compositeur", "description_fr": "Orchestration par la recherche automatique d\u2019instrumentations et de superpositions d\u2019instruments approchant une cible d\u00e9finie par le compositeur", "description_en": "", "gen_description": false, "created": "2017-02-10T12:07:23.437Z", "updated": "2018-06-29T10:25:56.614Z", "status": 2, "publish_date": "2017-02-10T12:07:23Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Cas singulier et r&eacute;cent de l&rsquo;aide informatis&eacute;e &agrave; la composition, ce projet aborde la question de l&rsquo;orchestration par la recherche automatique d&rsquo;instrumentations et de superpositions d&rsquo;instruments approchant, en fonction de diff&eacute;rents crit&egrave;res de similarit&eacute; acoustique, une cible d&eacute;finie par le compositeur. Les recherches actuelles s&rsquo;attachent &agrave; &eacute;tendre ce paradigme &agrave; l&rsquo;orchestration dynamique, suivant des cibles dont les caract&eacute;ristiques sonores varient au cours du temps.</p>\r\n<p>R&eacute;alis&eacute; &agrave; la suite du logiciel Orchid&eacute;e, <a href=\"http://forumnet.ircam.fr/fr/produit/orchids-2/\" target=\"_blank\">Orchids</a> est le premier syst&egrave;me complet pour l&rsquo;orchestration temporelle assist&eacute;e par ordinateur et l&rsquo;optimisation de m&eacute;langes de timbres. Il fournit un ensemble d&rsquo;algorithmes permettant de reconstruire n&rsquo;importe quelle cible sonore &eacute;voluant dans le temps par une combinaison d&rsquo;instruments ou &eacute;chantillons, selon un ensemble de crit&egrave;res psycho-acoustiques. Il peut aider les compositeurs &agrave; obtenir des couleurs de timbre inou&iuml;es en fournissant une multitude de solutions efficaces qui recr&eacute;ent au mieux cette cible sonore. Gr&acirc;ce &agrave; un ensemble &eacute;tendu de fonctionnalit&eacute;s, Orchids peut &eacute;galement reproduire des &eacute;volutions et formes abstraites de mouvements spectraux. Ses r&eacute;sultats fournissent des partitions d&rsquo;orchestre multiples pouvant &ecirc;tre organis&eacute;es de mani&egrave;re intuitive afin d&rsquo;obtenir rapidement une r&eacute;alisation d&rsquo;id&eacute;es orchestrales et musicales. Ce syst&egrave;me fournit plusieurs algorithmes d&rsquo;approximation permettant d&rsquo;optimiser conjointement plusieurs propri&eacute;t&eacute;s de timbre. Les avantages du syst&egrave;me Orchids r&eacute;sident dans le fait que cette approximation peut &ecirc;tre faite s&eacute;par&eacute;ment sur des formes temporelles, valeurs moyennes ou &eacute;carts-types (ou toute combinaison des trois) de chaque descripteur psychoacoustique. En outre, les utilisateurs peuvent &eacute;galement d&eacute;finir une d&eacute;formation temporelle manuelle, et m&ecirc;me effectuer une recherche multicible &agrave; l&rsquo;int&eacute;rieur de multiples segments sonores, offrant ainsi des r&eacute;alisations de pi&egrave;ces orchestrales compl&egrave;tes en quelques secondes.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicale</a>.</p>", "content_fr": "<p>Cas singulier et r&eacute;cent de l&rsquo;aide informatis&eacute;e &agrave; la composition, ce projet aborde la question de l&rsquo;orchestration par la recherche automatique d&rsquo;instrumentations et de superpositions d&rsquo;instruments approchant, en fonction de diff&eacute;rents crit&egrave;res de similarit&eacute; acoustique, une cible d&eacute;finie par le compositeur. Les recherches actuelles s&rsquo;attachent &agrave; &eacute;tendre ce paradigme &agrave; l&rsquo;orchestration dynamique, suivant des cibles dont les caract&eacute;ristiques sonores varient au cours du temps.</p>\r\n<p>R&eacute;alis&eacute; &agrave; la suite du logiciel Orchid&eacute;e, <a href=\"http://forumnet.ircam.fr/fr/produit/orchids-2/\" target=\"_blank\">Orchids</a> est le premier syst&egrave;me complet pour l&rsquo;orchestration temporelle assist&eacute;e par ordinateur et l&rsquo;optimisation de m&eacute;langes de timbres. Il fournit un ensemble d&rsquo;algorithmes permettant de reconstruire n&rsquo;importe quelle cible sonore &eacute;voluant dans le temps par une combinaison d&rsquo;instruments ou &eacute;chantillons, selon un ensemble de crit&egrave;res psycho-acoustiques. Il peut aider les compositeurs &agrave; obtenir des couleurs de timbre inou&iuml;es en fournissant une multitude de solutions efficaces qui recr&eacute;ent au mieux cette cible sonore. Gr&acirc;ce &agrave; un ensemble &eacute;tendu de fonctionnalit&eacute;s, Orchids peut &eacute;galement reproduire des &eacute;volutions et formes abstraites de mouvements spectraux. Ses r&eacute;sultats fournissent des partitions d&rsquo;orchestre multiples pouvant &ecirc;tre organis&eacute;es de mani&egrave;re intuitive afin d&rsquo;obtenir rapidement une r&eacute;alisation d&rsquo;id&eacute;es orchestrales et musicales. Ce syst&egrave;me fournit plusieurs algorithmes d&rsquo;approximation permettant d&rsquo;optimiser conjointement plusieurs propri&eacute;t&eacute;s de timbre. Les avantages du syst&egrave;me Orchids r&eacute;sident dans le fait que cette approximation peut &ecirc;tre faite s&eacute;par&eacute;ment sur des formes temporelles, valeurs moyennes ou &eacute;carts-types (ou toute combinaison des trois) de chaque descripteur psychoacoustique. En outre, les utilisateurs peuvent &eacute;galement d&eacute;finir une d&eacute;formation temporelle manuelle, et m&ecirc;me effectuer une recherche multicible &agrave; l&rsquo;int&eacute;rieur de multiples segments sonores, offrant ainsi des r&eacute;alisations de pi&egrave;ces orchestrales compl&egrave;tes en quelques secondes.</p>\r\n<p>&Eacute;quipe Ircam : <a href=\"/recherche/equipes-recherche/repmus/\">Repr&eacute;sentations musicale</a>.</p>", "content_en": "<p>A unique and recent case of computer-assisted composition, this project addresses the question of orchestration via an automatic search of instrumentation and layering instruments approaching, depending on different acoustic similarity criteria, a target defined by the composer. Current research endeavors to make this dynamic orchestration paradigm heard, according to the targets with sonorous characteristics that vary with time.</p>\r\n<p>Realized after the Orchid&eacute;e software suite, Orchids is the first complete system for temporal computer-assisted orchestration and the optimization of timbre combinations. It provides an ensemble of algorithms making it possible to recreate any sound target that changes over time through a combination of instruments or samples, according to the psycho-acoustic criteria. This can help composers obtain unique timbre colors providing a multitude of effective solutions to best recreate the sound target. Through a large selection of functions, Orchids can also recreate the evolutions and abstract forms of spectral movements. Its results provide multiple orchestra scores that can be organized intuitively in order to quickly construct orchestral and musical ideas. This system provides several approximation algorithms that make it possible to conjointly optimize several timbre features. The advantages of the Orchids system lies in the fact that this approximation can be carried out separately on temporal forms, values, mean values or standard deviations (or any combination of the three) of each psycho-acoustic descriptor. In addition, users can also manually define a temporal deformation and carry out a multi-target search within several sound segments, making it possible to create full orchestral works in just a few seconds.</p>\r\n<p>IRCAM's Team: <a href=\"/recherche/equipes-recherche/repmus/\">Musical Representations</a>.</p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [5], "organizations": [1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 175, "fields": {"keywords_string": "", "site": 1, "title": "IRiMaS", "title_fr": "IRiMaS", "title_en": "IRiMaS", "slug": "irimas", "_meta_title": "", "description": "Interactive Research in Music as Sound:Transforming Digital Musicology", "description_fr": "Interactive Research in Music as Sound:Transforming Digital Musicology", "description_en": "Interactive Research in Music as Sound:Transforming Digital Musicology", "gen_description": false, "created": "2017-08-02T13:35:44.141Z", "updated": "2018-06-29T11:06:15.385Z", "status": 1, "publish_date": "2017-08-02T13:35:44Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "", "content_fr": "", "content_en": "", "date_from": "2017-10-01", "date_to": "2022-09-30", "user": null, "type": "external", "external_id": "741904", "program": 8, "program_type": 27, "call": null, "lead_team": 4, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 176, "fields": {"keywords_string": "", "site": 1, "title": "FuturePulse", "title_fr": "FuturePulse", "title_en": "FuturePulse", "slug": "futurepulse", "_meta_title": "", "description": "FuturePulse: Multimodal Predictive Analytics and Recommendation Services for the Music Industry", "description_fr": "FuturePulse: Multimodal Predictive Analytics and Recommendation Services for the Music Industry", "description_en": "FuturePulse: Multimodal Predictive Analytics and Recommendation Services for the Music Industry", "gen_description": true, "created": "2017-08-02T13:51:20.789Z", "updated": "2018-09-10T10:55:01.502Z", "status": 1, "publish_date": "2017-08-02T13:51:20Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "", "content_fr": "", "content_en": "", "date_from": "2017-09-01", "date_to": "2020-08-31", "user": null, "type": "external", "external_id": "", "program": 8, "program_type": 5, "call": null, "lead_team": 4, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 177, "fields": {"keywords_string": "", "site": 1, "title": "Musique & Hacking", "title_fr": "Musique & Hacking", "title_en": "Music & Hacking", "slug": "musique-et-hacking", "_meta_title": "", "description": "", "description_fr": "", "description_en": "", "gen_description": false, "created": "2017-10-18T15:20:01.621Z", "updated": "2018-06-29T14:05:15.564Z", "status": 2, "publish_date": "2017-10-18T15:06:49Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Si le hacking est &eacute;troitement li&eacute; au d&eacute;veloppement de l&rsquo;informatique et du r&eacute;seau Internet, depuis les tentatives pionni&egrave;res au sein du Tech Model Railroad Club du Massachusetts Institute of Technology pour am&eacute;liorer l&rsquo;efficacit&eacute; et la rapidit&eacute; des premiers ordinateurs de calculs jusqu&rsquo;&agrave; Wikileaks en passant par le mouvement open source, il est aujourd&rsquo;hui assez courant d&rsquo;&eacute;tendre l&rsquo;usage du concept de hacking pour d&eacute;crire de nombreuses pratiques, y compris dans des champs largement ind&eacute;pendants des nouvelles technologies de l&rsquo;information et de la communication.</p>\r\n<p>De mani&egrave;re g&eacute;n&eacute;rale, le hacking peut caract&eacute;riser un ensemble d&rsquo;activit&eacute;s &agrave; la fois optimisatrices (am&eacute;lioration des performances d&rsquo;un objet ou d&rsquo;un dispositif technique, recherche de la meilleure solution &agrave; un probl&egrave;me donn&eacute;), transgressives (contournement des normes l&eacute;gales ou technologiques, d&eacute;tournement des usages inscrits, posture irr&eacute;v&eacute;rencieuse envers les objets) et h&eacute;doniques (plaisir de la trouvaille, de la manipulation ing&eacute;nieuse, de la prouesse technique, de la customisation). Le hacking d&eacute;signe alors bien davantage une certaine posture ou attitude, sous-tendue par un certain nombre de valeurs, qu&rsquo;il ne renvoie &agrave; une activit&eacute; pr&eacute;cise.&nbsp;</p>\r\n<p>Dans cette perspective, on peut consid&eacute;rer le hacking comme une s&eacute;rie de pratiques et d&rsquo;usages configur&eacute;s par les cat&eacute;gories conceptuelles de l&rsquo;informatique&nbsp;&ndash; l&rsquo;ordinateur comme objet technique &laquo;&nbsp;ouvert&nbsp;&raquo;, modulable, adaptable aux besoins changeants de l&rsquo;utilisateur&nbsp;; le code comme support de l&rsquo;information&nbsp;; et le r&eacute;seau comme structure de communication &ndash; pratiques et usages qui peuvent ensuite &ecirc;tre remobilis&eacute;s (et par l&agrave;-m&ecirc;me remodel&eacute;s) en dehors du contexte informatique.</p>\r\n<p>Le projet \"Musique &amp; Hacking\" se propose donc de partir &agrave; la recherche des points de greffe entre culture hacker et musiques d&rsquo;aujourd&rsquo;hui, des manifestations les plus explicites (organisation p&eacute;riodique de Music Hack Days et autres Hackathon, piratage massif des productions de l&rsquo;industrie musicale, etc.) aux transferts les plus implicites (&eacute;mergence de nouvelles conceptions de l&rsquo;instrument de musique, remise en cause de la fonction-auteur, dimension &eacute;thique de certaines musiques exp&eacute;rimentales, etc.), &eacute;clairant ainsi d&rsquo;un jour neuf les&nbsp;pratiques musicales consid&eacute;r&eacute;es.</p>\r\n<p>Pour l&rsquo;ann&eacute;e 2016-2017, l&rsquo;&eacute;quipe s&rsquo;investira sur l&rsquo;analyse des activit&eacute;s de hacking instrumental au sein de l&rsquo;atelier \"Lutheries Urbaines\" de Bagnolet, compl&eacute;t&eacute;e par la r&eacute;alisation d&rsquo;un ensemble d&rsquo;entretiens avec des acteurs importants de la sc&egrave;ne des musiques improvis&eacute;es qui en sont venus &agrave; constituer leur propre dispositif de jeu.</p>\r\n<p>En 2017, le projet se cl&ocirc;ture avec le colloque \"Musique et&nbsp;Hacking : instruments, communaut&eacute;s, &eacute;thiques\", organis&eacute; conjointement par le mus&eacute;e du quai Branly et l'Ircam,&nbsp;qui<span>&nbsp;abordera les multiples formes de d&eacute;tournement ou de r&eacute;appropriation qu&rsquo;exercent les musiciens envers leur environnement mat&eacute;riel, la formation et la f&eacute;d&eacute;ration de communaut&eacute;s musicales par le hacking ou encore l&rsquo;influence de l&rsquo;&eacute;thique \"hacker\" dans les pratiques musicales. <br />Enfin, l&rsquo;organisation d&rsquo;un Music Hack Day &agrave; l&rsquo;issue du colloque (les 10 et 11 novembre 2017 &agrave; l'Ircam) donnera un aper&ccedil;u concret de la vivacit&eacute; et de la f&eacute;condit&eacute; des approches qui nourrissent le monde du hacking musical.</span></p>", "content_fr": "<p>Si le hacking est &eacute;troitement li&eacute; au d&eacute;veloppement de l&rsquo;informatique et du r&eacute;seau Internet, depuis les tentatives pionni&egrave;res au sein du Tech Model Railroad Club du Massachusetts Institute of Technology pour am&eacute;liorer l&rsquo;efficacit&eacute; et la rapidit&eacute; des premiers ordinateurs de calculs jusqu&rsquo;&agrave; Wikileaks en passant par le mouvement open source, il est aujourd&rsquo;hui assez courant d&rsquo;&eacute;tendre l&rsquo;usage du concept de hacking pour d&eacute;crire de nombreuses pratiques, y compris dans des champs largement ind&eacute;pendants des nouvelles technologies de l&rsquo;information et de la communication.</p>\r\n<p>De mani&egrave;re g&eacute;n&eacute;rale, le hacking peut caract&eacute;riser un ensemble d&rsquo;activit&eacute;s &agrave; la fois optimisatrices (am&eacute;lioration des performances d&rsquo;un objet ou d&rsquo;un dispositif technique, recherche de la meilleure solution &agrave; un probl&egrave;me donn&eacute;), transgressives (contournement des normes l&eacute;gales ou technologiques, d&eacute;tournement des usages inscrits, posture irr&eacute;v&eacute;rencieuse envers les objets) et h&eacute;doniques (plaisir de la trouvaille, de la manipulation ing&eacute;nieuse, de la prouesse technique, de la customisation). Le hacking d&eacute;signe alors bien davantage une certaine posture ou attitude, sous-tendue par un certain nombre de valeurs, qu&rsquo;il ne renvoie &agrave; une activit&eacute; pr&eacute;cise.&nbsp;</p>\r\n<p>Dans cette perspective, on peut consid&eacute;rer le hacking comme une s&eacute;rie de pratiques et d&rsquo;usages configur&eacute;s par les cat&eacute;gories conceptuelles de l&rsquo;informatique&nbsp;&ndash; l&rsquo;ordinateur comme objet technique &laquo;&nbsp;ouvert&nbsp;&raquo;, modulable, adaptable aux besoins changeants de l&rsquo;utilisateur&nbsp;; le code comme support de l&rsquo;information&nbsp;; et le r&eacute;seau comme structure de communication &ndash; pratiques et usages qui peuvent ensuite &ecirc;tre remobilis&eacute;s (et par l&agrave;-m&ecirc;me remodel&eacute;s) en dehors du contexte informatique.</p>\r\n<p>Le projet \"Musique &amp; Hacking\" se propose donc de partir &agrave; la recherche des points de greffe entre culture hacker et musiques d&rsquo;aujourd&rsquo;hui, des manifestations les plus explicites (organisation p&eacute;riodique de Music Hack Days et autres Hackathon, piratage massif des productions de l&rsquo;industrie musicale, etc.) aux transferts les plus implicites (&eacute;mergence de nouvelles conceptions de l&rsquo;instrument de musique, remise en cause de la fonction-auteur, dimension &eacute;thique de certaines musiques exp&eacute;rimentales, etc.), &eacute;clairant ainsi d&rsquo;un jour neuf les&nbsp;pratiques musicales consid&eacute;r&eacute;es.</p>\r\n<p>Pour l&rsquo;ann&eacute;e 2016-2017, l&rsquo;&eacute;quipe s&rsquo;investira sur l&rsquo;analyse des activit&eacute;s de hacking instrumental au sein de l&rsquo;atelier \"Lutheries Urbaines\" de Bagnolet, compl&eacute;t&eacute;e par la r&eacute;alisation d&rsquo;un ensemble d&rsquo;entretiens avec des acteurs importants de la sc&egrave;ne des musiques improvis&eacute;es qui en sont venus &agrave; constituer leur propre dispositif de jeu.</p>\r\n<p>En 2017, le projet se cl&ocirc;ture avec le colloque \"Musique et&nbsp;Hacking : instruments, communaut&eacute;s, &eacute;thiques\", organis&eacute; conjointement par le mus&eacute;e du quai Branly et l'Ircam,&nbsp;qui<span>&nbsp;abordera les multiples formes de d&eacute;tournement ou de r&eacute;appropriation qu&rsquo;exercent les musiciens envers leur environnement mat&eacute;riel, la formation et la f&eacute;d&eacute;ration de communaut&eacute;s musicales par le hacking ou encore l&rsquo;influence de l&rsquo;&eacute;thique \"hacker\" dans les pratiques musicales. <br />Enfin, l&rsquo;organisation d&rsquo;un Music Hack Day &agrave; l&rsquo;issue du colloque (les 10 et 11 novembre 2017 &agrave; l'Ircam) donnera un aper&ccedil;u concret de la vivacit&eacute; et de la f&eacute;condit&eacute; des approches qui nourrissent le monde du hacking musical.</span></p>", "content_en": "<p><span class=\"s1\">While hacking is closely connected with the development of computer-science and the Internet, from the pioneering tests in the Tech Model Railroad Club at the Massachusetts Institute of Technology to try to improve the effectiveness and speed of the first computers to Wikileaks, without forgetting the open sources movement, today it is common for the concept of hacking to cover numerous practices including several found in fields far removed from new computer-science and communication technologies.</span></p>\r\n<p><span class=\"s1\">In general, hacking can characterize a group of activities that is intended to optimize the performances of an object or technological system&mdash;the search for the best solution to a given problem&mdash;to be transgressive (circumvention of legal or technological standards, misuse of common practices, disrespectful attitude towards objects), and hedonic (pleasure in finding a solution, ingenious manipulation, technical prowess, customization). Hacking therefore designates certain positions or attitudes underpinned by a number of values than it does a precise activity.</span></p>\r\n<p><span class=\"s1\">In view of this, we can consider hacking to be a series of practices and customs configured by the conceptual categories of computer-science: the computer is an &ldquo;open&rdquo;, modular, object adaptable to the changing needs of the user. Code is a support for information, and the network a structure for communication &ndash; practices and customs that can then be reused (and remodeled) beyond the computer-science context.</span></p>\r\n<p><span class=\"s1\">The Music and Hacking project aims to find points of intersection between the hacker culture and today&rsquo;s music, from the most explicit manifestations (periodical organization of music hack days and other hackathons, massive pirating of music industry productions, etc.) to implicit transfers (surfacing of new conceptions of the musical instrument, questioning the function-author, ethical dimension of certain experimental music, etc.), shedding light on new musical practices.</span></p>\r\n<p><span class=\"s1\">During 2016-2017, the team analyzed the activities of instrumental hacking in the &ldquo;Lutheries Urbaines&rdquo; workshop in Bagnolet, completed by the production of a set of interviews with important players in the improvised music scene who came to create their own performance system.</span></p>\r\n<p><span class=\"s1\">In 2017, the project will close with the conference &ldquo;Music and Hacking: Instruments, Communities, Ethics&rdquo; organized by the mus&eacute;e du quai Branly and IRCAM. This conference will address the multiple forms of misappropriation or misuse employed by musicians on their hardware, creation, and federation of musical communities via hacking or through the influence of the &ldquo;hacker&rdquo; ethics found in musical practices.</span></p>\r\n<p><span class=\"s1\">Finally, the organization of a music hack day after the conference (November 10 &amp; 11 at IRCAM) will give a concrete look at the vibrancy and wealth of different approaches that make up the world of musical hacking. &nbsp;</span></p>", "date_from": "2016-09-01", "date_to": "2017-11-30", "user": null, "type": "external", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "http://apm.ircam.fr/Hacking/", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6], "organizations": [1, 628], "referring_person": [93, 570, 646], "manager": [570], "concepts": []}}, {"model": "organization-projects.project", "pk": 178, "fields": {"keywords_string": "", "site": 1, "title": "MAKIMOno", "title_fr": "MAKIMOno", "title_en": "MAKIMOno", "slug": "makimono", "_meta_title": "", "description": "D\u00e9veloppement d'une th\u00e9orie scientifique de l'orchestration", "description_fr": "D\u00e9veloppement d'une th\u00e9orie scientifique de l'orchestration", "description_en": "Create the first partnership of a true scientific theory of orchestration", "gen_description": false, "created": "2017-12-22T17:20:07.886Z", "updated": "2018-07-25T14:46:45.129Z", "status": 2, "publish_date": "2017-12-22T17:20:07Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L'orchestration est l'art de combiner les diff&eacute;rents instruments afin d'atteindre divers objectifs sonores. Peu formalis&eacute;, ce savoir-faire est transmis empiriquement &agrave; travers des trait&eacute;s d'exemples, sans expliciter les raisons des choix du compositeur.</p>\r\n<p>Ce projet vise &agrave; d&eacute;velopper la premi&egrave;re approche, au sein d'un objectif &agrave; long terme, d'une th&eacute;orie scientifique de l'orchestration en s&rsquo;appuyant sur les domaines de l'informatique, de l'intelligence artificielle, de la psychologie exp&eacute;rimentale, du traitement du signal, de l&rsquo;&eacute;coute artificielle et de la th&eacute;orie musicale. Pour atteindre cet objectif, le projet exploitera un vaste ensemble de donn&eacute;es de pi&egrave;ces orchestrales associant partitions symboliques num&eacute;riques et rendus acoustiques multipistes. Des extraits orchestraux sont en cours d&rsquo;annotation par des groupes d'experts en musique, en termes d'occurrence d'effets perceptuels. Cette biblioth&egrave;que de connaissances orchestrales sera utilis&eacute;e via des techniques d'exploration de donn&eacute;es et les approches r&eacute;centes d'apprentissage profond. Notre objectif est d&rsquo;&eacute;valuer d'abord les repr&eacute;sentations optimales reliant partitions symboliques et enregistrements du point de vue de leurs capacit&eacute;s pr&eacute;dictives d&rsquo;un effet perceptuel donn&eacute;.</p>\r\n<p>Ensuite, nous voulons d&eacute;velopper ensuite de nouvelles m&eacute;thodes d'apprentissage et d'extraction de capables de relier les signaux audionum&eacute;riques, les partitions symboliques et les analyses perceptuelles en ciblant les espaces d'int&eacute;gration multimodale (transformation de sources d'information multiples en un syst&egrave;me de coordonn&eacute;es unifi&eacute;). Ces espaces peuvent fournir des relations m&eacute;triques entre les modalit&eacute;s qui peuvent &ecirc;tre exploit&eacute;es &agrave; la fois pour la g&eacute;n&eacute;ration automatique et l'extraction des connaissances. Les r&eacute;sultats de ces mod&egrave;les serviront ensuite &agrave; l'analyse de l'orchestration et seront &eacute;galement valid&eacute;s par des &eacute;tudes perceptuelles approfondies. En bouclant la boucle entre les effets perceptuels et l'apprentissage, tout en validant les connaissances de niveau sup&eacute;rieur qui seront extraites, ce projet propose une nouvelle approche cr&eacute;ative de l'orchestration et de sa p&eacute;dagogie. Les r&eacute;sultats pr&eacute;vus comprennent le d&eacute;veloppement des premiers outils technologiques pour l'analyse automatique des partitions orchestrales, pour pr&eacute;dire les r&eacute;sultats perceptuels de la combinaison de sources musicales multiples, ainsi que le d&eacute;veloppement d'interfaces prototypes pour la p&eacute;dagogie de l'orchestration, l'orchestration assist&eacute;e par ordinateur et la performance instrumentale dans les ensembles. Ces travaux impliquent une collaboration internationale &eacute;troite avec le CRSNG canadien.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-17-CE38-0015-01.</p>", "content_fr": "<p>L'orchestration est l'art de combiner les diff&eacute;rents instruments afin d'atteindre divers objectifs sonores. Peu formalis&eacute;, ce savoir-faire est transmis empiriquement &agrave; travers des trait&eacute;s d'exemples, sans expliciter les raisons des choix du compositeur.</p>\r\n<p>Ce projet vise &agrave; d&eacute;velopper la premi&egrave;re approche, au sein d'un objectif &agrave; long terme, d'une th&eacute;orie scientifique de l'orchestration en s&rsquo;appuyant sur les domaines de l'informatique, de l'intelligence artificielle, de la psychologie exp&eacute;rimentale, du traitement du signal, de l&rsquo;&eacute;coute artificielle et de la th&eacute;orie musicale. Pour atteindre cet objectif, le projet exploitera un vaste ensemble de donn&eacute;es de pi&egrave;ces orchestrales associant partitions symboliques num&eacute;riques et rendus acoustiques multipistes. Des extraits orchestraux sont en cours d&rsquo;annotation par des groupes d'experts en musique, en termes d'occurrence d'effets perceptuels. Cette biblioth&egrave;que de connaissances orchestrales sera utilis&eacute;e via des techniques d'exploration de donn&eacute;es et les approches r&eacute;centes d'apprentissage profond. Notre objectif est d&rsquo;&eacute;valuer d'abord les repr&eacute;sentations optimales reliant partitions symboliques et enregistrements du point de vue de leurs capacit&eacute;s pr&eacute;dictives d&rsquo;un effet perceptuel donn&eacute;.</p>\r\n<p>Ensuite, nous voulons d&eacute;velopper ensuite de nouvelles m&eacute;thodes d'apprentissage et d'extraction de capables de relier les signaux audionum&eacute;riques, les partitions symboliques et les analyses perceptuelles en ciblant les espaces d'int&eacute;gration multimodale (transformation de sources d'information multiples en un syst&egrave;me de coordonn&eacute;es unifi&eacute;). Ces espaces peuvent fournir des relations m&eacute;triques entre les modalit&eacute;s qui peuvent &ecirc;tre exploit&eacute;es &agrave; la fois pour la g&eacute;n&eacute;ration automatique et l'extraction des connaissances. Les r&eacute;sultats de ces mod&egrave;les serviront ensuite &agrave; l'analyse de l'orchestration et seront &eacute;galement valid&eacute;s par des &eacute;tudes perceptuelles approfondies. En bouclant la boucle entre les effets perceptuels et l'apprentissage, tout en validant les connaissances de niveau sup&eacute;rieur qui seront extraites, ce projet propose une nouvelle approche cr&eacute;ative de l'orchestration et de sa p&eacute;dagogie. Les r&eacute;sultats pr&eacute;vus comprennent le d&eacute;veloppement des premiers outils technologiques pour l'analyse automatique des partitions orchestrales, pour pr&eacute;dire les r&eacute;sultats perceptuels de la combinaison de sources musicales multiples, ainsi que le d&eacute;veloppement d'interfaces prototypes pour la p&eacute;dagogie de l'orchestration, l'orchestration assist&eacute;e par ordinateur et la performance instrumentale dans les ensembles. Ces travaux impliquent une collaboration internationale &eacute;troite avec le CRSNG canadien.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-17-CE38-0015-01.</p>", "content_en": "<p>Musical orchestration is the subtle art of writing musical pieces for orchestra, by combining instruments to achieve a particular sonic goal. Orchestration has been transmitted empirically and a true scientific theory of orchestration has never emerged.</p>\r\n<p>This project aims to create the first partnership towards the long-term goal of a true scientific theory of orchestration by coalescing the domains of computer science, artificial intelligence, experimental psychology, digital signal processing, computational audition, and music analysis. To achieve this aim, the project will exploit a large number of orchestral pieces in digital form for both symbolic scores and multi-track acoustic renderings of independent instrumental tracks. Orchestral excerpts are currently being annotated by panels of experts, in terms of the occurrence of given perceptual orchestral effects. This library of orchestral knowledge, readily available in both symbolic and signal formats for data mining and deep learning approaches. Our objective is to evaluate the optimal representations for symbolic scores and audio recordings of orchestration, by assessing their predictive capabilities on given perceptual effects.</p>\r\n<p>Then, we will develop novel models of learning and knowledge extraction capable of link musical signals, symbolic scores, and perceptual analyses by targeting multimodal embedding systems (transforming multiple sources of information into a unified coordinate system). These spaces can provide metric relationships between modalities that can be exploited for both automatic generation and knowledge extraction. The results from the models will then feed back to and be validated through extensive perceptual studies. By closing the loop between perceptual effects and learning, while validating the higher-level knowledge that will be extracted, this project will revolutionize creative approaches to orchestration and its pedagogy. The predicted outputs include the development of technological tools for the automatic analysis of musical scores, for predicting the perceptual results of combining multiple musical sources, as well as the development of digital media environments for orchestration pedagogy, computer-aided orchestration and instrumental performance in simulated ensembles. <br />This project implicates an international partnership with the Candaian CRSNG.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project reference: ANR-17-CE38-0015-01.</p>", "date_from": "2017-12-01", "date_to": "2019-12-31", "user": null, "type": "external", "external_id": "ANR-17-CE38-0015-01", "program": 1, "program_type": 31, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 3, "funding": "public", "teams": [5], "organizations": [646, 1], "referring_person": [55], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 180, "fields": {"keywords_string": "", "site": 1, "title": "TheVoice", "title_fr": "TheVoice", "title_en": "TheVoice", "slug": "thevoice", "_meta_title": "", "description": "Design de voix pour l\u2019industrie cr\u00e9ative", "description_fr": "Design de voix pour l\u2019industrie cr\u00e9ative", "description_en": "Voice design for the creatives industries", "gen_description": false, "created": "2018-01-18T18:15:28.463Z", "updated": "2018-07-25T14:32:51.813Z", "status": 2, "publish_date": "2018-01-18T18:15:28Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Le projet TheVoice s&rsquo;attaque &agrave; la cr&eacute;ation de voix pour la production de contenu dans le secteur de l'industrie cr&eacute;ative (films, s&eacute;ries, documentaires), secteur tr&egrave;s important en termes de potentiel industriel mais extr&ecirc;mement exigeant en termes de qualit&eacute;. Le projet s&rsquo;appuie sur un constat simple : la production de voix demeure exclusivement effectu&eacute;e par des op&eacute;rateurs humains dans un secteur quasi exclusivement num&eacute;rique.</p>\n<p>Les objectifs scientifiques et technologiques du projet visent &agrave; mod&eacute;liser la &laquo; palette vocale &raquo; d&rsquo;un acteur pour permettre la recommandation de voix par similarit&eacute;, et la cr&eacute;ation de voix artificielles capables de reproduire l&rsquo;identit&eacute; vocale d&rsquo;un acteur. Le projet cr&eacute;era une rupture des usages par la r&eacute;alisation et l&rsquo;industrialisation de nouvelles technologies pour la cr&eacute;ation de contenus vocaux naturels et expressifs. Le consortium, port&eacute; par un acteur majeur du secteur de l&rsquo;industrie de la cr&eacute;ation de contenus num&eacute;rique et constitu&eacute; de laboratoires de recherches reconnus, ambitionne de consolider une position d&rsquo;excellence de la recherche et des technologies num&eacute;riques &laquo;Made-in-France&raquo; et la promotion de la culture fran&ccedil;aise &agrave; travers le monde.</p>\n<p class=\"wys-small-text\" style=\"text-align: left;\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-17-CE23-0025.</p>\n<p></p>", "content_fr": "<p>Le projet TheVoice s&rsquo;attaque &agrave; la cr&eacute;ation de voix pour la production de contenu dans le secteur de l'industrie cr&eacute;ative (films, s&eacute;ries, documentaires), secteur tr&egrave;s important en termes de potentiel industriel mais extr&ecirc;mement exigeant en termes de qualit&eacute;. Le projet s&rsquo;appuie sur un constat simple : la production de voix demeure exclusivement effectu&eacute;e par des op&eacute;rateurs humains dans un secteur quasi exclusivement num&eacute;rique.</p>\n<p>Les objectifs scientifiques et technologiques du projet visent &agrave; mod&eacute;liser la &laquo; palette vocale &raquo; d&rsquo;un acteur pour permettre la recommandation de voix par similarit&eacute;, et la cr&eacute;ation de voix artificielles capables de reproduire l&rsquo;identit&eacute; vocale d&rsquo;un acteur. Le projet cr&eacute;era une rupture des usages par la r&eacute;alisation et l&rsquo;industrialisation de nouvelles technologies pour la cr&eacute;ation de contenus vocaux naturels et expressifs. Le consortium, port&eacute; par un acteur majeur du secteur de l&rsquo;industrie de la cr&eacute;ation de contenus num&eacute;rique et constitu&eacute; de laboratoires de recherches reconnus, ambitionne de consolider une position d&rsquo;excellence de la recherche et des technologies num&eacute;riques &laquo;Made-in-France&raquo; et la promotion de la culture fran&ccedil;aise &agrave; travers le monde.</p>\n<p class=\"wys-small-text\" style=\"text-align: left;\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-17-CE23-0025.</p>\n<p></p>", "content_en": "<p>TheVoice project addresses voice design for audiovisual production in the field of the creative, cultural, and entertainment industry. The facts are simples: today, the production of voices is exclusively carried out by humans in a sector almost exclusively digital, and extremely demanding in terms of quality. The scientific objectives of the project are to model the voices of professional actors, naturally expressive, in order to create innovative voice design solutions.&nbsp;</p>\n<p>This modeling will allow the realization of major scientific advances in the analysis and synthesis of expressive voices, with applications to automatic voice recommendation and voice conversion for the casting and the cloning of naturally expressive voices. The project will create a breakdown by the realization and the industrialization of innovative speech technologies for the production of voice content. The consortium, composed of recognized laboratories and industrialists, aims to consolidate a position of excellence for \"Made-in-France\" research and digital technologies, and to promote the French culture all over the world.</p>\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Project Reference: ANR-17-CE23-0025.</p>", "date_from": "2018-01-01", "date_to": "2021-06-30", "user": null, "type": "external", "external_id": "ANR-17-CE23-0025-01", "program": 1, "program_type": 31, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 3, "funding": "public", "teams": [4], "organizations": [645, 1, 656], "referring_person": [109], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 181, "fields": {"keywords_string": "", "site": 1, "title": "REFLETS", "title_fr": "REFLETS", "title_en": "REFLETS", "slug": "reflets", "_meta_title": "", "description": "R\u00e9troaction \u00c9motionnelle Faciale et Linguistique et \u00c9tats de Stress Traumatique", "description_fr": "R\u00e9troaction \u00c9motionnelle Faciale et Linguistique et \u00c9tats de Stress Traumatique", "description_en": "R\u00e9troaction \u00c9motionnelle Faciale et Linguistique et \u00c9tats de Stress Traumatique", "gen_description": false, "created": "2018-01-18T18:26:41.596Z", "updated": "2018-09-12T12:31:44.020Z", "status": 2, "publish_date": "2018-01-18T18:26:41Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p><img src=\"/media/uploads/recherche/projets/projet_reflets.png\" style=\"float: right; margin-left: 10px;\" width=\"600\" height=\"379\" />Le projet REFLETS (R&eacute;troaction &Eacute;motionnelle Faciale et Linguistique et &Eacute;tats de Stress Traumatique) vise l&rsquo;am&eacute;lioration de la prise en charge des personnes souffrant de syndrome de stress post-traumatique (PTSD) via un dispositif technologique agissant sur leur capacit&eacute; &agrave; percevoir et r&eacute;guler leurs propres &eacute;motions. Le projet est bas&eacute; sur de r&eacute;centes technologies d&eacute;velopp&eacute;es &agrave; l&rsquo;Ircam, sur la manipulation temps-r&eacute;el des indices du sourire dans la voix parl&eacute;e, et &agrave; CentraleSup&eacute;lec sur la manipulation vid&eacute;o des indices visuels du sourire sur les visages.</p>\n<p>Les efforts de REFLETS se concentrent dans trois domaines disciplinaires : du point de vue des sciences de l&rsquo;information, le projet vise &agrave; d&eacute;velopper une technologie de &laquo; miroir &eacute;motionnel &raquo; dans lequel un participant peut se voir et s&rsquo;entendre parler, avec un ton &eacute;motionnel manipul&eacute; algorithmiquement (en pratique, se voir et s&rsquo;entendre sourire alors que l&rsquo;on s&rsquo;exprime avec un ton neutre). Du point de vue de la psychologie et neurosciences cognitives, le projet vise &agrave; &eacute;tudier les m&eacute;canismes de perception de soi et de m&eacute;ta-cognition impliqu&eacute; dans ce paradigme de &laquo; faux feedback &raquo;, des travaux pr&eacute;liminaires ayant d&eacute;j&agrave; &eacute;tabli que le fait de s&rsquo;entendre parler avec un ton de voix plus joyeux a un effet positif sur les &eacute;motions du locuteur (Aucouturier et al., PNAS 2016). Enfin, du point de vue clinique, le projet vise &agrave; tester l&rsquo;impact th&eacute;rapeutique d&rsquo;un tel dispositif dans la prise en charge des d&eacute;ficits de perception de soi et de r&eacute;gulation &eacute;motionnelle (alexythymie) dans les troubles post-traumatiques. Le projet menera ainsi un essai clinique sur une population de patients PTSD (apr&egrave;s traumatisme cranien) recrut&eacute; en collaboration avec l&rsquo;H&ocirc;pital militaire Percy.</p>\n<p><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a></p>", "content_fr": "<p><img src=\"/media/uploads/recherche/projets/projet_reflets.png\" style=\"float: right; margin-left: 10px;\" width=\"600\" height=\"379\" />Le projet REFLETS (R&eacute;troaction &Eacute;motionnelle Faciale et Linguistique et &Eacute;tats de Stress Traumatique) vise l&rsquo;am&eacute;lioration de la prise en charge des personnes souffrant de syndrome de stress post-traumatique (PTSD) via un dispositif technologique agissant sur leur capacit&eacute; &agrave; percevoir et r&eacute;guler leurs propres &eacute;motions. Le projet est bas&eacute; sur de r&eacute;centes technologies d&eacute;velopp&eacute;es &agrave; l&rsquo;Ircam, sur la manipulation temps-r&eacute;el des indices du sourire dans la voix parl&eacute;e, et &agrave; CentraleSup&eacute;lec sur la manipulation vid&eacute;o des indices visuels du sourire sur les visages.</p>\n<p>Les efforts de REFLETS se concentrent dans trois domaines disciplinaires : du point de vue des sciences de l&rsquo;information, le projet vise &agrave; d&eacute;velopper une technologie de &laquo; miroir &eacute;motionnel &raquo; dans lequel un participant peut se voir et s&rsquo;entendre parler, avec un ton &eacute;motionnel manipul&eacute; algorithmiquement (en pratique, se voir et s&rsquo;entendre sourire alors que l&rsquo;on s&rsquo;exprime avec un ton neutre). Du point de vue de la psychologie et neurosciences cognitives, le projet vise &agrave; &eacute;tudier les m&eacute;canismes de perception de soi et de m&eacute;ta-cognition impliqu&eacute; dans ce paradigme de &laquo; faux feedback &raquo;, des travaux pr&eacute;liminaires ayant d&eacute;j&agrave; &eacute;tabli que le fait de s&rsquo;entendre parler avec un ton de voix plus joyeux a un effet positif sur les &eacute;motions du locuteur (Aucouturier et al., PNAS 2016). Enfin, du point de vue clinique, le projet vise &agrave; tester l&rsquo;impact th&eacute;rapeutique d&rsquo;un tel dispositif dans la prise en charge des d&eacute;ficits de perception de soi et de r&eacute;gulation &eacute;motionnelle (alexythymie) dans les troubles post-traumatiques. Le projet menera ainsi un essai clinique sur une population de patients PTSD (apr&egrave;s traumatisme cranien) recrut&eacute; en collaboration avec l&rsquo;H&ocirc;pital militaire Percy.</p>\n<p><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a></p>", "content_en": "<p><img src=\"/media/uploads/recherche/projets/projet_reflets.png\" style=\"float: right; margin-left: 10px;\" width=\"600\" height=\"379\" />The project REFLETS (R&eacute;troaction &Eacute;motionnelle Faciale et Linguistique et &Eacute;tats de Stress Traumatique) focuses on improving the care of those suffering from post-traumatic stress syndrome (PTSD) using a technological system that reacts with the sufferer&rsquo;s capacity to perceive and regulate their emotions. The project is based on technologies recently developed at IRCAM on the manipulation, in real-time, of indicators of smiles in the spoken voice and at CentralSup&eacute;lec on the video manipulation of visual cues of a smile on a face.</p>\r\n<p>The project focuses on three different disciplines. In the domain of information sciences, the project aims to develop &ldquo;emotional mirror&rdquo; technology in which the participant can see and hear themselves, but their emotional tone is manipulated algorithmically (in practice, participants will see and hear themselves with a smile while they express themselves using a neutral tone). In the domains of psychology and cognitive neurosciences,&nbsp; REFLECTS aims at studying mechanisms for perception of oneself and meta-cognition involved in this paradigm of false feedback. Preliminary studies have already established that hearing oneself speak with a more joyful tone has a positive effect on the speaker&rsquo;s emotions (Aucouturier et al., PNAS 2016). Finally, from a clinical point of view, the project intends to test the therapeutic impact of this type of system to treat patients suffering from deficiencies in self-perception and emotional control (alexithymia) in post-traumatic troubles. The project will lead to clinical trials on a group of PTSD patients selected in collaboration with the Percy Military Hospital.</p>\r\n<p><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a></p>", "date_from": "2017-10-01", "date_to": "2021-09-30", "user": 4, "type": "external", "external_id": "", "program": 1, "program_type": 30, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 3, "funding": "public", "teams": [3], "organizations": [637, 642, 641, 643, 644, 633, 1], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 182, "fields": {"keywords_string": "", "site": 1, "title": "MICA", "title_fr": "MICA", "title_en": "MICA", "slug": "mica", "_meta_title": "", "description": "Improvisation Musicale et Action Collective", "description_fr": "Improvisation Musicale et Action Collective", "description_en": "Musical Improvisation and Collective Action", "gen_description": false, "created": "2018-04-13T17:31:10.552Z", "updated": "2018-07-25T14:47:22.171Z", "status": 2, "publish_date": "2018-04-13T17:31:10Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>L&rsquo;objectif du projet MICA est de comprendre comment nous faisons pour agir ensemble de mani&egrave;re &agrave; la fois cr&eacute;ative et spontan&eacute;e, en abordant cette question &agrave; partir d&rsquo;une analyse d&eacute;taill&eacute;e de la pratique musicale de l&rsquo;improvisation &laquo; libre &raquo;. Plus pr&eacute;cis&eacute;ment, il s'agit de comprendre :</p>\r\n<ol>\r\n<li>Comment les agents n&eacute;gocient entre l&rsquo;exigence de coordination &ndash; propre aux situations d&rsquo;action collective &ndash; et l&rsquo;exigence d&rsquo;innovation &ndash; propre aux contextes cr&eacute;atifs ;</li>\r\n<li>Comment la forme de la coordination elle-m&ecirc;me peut servir de support &agrave; la communication entre les agents dans le d&eacute;roulement de l&rsquo;action collective ;</li>\r\n<li>Comment s&rsquo;articulent, dans le temps de l&rsquo;action, les ph&eacute;nom&egrave;nes de coordination de bas niveau (essentiellement moteurs) et les ph&eacute;nom&egrave;nes de cognition sociale de plus haut niveau (attributions d&rsquo;intentions aux autres agents, etc.) qui semblent n&eacute;cessaires au d&eacute;ploiement d&rsquo;une action collective un tant soit peu complexe.</li>\r\n</ol>\r\n<p>Dans un premier temps, l&rsquo;&eacute;quipe du projet MICA collectera des descriptions denses et pr&eacute;cises d&rsquo;actions collectivement improvis&eacute;es et des processus de coordination &agrave; l&rsquo;&oelig;uvre dans ce type d&rsquo;action &agrave; la fois complexe et spontan&eacute;e &agrave; travers plusieurs enqu&ecirc;tes ethnographiques longitudinales aupr&egrave;s de diff&eacute;rents collectifs d&rsquo;improvisateurs ainsi que de la Classe d&rsquo;Improvisation G&eacute;n&eacute;rative du Conservatoire de Paris. L&rsquo;&eacute;tude crois&eacute;e de ces diff&eacute;rents terrains permettra d&rsquo;observer comment le mode op&eacute;ratoire de la cr&eacute;ation collective se modifie lorsque les conditions de la coordination entre les musiciens varient.</p>\r\n<p>Ce travail ethnographique fournira les bases qui nous permettront de renouveler en profondeur les questions exp&eacute;rimentales traditionnellement pos&eacute;es au sujet de l&rsquo;action conjointe, en abordant la question de la coordination &eacute;mergente autrement que par le paradigme de la synchronisation. Il s&rsquo;agira donc dans un deuxi&egrave;me temps de mettre en place une s&eacute;rie de protocoles exp&eacute;rimentaux, inscrits dans la psychologie exp&eacute;rimentale et la cognition sociale, qui auront pour objectif de mettre en lumi&egrave;re certains aspects fondamentaux de l&rsquo;interaction dyadique improvis&eacute;e. On envisage ainsi des protocoles permettant d&rsquo;aborder cette question sur trois &eacute;chelles de temps diff&eacute;rentes : l&rsquo;&eacute;tude des strat&eacute;gies d&eacute;ploy&eacute;es par les agents pour coordonner quasi instantan&eacute;ment leurs actions respectives avec le maximum de fluidit&eacute; ; l&rsquo;analyse de la mani&egrave;re dont les indices de coordination et les ressources de l&rsquo;interaction sont int&eacute;gr&eacute;s continument dans le temps de la performance pour permettre la communication d&rsquo;intentions complexes ; la&nbsp; mise en &eacute;vidence des marqueurs de cognition d&rsquo;&eacute;quipe qui se s&eacute;dimentent sur le temps long de la collaboration.</p>\r\n<p>Enfin, il s&rsquo;agira de confronter les r&eacute;sultats des enqu&ecirc;tes et des exp&eacute;riences aux diff&eacute;rentes th&eacute;ories philosophiques de l&rsquo;action conjointe. Ce travail d&rsquo;&eacute;laboration th&eacute;orique d&eacute;bouchera soit sur la proposition de r&eacute;visions ou d&rsquo;amendements pour les th&eacute;ories d&eacute;j&agrave; existantes qui se pr&ecirc;tent le mieux &agrave; penser le cas de l&rsquo;improvisation collective, soit, le cas &eacute;ch&eacute;ant, sur une nouvelle th&eacute;orie de l&rsquo;action collective construite &agrave; partir des donn&eacute;es empiriques obtenues au sein du projet MICA, visant &agrave; pleinement rendre compte de la dimension improvis&eacute;e de l&rsquo;agir collectif.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-17-CE27-0021-01.</p>", "content_fr": "<p>L&rsquo;objectif du projet MICA est de comprendre comment nous faisons pour agir ensemble de mani&egrave;re &agrave; la fois cr&eacute;ative et spontan&eacute;e, en abordant cette question &agrave; partir d&rsquo;une analyse d&eacute;taill&eacute;e de la pratique musicale de l&rsquo;improvisation &laquo; libre &raquo;. Plus pr&eacute;cis&eacute;ment, il s'agit de comprendre :</p>\r\n<ol>\r\n<li>Comment les agents n&eacute;gocient entre l&rsquo;exigence de coordination &ndash; propre aux situations d&rsquo;action collective &ndash; et l&rsquo;exigence d&rsquo;innovation &ndash; propre aux contextes cr&eacute;atifs ;</li>\r\n<li>Comment la forme de la coordination elle-m&ecirc;me peut servir de support &agrave; la communication entre les agents dans le d&eacute;roulement de l&rsquo;action collective ;</li>\r\n<li>Comment s&rsquo;articulent, dans le temps de l&rsquo;action, les ph&eacute;nom&egrave;nes de coordination de bas niveau (essentiellement moteurs) et les ph&eacute;nom&egrave;nes de cognition sociale de plus haut niveau (attributions d&rsquo;intentions aux autres agents, etc.) qui semblent n&eacute;cessaires au d&eacute;ploiement d&rsquo;une action collective un tant soit peu complexe.</li>\r\n</ol>\r\n<p>Dans un premier temps, l&rsquo;&eacute;quipe du projet MICA collectera des descriptions denses et pr&eacute;cises d&rsquo;actions collectivement improvis&eacute;es et des processus de coordination &agrave; l&rsquo;&oelig;uvre dans ce type d&rsquo;action &agrave; la fois complexe et spontan&eacute;e &agrave; travers plusieurs enqu&ecirc;tes ethnographiques longitudinales aupr&egrave;s de diff&eacute;rents collectifs d&rsquo;improvisateurs ainsi que de la Classe d&rsquo;Improvisation G&eacute;n&eacute;rative du Conservatoire de Paris. L&rsquo;&eacute;tude crois&eacute;e de ces diff&eacute;rents terrains permettra d&rsquo;observer comment le mode op&eacute;ratoire de la cr&eacute;ation collective se modifie lorsque les conditions de la coordination entre les musiciens varient.</p>\r\n<p>Ce travail ethnographique fournira les bases qui nous permettront de renouveler en profondeur les questions exp&eacute;rimentales traditionnellement pos&eacute;es au sujet de l&rsquo;action conjointe, en abordant la question de la coordination &eacute;mergente autrement que par le paradigme de la synchronisation. Il s&rsquo;agira donc dans un deuxi&egrave;me temps de mettre en place une s&eacute;rie de protocoles exp&eacute;rimentaux, inscrits dans la psychologie exp&eacute;rimentale et la cognition sociale, qui auront pour objectif de mettre en lumi&egrave;re certains aspects fondamentaux de l&rsquo;interaction dyadique improvis&eacute;e. On envisage ainsi des protocoles permettant d&rsquo;aborder cette question sur trois &eacute;chelles de temps diff&eacute;rentes : l&rsquo;&eacute;tude des strat&eacute;gies d&eacute;ploy&eacute;es par les agents pour coordonner quasi instantan&eacute;ment leurs actions respectives avec le maximum de fluidit&eacute; ; l&rsquo;analyse de la mani&egrave;re dont les indices de coordination et les ressources de l&rsquo;interaction sont int&eacute;gr&eacute;s continument dans le temps de la performance pour permettre la communication d&rsquo;intentions complexes ; la&nbsp; mise en &eacute;vidence des marqueurs de cognition d&rsquo;&eacute;quipe qui se s&eacute;dimentent sur le temps long de la collaboration.</p>\r\n<p>Enfin, il s&rsquo;agira de confronter les r&eacute;sultats des enqu&ecirc;tes et des exp&eacute;riences aux diff&eacute;rentes th&eacute;ories philosophiques de l&rsquo;action conjointe. Ce travail d&rsquo;&eacute;laboration th&eacute;orique d&eacute;bouchera soit sur la proposition de r&eacute;visions ou d&rsquo;amendements pour les th&eacute;ories d&eacute;j&agrave; existantes qui se pr&ecirc;tent le mieux &agrave; penser le cas de l&rsquo;improvisation collective, soit, le cas &eacute;ch&eacute;ant, sur une nouvelle th&eacute;orie de l&rsquo;action collective construite &agrave; partir des donn&eacute;es empiriques obtenues au sein du projet MICA, visant &agrave; pleinement rendre compte de la dimension improvis&eacute;e de l&rsquo;agir collectif.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-17-CE27-0021-01.</p>", "content_en": "<p>The goal of the MICA project is to look at collective action through the lens of musical improvisation, particularly in situations of so-called &rdquo;free&rdquo; improvisation. The project endeavors to understand :</p>\r\n<ol>\r\n<li>How operational modes vary between the demands of coordination&mdash;found in situations of collective action&mdash;and the demands of innovation found solely in creative contexts</li>\r\n<li>How the form of the coordination can be used as a support for communication among operators during collective action</li>\r\n<li>How, during an action, the phenomena of low-level coordination (essentially motor) and the phenomena of high-level social cognition (attributions of intentions towards other operators, etc.) that seem necessary to put in place a collective action that is, in itself, simple.</li>\r\n</ol>\r\n<p>To begin, the team working on the MICA project will collect complete and detail descriptions of collective improvised actions as well as the complex and spontaneous processes of coordination used in this type of action. This will be carried out through several longitudinal ethnographic studies of different improvisational collectives and the &ldquo;Classe d&rsquo;Improvisation G&eacute;n&eacute;rative&rdquo; at the Paris Conservatory. The crossover study of these various fields makes it possible to observe how the collective modus operandi is modified when the conditions of coordination among musicians changes.</p>\r\n<p>This ethnographic work will create the foundation on which we can raise issues typically investigated on conjoint action, addressing the question of emerging coordination differently from the paradigm of synchronization. The next step is putting in place a series of experimental protocols, found in experimental psychology and social cognition,&nbsp; with the goal of shedding light on certain fundamental aspects of improvised didactic interaction. We also envisage protocols that make it possible to address this issue in three different time-frames: studying strategies used by agents to coordinate, almost instantaneously, their individual actions with optimal fluidity; the analysis of material, including indications of coordination and resources, is continuously integrated in the performance time permitting communication of complex intentions; highlighting markers of team cognition that have been appropriated after long periods of collaboration.</p>\r\n<p>Finally, the results of the surveys and experiments will be compared with philosophical theories on collective action. The formulation of this theoretical work will lead to either a proposition to revise or amend existing theories which lend themselves best to thin.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" />P</a>roject reference: ANR-17-CE27-0021-01.</p>", "date_from": "2018-03-01", "date_to": "2021-02-28", "user": null, "type": "external", "external_id": "ANR-17-CE27-0021-01", "program": 1, "program_type": 8, "call": null, "lead_team": null, "lead_organization": 1, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": "public", "teams": [6, 7, 3], "organizations": [147, 634], "referring_person": [570], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 183, "fields": {"keywords_string": "", "site": 1, "title": "DEMOS", "title_fr": "DEMOS", "title_en": "", "slug": "demos", "_meta_title": "", "description": "DEMOS", "description_fr": "DEMOS", "description_en": "DEMOS", "gen_description": true, "created": "2018-04-13T17:37:16.092Z", "updated": "2018-04-13T17:37:16.093Z", "status": 1, "publish_date": "2018-04-13T17:37:16.090Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "", "content_fr": "", "content_en": "", "date_from": "2017-01-01", "date_to": "2019-12-31", "user": null, "type": "external", "external_id": "DEMOS", "program": null, "program_type": null, "call": null, "lead_team": 7, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 3, "funding": null, "teams": [7], "organizations": [], "referring_person": [70], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 184, "fields": {"keywords_string": "", "site": 1, "title": "ENTRECORPS", "title_fr": "ENTRECORPS", "title_en": "ENTRECORPS", "slug": "entrecorps", "_meta_title": "", "description": "\u00c9tude sur des m\u00e9canismes de coordination interpersonnelle dans les interactions humaines m\u00e9diatis\u00e9es", "description_fr": "\u00c9tude sur des m\u00e9canismes de coordination interpersonnelle dans les interactions humaines m\u00e9diatis\u00e9es", "description_en": "Study the mechanisms of interpersonal coordination in public human interactions.", "gen_description": false, "created": "2018-06-20T12:56:53.238Z", "updated": "2018-06-29T11:02:49.081Z", "status": 2, "publish_date": "2018-06-20T12:56:53Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Les interactions humaines m&eacute;diatis&eacute;es sont &eacute;tudi&eacute;es depuis plusieurs ann&eacute;es par les disciplines relevant des sciences de l'ing&eacute;nieur et de la robotique, de part l'importance croissante que prennent les machines dans la communication entre les humains. Parall&egrave;lement, les neurosciences commencent &agrave; s'int&eacute;resser &agrave; l'inscription de l'homme dans sa soci&eacute;t&eacute; et r&eacute;alisent qu'il est difficile d'&eacute;tablir les m&eacute;canismes neuronaux de la cognition sociale en &eacute;tudiant des individus en isolation. Si l'on sait depuis longtemps que le contexte social module les r&eacute;ponses comportementales aux stimuli sensoriels, il n'en reste pas moins que prendre en compte celui-ci n'est pas une pratique courante de la d&eacute;marche exp&eacute;rimentale adopt&eacute;e en neurosciences comportementales chez l'homme. Avec l'introduction des nouvelles formes de communication, les interactions humaines sont m&eacute;diatis&eacute;es et sans doute transform&eacute;es.</p>\r\n<p>Ce projet se propose de croiser les connaissances de plusieurs champs disciplinaires afin d'aboutir &agrave; l'&eacute;tude des m&eacute;canismes de coordination interpersonnelle dans les interactions humaines m&eacute;diatis&eacute;es. Saisissant l'opportunit&eacute; que repr&eacute;sentent les nouvelles applications collaboratives, nous d&eacute;sirons les utiliser comme des outils exp&eacute;rimentaux pour apporter des connaissances aux neurosciences cognitives et sociales. Inversement, les r&eacute;sultats de nos exp&eacute;riences devraient pouvoir servir d'&eacute;valuation aux applications collaboratives, questionnant les m&eacute;canismes sensoriels qu'elles mettent en jeu, leur retomb&eacute;es sociales et artistiques.</p>\r\n<p>Un premier exemple d&rsquo;&eacute;tude est celui de l&rsquo;espace p&eacute;ri-personnel, &eacute;tudi&eacute; cette fois non plus chez le sujet isol&eacute; mais en situation d&rsquo;interaction. Il y a plus de 50 ans, l'anthropologue Edward Hall cr&eacute;ait la notion de prox&eacute;mie, d&eacute;finissant les diff&eacute;rents compartiments de l'espace autour du corps et leur fonction sociale. Depuis peu, ces travaux ont &eacute;t&eacute; reli&eacute;s aux recherches en neurophysiologie &eacute;tablissant les bases neuronales de l'espace peri-personnel (EPP). Cet EPP est cod&eacute; au niveau c&eacute;r&eacute;bral comme une interface motrice et multisensorielle entre le corps et l&rsquo;environnement. Plusieurs &eacute;tudes mettent en &eacute;vidence la plasticit&eacute; des limites de cet espace virtuel entourant le corps du sujet, en fonction de la situation sociale et &eacute;motionnelle dans laquelle il se trouve.</p>\r\n<p>Une &eacute;tude a &eacute;t&eacute; d&eacute;velopp&eacute;e pour investiguer l&rsquo;impact de diff&eacute;rents contextes sociaux sur la taille de l&rsquo;espace p&eacute;ri-personnel, en particulier des contextes de collaboration ou de comp&eacute;tition entre individus. Ces &eacute;tudes ont permis de confirmer la sp&eacute;cificit&eacute; de la collaboration comme contexte social modulant la taille de l&rsquo;espace p&eacute;ri-personnel.</p>", "content_fr": "<p>Les interactions humaines m&eacute;diatis&eacute;es sont &eacute;tudi&eacute;es depuis plusieurs ann&eacute;es par les disciplines relevant des sciences de l'ing&eacute;nieur et de la robotique, de part l'importance croissante que prennent les machines dans la communication entre les humains. Parall&egrave;lement, les neurosciences commencent &agrave; s'int&eacute;resser &agrave; l'inscription de l'homme dans sa soci&eacute;t&eacute; et r&eacute;alisent qu'il est difficile d'&eacute;tablir les m&eacute;canismes neuronaux de la cognition sociale en &eacute;tudiant des individus en isolation. Si l'on sait depuis longtemps que le contexte social module les r&eacute;ponses comportementales aux stimuli sensoriels, il n'en reste pas moins que prendre en compte celui-ci n'est pas une pratique courante de la d&eacute;marche exp&eacute;rimentale adopt&eacute;e en neurosciences comportementales chez l'homme. Avec l'introduction des nouvelles formes de communication, les interactions humaines sont m&eacute;diatis&eacute;es et sans doute transform&eacute;es.</p>\r\n<p>Ce projet se propose de croiser les connaissances de plusieurs champs disciplinaires afin d'aboutir &agrave; l'&eacute;tude des m&eacute;canismes de coordination interpersonnelle dans les interactions humaines m&eacute;diatis&eacute;es. Saisissant l'opportunit&eacute; que repr&eacute;sentent les nouvelles applications collaboratives, nous d&eacute;sirons les utiliser comme des outils exp&eacute;rimentaux pour apporter des connaissances aux neurosciences cognitives et sociales. Inversement, les r&eacute;sultats de nos exp&eacute;riences devraient pouvoir servir d'&eacute;valuation aux applications collaboratives, questionnant les m&eacute;canismes sensoriels qu'elles mettent en jeu, leur retomb&eacute;es sociales et artistiques.</p>\r\n<p>Un premier exemple d&rsquo;&eacute;tude est celui de l&rsquo;espace p&eacute;ri-personnel, &eacute;tudi&eacute; cette fois non plus chez le sujet isol&eacute; mais en situation d&rsquo;interaction. Il y a plus de 50 ans, l'anthropologue Edward Hall cr&eacute;ait la notion de prox&eacute;mie, d&eacute;finissant les diff&eacute;rents compartiments de l'espace autour du corps et leur fonction sociale. Depuis peu, ces travaux ont &eacute;t&eacute; reli&eacute;s aux recherches en neurophysiologie &eacute;tablissant les bases neuronales de l'espace peri-personnel (EPP). Cet EPP est cod&eacute; au niveau c&eacute;r&eacute;bral comme une interface motrice et multisensorielle entre le corps et l&rsquo;environnement. Plusieurs &eacute;tudes mettent en &eacute;vidence la plasticit&eacute; des limites de cet espace virtuel entourant le corps du sujet, en fonction de la situation sociale et &eacute;motionnelle dans laquelle il se trouve.</p>\r\n<p>Une &eacute;tude a &eacute;t&eacute; d&eacute;velopp&eacute;e pour investiguer l&rsquo;impact de diff&eacute;rents contextes sociaux sur la taille de l&rsquo;espace p&eacute;ri-personnel, en particulier des contextes de collaboration ou de comp&eacute;tition entre individus. Ces &eacute;tudes ont permis de confirmer la sp&eacute;cificit&eacute; de la collaboration comme contexte social modulant la taille de l&rsquo;espace p&eacute;ri-personnel.</p>", "content_en": "<p>Public human interactions have been studied for several years by disciplines such as engineering and robotics, due to the growing impact of machines in communication among humans. Concurrently, neuroscience has begun to address the inclusion of humans in society and realize that it is difficult to establish social cognition neuronal mechanisms by studying isolated individuals. While we have long known that social context controls behavioral responses to sensorial stimuli, taking this factor into account is not common practice in the experimental protocol adopted in human behavioral neurosciences. With the introduction of new forms of communication, human interactions are made public and undoubtedly transformed.</p>\r\n<p>This project aims to cross-reference knowledge from several disciplines to study the mechanisms of interpersonal coordination in public human interactions. Taking advantage of new collaborative applications, we would like to use them as experimental tools to provide knowledge to cognitive and social neurosciences. Inversely, the results of our experiments should be used to assess collaborative applications, questioning the sensory mechanisms they reveal as well as their social and artistic consequences.</p>\r\n<p>The first example is that of personal space, studied this time in a situation of interaction. Over 50 years ago, the anthropologist Edward Hall created the idea of proxemics, defining different levels of territory around the body and their social function. Recently, this work was associated with research in neurophysiology establishing the neuronal standards for personal space. This personal space is coded on a cerebral level like a motor and multisensory interface between body and environment. Several studies have revealed the plasticity of the limits of this virtual space around the subject&rsquo;s body depending on the social and emotional situation in which she is placed.</p>\r\n<p>A study was developed to investigate the impact of different social contexts on the size of personal space, in particular in contexts of either collaboration or competition between subjects. These studies confirmed the specificity of collaboration as a social context that controls the volume of personal space.</p>", "date_from": "2017-09-01", "date_to": "2018-06-30", "user": 4, "type": "external", "external_id": "", "program": null, "program_type": 29, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [2], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 185, "fields": {"keywords_string": "", "site": 1, "title": "ALCOLL", "title_fr": "ALCOLL", "title_en": "ALCOLL", "slug": "alcoll", "_meta_title": "", "description": "Analyser le collectif dans les processus de cr\u00e9ation musicale", "description_fr": "Analyser le collectif dans les processus de cr\u00e9ation musicale", "description_en": "Anlayse the collective in the musical creation processes", "gen_description": false, "created": "2018-06-21T09:31:46.062Z", "updated": "2018-06-29T11:02:28.238Z", "status": 2, "publish_date": "2018-06-21T09:31:46Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet vise &agrave; rendre compte de processus cr&eacute;ateurs en musique par-del&agrave; l&rsquo;opposition suppos&eacute;e entre individuel et collectif (et, par l&agrave;-m&ecirc;me, entre musicologie et sciences humaines et sociales). Qu&rsquo;est-ce qui, dans un travail musical donn&eacute;, tient du particulier et qu&rsquo;est-ce qui tient du g&eacute;n&eacute;ral ? Qu&rsquo;est-ce qui rel&egrave;ve en propre de la participation de tel ou telle &agrave; l&rsquo;action cr&eacute;ative ? C&rsquo;est ce dont le projet ALCOLL se propose de prendre la mesure &agrave; travers une relecture de donn&eacute;es issues d&rsquo;observations de situations de cr&eacute;ation musicale (composition, improvisation, interpr&eacute;tation), l'organisation de s&eacute;minaires, ainsi que la r&eacute;alisation d'une enqu&ecirc;te ethnographique.&nbsp;</p>", "content_fr": "<p>Ce projet vise &agrave; rendre compte de processus cr&eacute;ateurs en musique par-del&agrave; l&rsquo;opposition suppos&eacute;e entre individuel et collectif (et, par l&agrave;-m&ecirc;me, entre musicologie et sciences humaines et sociales). Qu&rsquo;est-ce qui, dans un travail musical donn&eacute;, tient du particulier et qu&rsquo;est-ce qui tient du g&eacute;n&eacute;ral ? Qu&rsquo;est-ce qui rel&egrave;ve en propre de la participation de tel ou telle &agrave; l&rsquo;action cr&eacute;ative ? C&rsquo;est ce dont le projet ALCOLL se propose de prendre la mesure &agrave; travers une relecture de donn&eacute;es issues d&rsquo;observations de situations de cr&eacute;ation musicale (composition, improvisation, interpr&eacute;tation), l'organisation de s&eacute;minaires, ainsi que la r&eacute;alisation d'une enqu&ecirc;te ethnographique.&nbsp;</p>", "content_en": "<p>This project aims at understanding the creative process in music beyond the supposed opposition between the individual and the collective (and between musicology and the humanities and social sciences). Who is who in a given musical work? What is unique and what is general?&nbsp; What is specific to participation or to a creative action? This is what the ALCOLL project endeavors to measure by reexamining data by observing situations of musical creation (composition, improvisation, performance), the organization of seminars, and the realization of a ethnographical survey.</p>", "date_from": "2017-09-01", "date_to": "2018-07-31", "user": null, "type": "external", "external_id": "", "program": null, "program_type": 29, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 26, "is_archive": false, "validation_status": 1, "funding": null, "teams": [6], "organizations": [1, 649], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 186, "fields": {"keywords_string": "", "site": 1, "title": "INFIDHEM", "title_fr": "INFIDHEM", "title_en": "INFIDHEM", "slug": "infidhem", "_meta_title": "", "description": "Syst\u00e8mes interconnect\u00e9s de dimension infinie pour les milieux h\u00e9t\u00e9rog\u00e8nes", "description_fr": "Syst\u00e8mes interconnect\u00e9s de dimension infinie pour les milieux h\u00e9t\u00e9rog\u00e8nes", "description_en": "Interconnected inFInite-Dimensional systems for HEterogeneous Media", "gen_description": false, "created": "2018-06-29T13:00:54.674Z", "updated": "2018-07-25T14:42:23.554Z", "status": 2, "publish_date": "2018-06-29T13:00:54Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Motiv&eacute;s par les progr&egrave;s technologiques r&eacute;cents dans les domaines de la m&eacute;canique, de l'a&eacute;ronautique, des syst&egrave;mes &eacute;nerg&eacute;tiques et de l'ing&eacute;nierie chimique et des nouveaux outils de calcul, l'analyse et le contr&ocirc;le des syst&egrave;mes &agrave; dimension infinie sont devenus un sujet d'int&eacute;r&ecirc;t majeur ces derni&egrave;res d&eacute;cennies. Les concepts de base de la th&eacute;orie des syst&egrave;mes classiques ont &eacute;t&eacute; progressivement g&eacute;n&eacute;ralis&eacute;s &agrave; des syst&egrave;mes &agrave; dimension infinie avec des contributions issues de la communaut&eacute; math&eacute;matique et de la communaut&eacute; des ing&eacute;nieurs.</p>\r\n<p>Plus r&eacute;cemment, les scientifiques se sont int&eacute;ress&eacute;s &agrave; la compr&eacute;hension de syst&egrave;mes compos&eacute;s de sous-syst&egrave;mes &agrave; param&egrave;tres distribu&eacute;s (d&eacute;crits par des syst&egrave;mes d'&eacute;quations aux d&eacute;riv&eacute;es partielles, des EDP) qui interagissent dans les r&eacute;seaux. La majeure partie de la litt&eacute;rature existante sur la mod&eacute;lisation, l'analyse et le contr&ocirc;le de syst&egrave;mes, traite des r&eacute;seaux de syst&egrave;mes homog&egrave;nes tels que les fermes de barres &eacute;lastiques ou les propri&eacute;t&eacute;s de conductivit&eacute; thermique des mousses m&eacute;talliques.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-16-CE92-0028.</p>", "content_fr": "<p>Motiv&eacute;s par les progr&egrave;s technologiques r&eacute;cents dans les domaines de la m&eacute;canique, de l'a&eacute;ronautique, des syst&egrave;mes &eacute;nerg&eacute;tiques et de l'ing&eacute;nierie chimique et des nouveaux outils de calcul, l'analyse et le contr&ocirc;le des syst&egrave;mes &agrave; dimension infinie sont devenus un sujet d'int&eacute;r&ecirc;t majeur ces derni&egrave;res d&eacute;cennies. Les concepts de base de la th&eacute;orie des syst&egrave;mes classiques ont &eacute;t&eacute; progressivement g&eacute;n&eacute;ralis&eacute;s &agrave; des syst&egrave;mes &agrave; dimension infinie avec des contributions issues de la communaut&eacute; math&eacute;matique et de la communaut&eacute; des ing&eacute;nieurs.</p>\r\n<p>Plus r&eacute;cemment, les scientifiques se sont int&eacute;ress&eacute;s &agrave; la compr&eacute;hension de syst&egrave;mes compos&eacute;s de sous-syst&egrave;mes &agrave; param&egrave;tres distribu&eacute;s (d&eacute;crits par des syst&egrave;mes d'&eacute;quations aux d&eacute;riv&eacute;es partielles, des EDP) qui interagissent dans les r&eacute;seaux. La majeure partie de la litt&eacute;rature existante sur la mod&eacute;lisation, l'analyse et le contr&ocirc;le de syst&egrave;mes, traite des r&eacute;seaux de syst&egrave;mes homog&egrave;nes tels que les fermes de barres &eacute;lastiques ou les propri&eacute;t&eacute;s de conductivit&eacute; thermique des mousses m&eacute;talliques.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>R&eacute;f&eacute;rence projet : ANR-16-CE92-0028.</p>", "content_en": "<p>Motivated by recent technological progress in mechanical, aeronautical, energy systems and chemical engineering and novel computational tools, the analysis and control of infinite-dimensional systems became a field of major interest during the last decades. The basic concepts of classical systems theory have been progressively generalized to infinite-dimensional systems with contributions stemming from the mathematical as well as from the engineering community.</p>\r\n<p>More recently, scientists became interested in understanding systems composed of distributed-parameter subsystems (described by systems of partial differential equations, PDEs) which interact in networks. Most of the existing literature on modeling, system analysis and control, deals with networks of homogeneous systems such as trusses of elastic rods or the heat conductivity properties of metal foams.</p>\r\n<p class=\"wys-small-text\"><a href=\"http://www.agence-nationale-recherche.fr/\" target=\"_blank\" class=\"wys-unstyled-link\"><img src=\"/media/uploads/logos recherche/anr-finance.jpg\" style=\"margin-right: 10px;\" width=\"60\" height=\"63\" /></a>Projet reference: ANR-16-CE92-0028.</p>", "date_from": "2017-02-01", "date_to": "2020-01-01", "user": null, "type": "external", "external_id": "ANR-16-CE92-0028", "program": 1, "program_type": 28, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [604, 1, 654, 650, 653, 652, 651], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 187, "fields": {"keywords_string": "", "site": 1, "title": "ANIMAGLOTTE", "title_fr": "ANIMAGLOTTE", "title_en": "ANIMAGLOTTE", "slug": "animaglotte", "_meta_title": "", "description": "Syst\u00e8me artificiel d\u2019animation de larynx ex vivo", "description_fr": "Syst\u00e8me artificiel d\u2019animation de larynx ex vivo", "description_en": "Artificial System of Ex Vivo Animation of the Larynx", "gen_description": false, "created": "2018-06-29T13:52:22.580Z", "updated": "2018-09-05T13:04:11.834Z", "status": 2, "publish_date": "2018-06-29T13:52:22Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>La voix humaine peut pr&eacute;senter des caract&eacute;ristiques acoustiques tr&egrave;s variables selon qu&rsquo;il s&rsquo;agisse d&rsquo;une voix chuchot&eacute;e, chant&eacute;e, parl&eacute;e ou pathologique. Pour produire ces diff&eacute;rents types de voix, l&rsquo;&ecirc;tre humain agit principalement sur la longueur de ses plis vocaux et sur leur degr&eacute; de contact (d&eacute;limitant la glotte).</p>\r\n<p>Notre projet vise &agrave; d&eacute;velopper un syst&egrave;me m&eacute;canis&eacute; d&rsquo;animation ex vivo pour des larynx humains excis&eacute;s post-mortem. Apr&egrave;s avoir mesur&eacute; in vivo la dynamique (amplitude et vitesse) des mouvements de la glotte nous souhaitons les reproduire via un contr&ocirc;le m&eacute;canique artificiel.</p>", "content_fr": "<p>La voix humaine peut pr&eacute;senter des caract&eacute;ristiques acoustiques tr&egrave;s variables selon qu&rsquo;il s&rsquo;agisse d&rsquo;une voix chuchot&eacute;e, chant&eacute;e, parl&eacute;e ou pathologique. Pour produire ces diff&eacute;rents types de voix, l&rsquo;&ecirc;tre humain agit principalement sur la longueur de ses plis vocaux et sur leur degr&eacute; de contact (d&eacute;limitant la glotte).</p>\r\n<p>Notre projet vise &agrave; d&eacute;velopper un syst&egrave;me m&eacute;canis&eacute; d&rsquo;animation ex vivo pour des larynx humains excis&eacute;s post-mortem. Apr&egrave;s avoir mesur&eacute; in vivo la dynamique (amplitude et vitesse) des mouvements de la glotte nous souhaitons les reproduire via un contr&ocirc;le m&eacute;canique artificiel.</p>", "content_en": "<p>The human voice has an extremely variable range of acoustic characteristics depending on whether it is a whispered, sung, spoken or pathologically effected voice. To produce these different types of voices, humans use the length of the vocal folds and their level of contact (delineating the glottis).</p>\r\n<p>Our project develops a mechanized system of ex vivo animation for human larynxes excised post-mortem. Following measures taken in vivo of the dynamic (amplitude and speed) of the glottis&rsquo; movements, we aim to reproduce them via an artificial mechanical controller.</p>", "date_from": null, "date_to": null, "user": null, "type": "external", "external_id": "", "program": null, "program_type": 32, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [648, 6, 1, 36], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 188, "fields": {"keywords_string": "", "site": 1, "title": "OndesMartenots", "title_fr": "OndesMartenots", "title_en": "OndesMartenots", "slug": "ondes-martenots", "_meta_title": "", "description": "Virtualisation d\u2019instruments de musique \u00e9lectroniques et clonage analogique/num\u00e9rique de composants pour la conservation", "description_fr": "Virtualisation d\u2019instruments de musique \u00e9lectroniques et clonage analogique/num\u00e9rique de composants pour la conservation", "description_en": "Virtualisation d\u2019instruments de musique \u00e9lectroniques et clonage analogique/num\u00e9rique de composants pour la conservation", "gen_description": false, "created": "2018-07-04T10:10:00.637Z", "updated": "2018-09-12T12:32:17.771Z", "status": 2, "publish_date": "2018-07-04T10:10:00Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p>Ce projet a un double objectif, mus&eacute;al et scientifique.</p>\r\n<p>L'objectif mus&eacute;al concerne la g&eacute;n&eacute;ration automatique (i) de documentation sur les instruments et (ii) de code de simulation pour &laquo; l&rsquo;&eacute;coute non invasive &raquo;, importante pour la pr&eacute;servation sous des formes virtuelles jouables. Il concerne &eacute;galement le clonage de composants &eacute;lectroniques &agrave; technologie ancienne sous forme de composants analogiques programmables ins&eacute;rables dans des circuits, point important pour la pr&eacute;servation d&rsquo;instruments sous forme non virtuelle.</p>\r\n<p>L'objectif scientifique porte sur les mod&egrave;les physiques de composants &eacute;lectroniques non lin&eacute;aires anciens, simulation temps r&eacute;el &agrave; passivit&eacute; garantie de circuits &eacute;lectroniques avec g&eacute;n&eacute;ration automatique de documentation et de code de simulation (travaux fond&eacute;s sur les Syst&egrave;mes Hamiltoniens &agrave; Port, formalisme tr&egrave;s productif pour les syst&egrave;mes multi-physiques). Il porte &eacute;galement sur la conception de composants &eacute;lectroniques analogiques programmables et la mise au point d&rsquo;une m&eacute;thodologie g&eacute;n&eacute;rale applicable aux ondes Martenot et d&rsquo;autres grandes familles de circuits analogiques audios.</p>", "content_fr": "<p>Ce projet a un double objectif, mus&eacute;al et scientifique.</p>\r\n<p>L'objectif mus&eacute;al concerne la g&eacute;n&eacute;ration automatique (i) de documentation sur les instruments et (ii) de code de simulation pour &laquo; l&rsquo;&eacute;coute non invasive &raquo;, importante pour la pr&eacute;servation sous des formes virtuelles jouables. Il concerne &eacute;galement le clonage de composants &eacute;lectroniques &agrave; technologie ancienne sous forme de composants analogiques programmables ins&eacute;rables dans des circuits, point important pour la pr&eacute;servation d&rsquo;instruments sous forme non virtuelle.</p>\r\n<p>L'objectif scientifique porte sur les mod&egrave;les physiques de composants &eacute;lectroniques non lin&eacute;aires anciens, simulation temps r&eacute;el &agrave; passivit&eacute; garantie de circuits &eacute;lectroniques avec g&eacute;n&eacute;ration automatique de documentation et de code de simulation (travaux fond&eacute;s sur les Syst&egrave;mes Hamiltoniens &agrave; Port, formalisme tr&egrave;s productif pour les syst&egrave;mes multi-physiques). Il porte &eacute;galement sur la conception de composants &eacute;lectroniques analogiques programmables et la mise au point d&rsquo;une m&eacute;thodologie g&eacute;n&eacute;rale applicable aux ondes Martenot et d&rsquo;autres grandes familles de circuits analogiques audios.</p>", "content_en": "<p>This project has a dual focus: museums and science&nbsp;&nbsp;&nbsp;</p>\r\n<p>The objective for museums in this project concerns the automatic generation of documentation for instruments and simulation code for &ldquo;non-invasive listening&rdquo;&mdash;important for preserving playable virtual forms&mdash;in addition to electronic cloning of ancient technological components as programmable analog components that can be inserted in circuits, an important factor for the preservation of instruments in a non-virtual form.</p>\r\n<p>The scientific objective focuses on physical models of old non-linear electronic components, simulation in real-time with guaranteed passivity of electronic circuits, and automatic generation of documentation and simulation code (work based on Port-Hamiltonien systems, a very productive formalism for multi-physical systems). It also focuses on the conception of programmable analogical electronic components and the creation of a general methodology applicable to ondes Martenot and other families of analogical audio circuits.</p>", "date_from": null, "date_to": null, "user": null, "type": "external", "external_id": "", "program": 15, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 25, "is_archive": false, "validation_status": 1, "funding": null, "teams": [44], "organizations": [1, 655], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 189, "fields": {"keywords_string": "", "site": 1, "title": "Symbioz", "title_fr": "Symbioz", "title_en": "Symbioz", "slug": "symbioz", "_meta_title": "", "description": "Conception du design sonore de la Renault Symbioz", "description_fr": "Conception du design sonore de la Renault Symbioz", "description_en": "Renault Symbioz Sound Design", "gen_description": false, "created": "2018-09-20T11:29:13.285Z", "updated": "2018-09-20T12:47:31.109Z", "status": 2, "publish_date": "2018-09-20T11:29:13Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "<p><strong>En concevant le design sonore de la Renault Symbioz, le nouveau concept car de Renault, un v&eacute;hicule &eacute;lectrique et autonome, l&rsquo;&eacute;quipe <a href=\"/recherche/equipes-recherche/pds/\">Perception et design sonores</a> de l&rsquo;Ircam a r&eacute;pondu &agrave; deux challenges : la conception d&rsquo;un son de signal&eacute;tique avertissant les pi&eacute;tons de la pr&eacute;sence du v&eacute;hicule, et la conception d&rsquo;une gamme de sons destin&eacute;s &agrave; l&rsquo;habitacle de la voiture.</strong></p>\r\n<p><img src=\"/media/uploads/recherche/projets/symbioz.jpg\" style=\"float: right; margin-left: 10px;\" width=\"480\" height=\"321\" />Lors de l&rsquo;&eacute;dition 2017 du Salon de l&rsquo;Automobile &agrave; Francfort, Renault d&eacute;voile sa vision pour 2030 : elle s&rsquo;incarne dans le concept car Symbioz. Le constructeur offre m&ecirc;me aux journalistes l&rsquo;opportunit&eacute; de l&rsquo;essayer.</p>\r\n<p>En amont, une collaboration industrielle est initi&eacute;e pour mettre au point la signature sonore du v&eacute;hicule, entre les laboratoires de Design et innovation de Renault et l&rsquo;&eacute;quipe Perception et design sonores de l&rsquo;Ircam, repr&eacute;sent&eacute;e par l&rsquo;ing&eacute;nieur-chercheur Nicolas Misdariis et le compositeur Andrea Cera.</p>\r\n<p>La Renault Symbioz est la promesse d&rsquo;une fusion entre v&eacute;hicule et espace de vie. Le projet porte une attention toute particuli&egrave;re au confort et &agrave; la qui&eacute;tude du passager, ainsi qu&rsquo;&agrave; l&rsquo;exp&eacute;rimentation des nouvelles technologies pour le contr&ocirc;le du comportement de la voiture et l&rsquo;ambiance &agrave; l&rsquo;int&eacute;rieur du cockpit. Il comporte deux challenges : la conception d&rsquo;un son externe qui avertit les pi&eacute;tons de la pr&eacute;sence du v&eacute;hicule (la signature sonore), et la conception d&rsquo;une gamme de sons destin&eacute;s &agrave; l&rsquo;habitacle de la voiture (les sons du cockpit).</p>\r\n<p>La signature sonore est activ&eacute;e lorsque la vitesse de la voiture se situe entre 0 et 30 km/h &ndash;, une plage de vitesse durant laquelle la voiture &eacute;lectrique est potentiellement silencieuse. Ses caract&eacute;ristiques sont issues de deux projets pr&eacute;c&eacute;dents &eacute;labor&eacute;s par la m&ecirc;me &eacute;quipe : la signature sonore de la Renault Trezor (un concept car) et de la Renault Zo&eacute; (un mod&egrave;le commercialis&eacute;).</p>\r\n<p>La signature sonore de la Symbioz est un hybride entre composants &eacute;lectriques et turbine, avec une touche de moteur &agrave; combustion, puissante sans &ecirc;tre agressive. Quand le moteur est au ralenti, il &eacute;met de courtes s&eacute;quences sonores &agrave; la fois douces et aigues cr&eacute;ant ainsi un langage abstrait (r&eacute;sultant de l&rsquo;&eacute;mergence d&rsquo;&eacute;l&eacute;ments appel&eacute;s &laquo; agents audio &raquo;) et avertissant les pi&eacute;tons que le moteur est allum&eacute;. Le prototype du son est cr&eacute;&eacute; dans le logiciel Max puis convertit dans un environnement propri&eacute;taire.</p>\r\n<p>La Symbioz est &eacute;galement un vrai laboratoire d&rsquo;&eacute;tude pour les sons de cockpit du futur. L&rsquo;Ircam a d&eacute;velopp&eacute; un ensemble d&rsquo;interfaces sonores homme-machine innovantes (IHM) dans deux directions distinctes :</p>\r\n<p style=\"padding-left: 30px;\">1. Exhaustivit&eacute;<br />C&rsquo;est la totalit&eacute; des interactions conducteur/passager/cockpit, li&eacute;es aux modes de fonctionnement de la Symbioz, qui a &eacute;t&eacute; trait&eacute;e.<br />A ce titre, la possibilit&eacute; d&rsquo;un mode de conduite autonome implique de nouveaux challenges au niveau du design : comment communiquer les diff&eacute;rents niveaux d&rsquo;autonomie de la voiture ? Comment rassurer les passagers lorsque la voiture est en mode de conduite autonome ? Pour y r&eacute;pondre, un prototype dans Max a &eacute;t&eacute; cr&eacute;e afin de g&eacute;rer le grand nombre d&rsquo;IHM n&eacute;cessaires &agrave; la r&eacute;alisation du projet.</p>\r\n<p style=\"padding-left: 30px;\">2. Spatialisation<br />Un concept original d&rsquo;IHM sonores spatialis&eacute;es ont &eacute;t&eacute; d&eacute;velopp&eacute;es.<br />Chaque son &eacute;mis dans le cockpit de la Symbioz (clignotants, alarmes, sons informatifs...) est positionn&eacute; dans un espace acoustique virtuel. La voiture dispose de trois modes de conduite (Classique, Dynamique, Autonome). Dans chaque mode, les sons tournent l&eacute;g&egrave;rement autour de positions virtuelles, avec divers degr&eacute;s de modulation et de r&eacute;verb&eacute;ration. Par exemple, dans le mode Dynamique, les clignotants sont plac&eacute;s de fa&ccedil;on tr&egrave;s stable dans la direction que la voiture va emprunter. Dans le mode Autonome, l&rsquo;orientation des clignotants est beaucoup plus souple puisque qu&rsquo;aucun passager ne se concentre sur la conduite. En bougeant dans l&rsquo;espace, les IHMs deviennent moins g&ecirc;nantes et plus naturelles &ndash; les changements de position se traduisent par de subtiles alt&eacute;rations de timbre d&ucirc;es au d&eacute;phasage et &agrave; la r&eacute;verb&eacute;ration sur les murs du cockpit.</p>\r\n<p class=\"wys-small-text\"><a href=\"https://audio-branding-academy.org/renault-symbioz-sound-design/\" target=\"_blank\">https://audio-branding-academy.org/renault-symbioz-sound-design/</a></p>", "content_fr": "<p><strong>En concevant le design sonore de la Renault Symbioz, le nouveau concept car de Renault, un v&eacute;hicule &eacute;lectrique et autonome, l&rsquo;&eacute;quipe <a href=\"/recherche/equipes-recherche/pds/\">Perception et design sonores</a> de l&rsquo;Ircam a r&eacute;pondu &agrave; deux challenges : la conception d&rsquo;un son de signal&eacute;tique avertissant les pi&eacute;tons de la pr&eacute;sence du v&eacute;hicule, et la conception d&rsquo;une gamme de sons destin&eacute;s &agrave; l&rsquo;habitacle de la voiture.</strong></p>\r\n<p><img src=\"/media/uploads/recherche/projets/symbioz.jpg\" style=\"float: right; margin-left: 10px;\" width=\"480\" height=\"321\" />Lors de l&rsquo;&eacute;dition 2017 du Salon de l&rsquo;Automobile &agrave; Francfort, Renault d&eacute;voile sa vision pour 2030 : elle s&rsquo;incarne dans le concept car Symbioz. Le constructeur offre m&ecirc;me aux journalistes l&rsquo;opportunit&eacute; de l&rsquo;essayer.</p>\r\n<p>En amont, une collaboration industrielle est initi&eacute;e pour mettre au point la signature sonore du v&eacute;hicule, entre les laboratoires de Design et innovation de Renault et l&rsquo;&eacute;quipe Perception et design sonores de l&rsquo;Ircam, repr&eacute;sent&eacute;e par l&rsquo;ing&eacute;nieur-chercheur Nicolas Misdariis et le compositeur Andrea Cera.</p>\r\n<p>La Renault Symbioz est la promesse d&rsquo;une fusion entre v&eacute;hicule et espace de vie. Le projet porte une attention toute particuli&egrave;re au confort et &agrave; la qui&eacute;tude du passager, ainsi qu&rsquo;&agrave; l&rsquo;exp&eacute;rimentation des nouvelles technologies pour le contr&ocirc;le du comportement de la voiture et l&rsquo;ambiance &agrave; l&rsquo;int&eacute;rieur du cockpit. Il comporte deux challenges : la conception d&rsquo;un son externe qui avertit les pi&eacute;tons de la pr&eacute;sence du v&eacute;hicule (la signature sonore), et la conception d&rsquo;une gamme de sons destin&eacute;s &agrave; l&rsquo;habitacle de la voiture (les sons du cockpit).</p>\r\n<p>La signature sonore est activ&eacute;e lorsque la vitesse de la voiture se situe entre 0 et 30 km/h &ndash;, une plage de vitesse durant laquelle la voiture &eacute;lectrique est potentiellement silencieuse. Ses caract&eacute;ristiques sont issues de deux projets pr&eacute;c&eacute;dents &eacute;labor&eacute;s par la m&ecirc;me &eacute;quipe : la signature sonore de la Renault Trezor (un concept car) et de la Renault Zo&eacute; (un mod&egrave;le commercialis&eacute;).</p>\r\n<p>La signature sonore de la Symbioz est un hybride entre composants &eacute;lectriques et turbine, avec une touche de moteur &agrave; combustion, puissante sans &ecirc;tre agressive. Quand le moteur est au ralenti, il &eacute;met de courtes s&eacute;quences sonores &agrave; la fois douces et aigues cr&eacute;ant ainsi un langage abstrait (r&eacute;sultant de l&rsquo;&eacute;mergence d&rsquo;&eacute;l&eacute;ments appel&eacute;s &laquo; agents audio &raquo;) et avertissant les pi&eacute;tons que le moteur est allum&eacute;. Le prototype du son est cr&eacute;&eacute; dans le logiciel Max puis convertit dans un environnement propri&eacute;taire.</p>\r\n<p>La Symbioz est &eacute;galement un vrai laboratoire d&rsquo;&eacute;tude pour les sons de cockpit du futur. L&rsquo;Ircam a d&eacute;velopp&eacute; un ensemble d&rsquo;interfaces sonores homme-machine innovantes (IHM) dans deux directions distinctes :</p>\r\n<p style=\"padding-left: 30px;\">1. Exhaustivit&eacute;<br />C&rsquo;est la totalit&eacute; des interactions conducteur/passager/cockpit, li&eacute;es aux modes de fonctionnement de la Symbioz, qui a &eacute;t&eacute; trait&eacute;e.<br />A ce titre, la possibilit&eacute; d&rsquo;un mode de conduite autonome implique de nouveaux challenges au niveau du design : comment communiquer les diff&eacute;rents niveaux d&rsquo;autonomie de la voiture ? Comment rassurer les passagers lorsque la voiture est en mode de conduite autonome ? Pour y r&eacute;pondre, un prototype dans Max a &eacute;t&eacute; cr&eacute;e afin de g&eacute;rer le grand nombre d&rsquo;IHM n&eacute;cessaires &agrave; la r&eacute;alisation du projet.</p>\r\n<p style=\"padding-left: 30px;\">2. Spatialisation<br />Un concept original d&rsquo;IHM sonores spatialis&eacute;es ont &eacute;t&eacute; d&eacute;velopp&eacute;es.<br />Chaque son &eacute;mis dans le cockpit de la Symbioz (clignotants, alarmes, sons informatifs...) est positionn&eacute; dans un espace acoustique virtuel. La voiture dispose de trois modes de conduite (Classique, Dynamique, Autonome). Dans chaque mode, les sons tournent l&eacute;g&egrave;rement autour de positions virtuelles, avec divers degr&eacute;s de modulation et de r&eacute;verb&eacute;ration. Par exemple, dans le mode Dynamique, les clignotants sont plac&eacute;s de fa&ccedil;on tr&egrave;s stable dans la direction que la voiture va emprunter. Dans le mode Autonome, l&rsquo;orientation des clignotants est beaucoup plus souple puisque qu&rsquo;aucun passager ne se concentre sur la conduite. En bougeant dans l&rsquo;espace, les IHMs deviennent moins g&ecirc;nantes et plus naturelles &ndash; les changements de position se traduisent par de subtiles alt&eacute;rations de timbre d&ucirc;es au d&eacute;phasage et &agrave; la r&eacute;verb&eacute;ration sur les murs du cockpit.</p>\r\n<p class=\"wys-small-text\"><a href=\"https://audio-branding-academy.org/renault-symbioz-sound-design/\" target=\"_blank\">https://audio-branding-academy.org/renault-symbioz-sound-design/</a></p>", "content_en": "<p><strong>IRCAM&rsquo;s <a href=\"/recherche/equipes-recherche/pds/\">Sound Perception and Design</a> team responded to two challenges in designing the sound of Renault Symbioz, Renault&rsquo;s new concept car: the conception of external sound to warn pedestrians of the car&rsquo;s presence and the design of a collection of sounds for the car&rsquo;s interior.</strong></p>\r\n<p><img src=\"/media/uploads/recherche/projets/symbioz.jpg\" style=\"float: right; margin-left: 10px;\" width=\"480\" height=\"321\" />After unveiling a vision for 2030 with the concept car Symbioz at the Frankfurt motor show in September 2017, Renault gave journalists the chance to drive the Symbioz demo car.</p>\r\n<p>To curate the sonic aspects of this project, in 2016 an industrial collaboration was initiated between Renault&rsquo;s Design/Innovation Lab departments, and IRCAM&rsquo;s Sound Perception and Design Team, represented by engineer-researcher Nicolas Misdariis and sound designer Andrea Cera.</p>\r\n<p>Symbioz represents a fusion of vehicle and living space. Care for the passenger&rsquo;s comfort and peace of mind coexists with experimentation of new technologies to control the car&rsquo;s behavior, internal atmosphere, and feel. The project offered two sound design challenges: the design of an external sound to warn pedestrians of the presence of the car (sound signature), and the design of a collection of sounds for the car&rsquo;s interior (cockpit sounds).</p>\r\n<p>The sound signature is diffused when the car&rsquo;s speed is between 0 and 30 km/h &ndash; a speed range in which the electric car is potentially silent. Its features are derived from two previous projects by the same team, the sound signatures of Renault Trezor (a concept-car) and Renault Zo&eacute; (a commercialized model).</p>\r\n<p>The nature of Symbioz&rsquo;s sound signature is a hybrid of electric and turbine components, with a trace of a powerful, but not aggressive, internal combustion engine. When the car is idling, it emits sequences of soft, short, and high-pitched sounds creating an abstract language (from the emerging behavior of audio agents) and warning pedestrians that the car is switched on. The sound was prototyped in Max and converted to a proprietary algorithm.</p>\r\n<p>Symbioz is a laboratory for studying the future of cockpit sounds. IRCAM developed a series of innovative sonic Human-Machine Interfaces (HMI), in two distinct directions.</p>\r\n<p style=\"padding-left: 30px;\">1.&nbsp;&nbsp; &nbsp;Exhaustiveness &ndash; All driver/passenger/cockpit interactions related to Symbioz&rsquo;s modes of functioning were processed. The availability of a self-driving mode creates new design challenges. How to communicate levels of the car&rsquo;s autonomy? How to reassure the passengers that everything is OK when the car is self-driving? To manage the large number of HMIs needed a prototype was created in Max.</p>\r\n<p style=\"padding-left: 30px;\">2.&nbsp;&nbsp; &nbsp;Spatialization &ndash; IRCAM developed an original concept of spatial sonic HMI.<br />Every sound played in Symbioz&rsquo;s cockpit (blinkers, alarms, info sounds&hellip;) is placed in a virtual acoustic space. The car has three modes of use (Classic, Dynamic, Autonomous). In each mode the sounds move slightly around virtual positions, with different degrees of jitter and reverberation. For instance, in Dynamic Mode the blinkers are firmly placed in the direction the car will take. In Autonomous Drive Mode the blinkers are oriented much loosely, since no passenger is focused in driving. By moving in space, HMIs become less annoying and more natural &ndash; changes in position translate into subtle timbral shifts due to phasing and reflections in the cockpit walls.</p>\r\n<p class=\"wys-small-text\"><a href=\"https://audio-branding-academy.org/renault-symbioz-sound-design/\" target=\"_blank\">https://audio-branding-academy.org/renault-symbioz-sound-design/</a></p>", "date_from": null, "date_to": null, "user": null, "type": "internal", "external_id": "", "program": null, "program_type": null, "call": null, "lead_team": null, "lead_organization": null, "website": "", "topic": 24, "is_archive": false, "validation_status": 1, "funding": null, "teams": [3], "organizations": [1, 210], "referring_person": [], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 190, "fields": {"keywords_string": "", "site": 1, "title": "Rasputin", "title_fr": "Rasputin", "title_en": "", "slug": "rasputin", "_meta_title": "", "description": "Rasputin", "description_fr": "Rasputin", "description_en": "Rasputin", "gen_description": true, "created": "2018-11-09T17:40:22.328Z", "updated": "2018-11-09T17:40:22.329Z", "status": 1, "publish_date": "2018-11-09T17:40:22.326Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "", "content_fr": "", "content_en": "", "date_from": "2018-11-01", "date_to": "2022-10-30", "user": null, "type": "external", "external_id": "", "program": 1, "program_type": 28, "call": null, "lead_team": 2, "lead_organization": 422, "website": "", "topic": null, "is_archive": false, "validation_status": 3, "funding": "public", "teams": [2], "organizations": [], "referring_person": [173], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 191, "fields": {"keywords_string": "", "site": 1, "title": "Element", "title_fr": "Element", "title_en": "", "slug": "element", "_meta_title": "", "description": "Element", "description_fr": "Element", "description_en": "Element", "gen_description": true, "created": "2018-11-12T09:45:22.262Z", "updated": "2018-11-15T16:14:39.066Z", "status": 1, "publish_date": "2018-11-12T09:45:22Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "", "content_fr": "", "content_en": "", "date_from": "2018-11-01", "date_to": "2021-10-31", "user": null, "type": "external", "external_id": "", "program": 1, "program_type": 28, "call": null, "lead_team": 7, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 2, "funding": "public", "teams": [7], "organizations": [], "referring_person": [70], "manager": [], "concepts": []}}, {"model": "organization-projects.project", "pk": 192, "fields": {"keywords_string": "", "site": 1, "title": "Ulysses", "title_fr": "Ulysses", "title_en": "", "slug": "ulysses", "_meta_title": "", "description": "Ulysses", "description_fr": "Ulysses", "description_en": "Ulysses", "gen_description": true, "created": "2019-01-08T18:03:20.898Z", "updated": "2019-01-08T18:03:20.899Z", "status": 1, "publish_date": "2019-01-08T18:03:20.896Z", "expiry_date": null, "short_url": "", "in_sitemap": true, "content": "", "content_fr": "", "content_en": "", "date_from": "2016-06-01", "date_to": "2020-05-31", "user": null, "type": "external", "external_id": "", "program": 16, "program_type": null, "call": null, "lead_team": 9, "lead_organization": 1, "website": "", "topic": null, "is_archive": false, "validation_status": 1, "funding": null, "teams": [], "organizations": [], "referring_person": [], "manager": [], "concepts": []}}]